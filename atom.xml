<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>BG运维说</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-11-05T13:00:29.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Andy Xu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>我的越野元年</title>
    <link href="http://yoursite.com/2017/11/05/%E6%88%91%E7%9A%84%E8%B6%8A%E9%87%8E%E5%85%83%E5%B9%B4/"/>
    <id>http://yoursite.com/2017/11/05/我的越野元年/</id>
    <published>2017-11-05T10:35:33.000Z</published>
    <updated>2017-11-05T13:00:29.000Z</updated>
    
    <content type="html"><![CDATA[<p>时间过的很快，不知不觉中已经到了一年的最后两个月了，而同样也到了需要供暖和剁手的季节(插播个小广告:挑好物，上京东哦！)。北京的秋天和冬天其实并不明显，因为天气逐渐变冷，我也深知，今年的户外长跑可能就要止步于昨天的”奥森100+超级马拉松”的陪跑活动了，该赛事由”汇跑赛事”主办，参赛选手需要有资深的跑步经历，并且需要再12小时内完成100+公里的马拉松。很幸运，公司的同事”藤神”也是其中50多位选手中的一员，而我为了感受”疯(封)神之旅”，也依然加入了”藤神”陪跑团中，助力京东跑团的兄弟安全完赛。</p>
<a id="more"></a>
<h4 id="2017马拉松赛事历程"><a href="#2017马拉松赛事历程" class="headerlink" title="2017马拉松赛事历程"></a>2017马拉松赛事历程</h4><p><strong>11-4 奥森100+超级马拉松</strong><br>封神之路需要一个强大的跑团作为支撑，作为“藤神”的后盾，我们也有一只团结、温暖、强大的跑团。<br><img src="http://oyep1jupk.bkt.clouddn.com/running/malasong/aosen100-3.jpeg" alt=""></p>
<p>跑步过程中的临时补给拉伸，再次整装待发。<br><img src="http://oyep1jupk.bkt.clouddn.com/running/malasong/aosen100.jpeg" alt=""></p>
<p>终于在12个小时内轻松完赛。<br><img src="http://oyep1jupk.bkt.clouddn.com/running/malasong/aosen100-1.jpeg" alt=""></p>
<p>对了，中间戴红帽子的就是我们这次比赛的主将”藤神”</p>
<p>由于我是最后陪跑的，也没在后方给”藤神”太多的帮助，所以在最后三十公里，决定都陪着”藤神”跑，虽然最后一圈半比较冷，但陪跑的过程中却是无比开心和自豪，其实也是想趁着这次机会，再来一次长跑。<br><img src="http://oyep1jupk.bkt.clouddn.com/running/malasong/aosen100-2.png" alt=""></p>
<p>“藤神”封神之路，在我看来尽是感动，三四十位跑友们自发组成陪跑团，提供补给，路跑开路，全程护送到终点，大家没有明确分工，但却各司其职，尽自己的最大努力来给主将兄弟助威。这一方面是因为跑友情，另外一方面可能也是因为”京东跑团”情，让我再一次感受到”京东跑团、爱心暖暖！”。也许如果哪天我离开京东了，可能最让我不舍的就是京东跑团这个民间组织以及跑团的各位兄弟了吧。</p>
<p>再回退两个月，9月参加了两次长跑，分别是“2017北京马拉松”和“2017太原马拉松”。讲真，跑步六七年，我还未曾跑过超过30KM的距离，一方面是因为懒癌上身，独自一人懒得跑那么多，另外一方面是因为不够跑🐴的资格，导致多次报名马拉松都未中签，所以，在得知一个月要参加两次马拉松的时候，内心的愉悦是难以言表的，而且最终两场比赛都安全完赛且刷新个人成绩，这其中也是非常感谢京东跑团的各位兄弟姐妹们特别是我们的跑团老大哥团长凯哥，我和凯哥配速相当，这一两年只要有比赛，基本都会一起跑，在凯哥的帮助指导下飞速进步，而凯哥作为一位长辈在我的成长之路上也影响了我很多，肉麻的话我就不说了，哈哈。</p>
<p><strong>9-17 北京马拉松</strong><br>起跑前在天安门前的齐唱国歌:<br><img src="http://oyep1jupk.bkt.clouddn.com/running/malasong/beima1.jpeg" alt=""></p>
<p>起点的人山人海:<br><img src="http://oyep1jupk.bkt.clouddn.com/running/malasong/beima2.jpeg" alt=""></p>
<p>起跑前的跑团合影:<br><img src="http://oyep1jupk.bkt.clouddn.com/running/malasong/beima8.jpeg" alt=""></p>
<p>快到终点时的欣喜:<br><img src="http://oyep1jupk.bkt.clouddn.com/running/malasong/beima10.jpeg" alt=""></p>
<p><img src="http://oyep1jupk.bkt.clouddn.com/running/malasong/beima11.jpeg" alt=""></p>
<p>帅气的北马完赛奖牌:<br><img src="http://oyep1jupk.bkt.clouddn.com/running/malasong/beima5.jpeg" alt=""><br><img src="http://oyep1jupk.bkt.clouddn.com/running/malasong/beima6.jpeg" alt=""></p>
<p>完赛大合照:<br><img src="http://oyep1jupk.bkt.clouddn.com/running/malasong/beima7.jpeg" alt=""></p>
<p>北马路线和完赛证书:<br><img src="http://oyep1jupk.bkt.clouddn.com/running/malasong/beima3.png" alt=""><br><img src="http://oyep1jupk.bkt.clouddn.com/running/malasong/beima9.png" alt=""></p>
<p>北马，我的第二个全程马拉松，成功在四小时三十分钟内完赛，在我的两次马拉松历史中刷新了最佳成绩。</p>
<p><strong>9-10 太马前的跑团</strong><br>跑前合影<br><img src="http://oyep1jupk.bkt.clouddn.com/running/malasong/taima1.jpeg" alt=""></p>
<p><img src="http://oyep1jupk.bkt.clouddn.com/running/malasong/taima4.jpeg" alt=""><br>自左向右分别是：+神、我、凯哥、磊哥、藤神、爱林和妹妹的钧涵小姐姐</p>
<p>桥洞下的人山人海<br><img src="http://oyep1jupk.bkt.clouddn.com/running/malasong/taima2.jpeg" alt=""></p>
<p>英姿飒爽的跑者(左边那位帅气的男子就是凯哥)<br><img src="http://oyep1jupk.bkt.clouddn.com/running/malasong/taima6.jpeg" alt=""></p>
<p>晒奖牌<br><img src="http://oyep1jupk.bkt.clouddn.com/running/malasong/taima5.jpeg" alt=""></p>
<p>太马路线和完赛证书:<br><img src="http://oyep1jupk.bkt.clouddn.com/running/malasong/taima3.png" alt=""><br><img src="http://oyep1jupk.bkt.clouddn.com/running/malasong/taima7.png" alt=""></p>
<p><strong>崇礼50越野</strong><br>再往回倒一两个月，具体时间忘记了，是去崇礼参加的50KM越野比赛，算是第三次参加超过全马距离的越野赛事，这次我的好搭档凯哥由于身体原因不能参赛，没有相当配速的跑友一起，我需要更加小心和合理规划自己的时间和体力。</p>
<p>越野跑者装备<br><img src="http://oyep1jupk.bkt.clouddn.com/running/chongli50/chongli1.jpeg" alt=""><br>(突然发现，越野真的很费钱，很入门很简单的装备至少也在一两千块了，心疼几秒)</p>
<p>赛前合影<br><img src="http://oyep1jupk.bkt.clouddn.com/running/chongli50/chongli6.jpeg" alt=""><br><img src="http://oyep1jupk.bkt.clouddn.com/running/chongli50/chongli3.jpeg" alt=""><br><img src="http://oyep1jupk.bkt.clouddn.com/running/chongli50/chongli5.jpeg" alt=""></p>
<p>崇礼山上的美景<br><img src="http://oyep1jupk.bkt.clouddn.com/running/chongli50/chongli4.jpeg" alt=""><br><img src="http://oyep1jupk.bkt.clouddn.com/running/chongli50/chongli7.jpeg" alt=""><br><img src="http://oyep1jupk.bkt.clouddn.com/running/chongli50/chongli8.jpeg" alt=""><br><img src="http://oyep1jupk.bkt.clouddn.com/running/chongli50/chongli16.jpeg" alt=""></p>
<p>离天空最近的地方<br><img src="http://oyep1jupk.bkt.clouddn.com/running/chongli50/chongli10.jpeg" alt=""></p>
<p>英姿飒爽<br><img src="http://oyep1jupk.bkt.clouddn.com/running/chongli50/chongli11.jpeg" alt=""><br><img src="http://oyep1jupk.bkt.clouddn.com/running/chongli50/chongli13.jpeg" alt=""></p>
<p>妹子帮忙做的后期,很符合我的口味<br><img src="http://oyep1jupk.bkt.clouddn.com/running/chongli50/chongli14.jpeg" alt=""></p>
<p>崇礼50路线<br><img src="http://oyep1jupk.bkt.clouddn.com/running/chongli50/chongli15.jpeg" alt=""></p>
<p><strong>TNF50赛事</strong><br>再往前两个多月，应该四月多，独自参加了碎碎念的北京TNF50公里越野，这次依然是没有配速相当的跑友，并且是晚上凌晨起跑，对于这次比赛的心情更是无以言表，但与此同时又需要更加的小心。</p>
<p>TNF宣传牌<br><img src="http://oyep1jupk.bkt.clouddn.com/running/tnf50/tnf1.jpeg" alt=""></p>
<p>起跑前的留念<br><img src="http://oyep1jupk.bkt.clouddn.com/running/tnf50/tnf2.jpeg" alt=""></p>
<p>TNF50起跑现场<br><img src="http://oyep1jupk.bkt.clouddn.com/running/tnf50/tnf3.jpeg" alt=""></p>
<p>香山夜景<br><img src="http://oyep1jupk.bkt.clouddn.com/running/tnf50/tnf4.jpeg" alt=""></p>
<p>清晨到达CP9<br><img src="http://oyep1jupk.bkt.clouddn.com/running/tnf50/tnf5.jpeg" alt=""></p>
<p>清晨的水库(忘记名字了，之前跑过的路线)<br><img src="http://oyep1jupk.bkt.clouddn.com/running/tnf50/tnf6.jpeg" alt=""></p>
<p>爬山路<br><img src="http://oyep1jupk.bkt.clouddn.com/running/tnf50/tnf7.jpeg" alt=""><br><img src="http://oyep1jupk.bkt.clouddn.com/running/tnf50/tnf8.jpeg" alt=""><br><img src="http://oyep1jupk.bkt.clouddn.com/running/tnf50/tnf9.jpeg" alt=""></p>
<p>完赛路线和奖牌<br><img src="http://oyep1jupk.bkt.clouddn.com/running/tnf50/tnf10.png" alt=""></p>
<p><img src="http://oyep1jupk.bkt.clouddn.com/running/tnf50/tnf11.jpeg" alt=""></p>
<p>完赛留念<br><img src="http://oyep1jupk.bkt.clouddn.com/running/tnf50/tnf15.jpeg" alt=""></p>
<p>可怜的脚丫子<br><img src="http://oyep1jupk.bkt.clouddn.com/running/tnf50/tnf13.jpeg" alt=""><br><img src="http://oyep1jupk.bkt.clouddn.com/running/tnf50/tnf12.jpeg" alt=""></p>
<p>唯一的抓拍照<br><img src="http://oyep1jupk.bkt.clouddn.com/running/tnf50/tnf14.jpeg" alt=""></p>
<p><strong>新年刷天安门跑</strong><br>再上一次户外长跑应该就是元旦时和几位兄弟姐妹们一起刷天安门了，只为了留作一些纪念，新年伊始刷个新年的数字希望也能重新开始。到目前为止，我已经刷过2015,2016,2017三个数字了，等待明年碰个好天气一起刷2018.</p>
<p><img src="http://oyep1jupk.bkt.clouddn.com/running/2017/2017-1.jpeg" alt=""><br><img src="http://oyep1jupk.bkt.clouddn.com/running/2017/2017.jpeg" alt=""></p>
<p><strong>青芝坞越野</strong></p>
<p>青芝坞越野赛算是我真正意义上第一个长距离越野赛事，是2016年11月初和凯哥一起去杭州参赛的，也正是因为那场赛事的成功完赛，让我有了底气去参加今年的两场50公里的越野赛事。</p>
<p>青芝坞越野赛照<br><img src="http://oyep1jupk.bkt.clouddn.com/running/2017/qingzhiwu.jpeg" alt=""></p>
<p>帅气的奖牌<br><img src="http://oyep1jupk.bkt.clouddn.com/running/2017/qingzhiwu2.jpeg" alt=""></p>
<p>完赛路线<br><img src="http://oyep1jupk.bkt.clouddn.com/running/2017/qingzhiwu3.jpeg" alt=""></p>
<p><strong>与越野结缘</strong></p>
<p>与越野结缘，应当算是京东体育主办的”西山7公里轻越野”，但是轻的让人感觉不到有什么难度，但也是那次体验让我真正喜欢上了越野赛事。</p>
<p>京东跑团的多位跑友一同参加，欢聚一堂<br><img src="http://oyep1jupk.bkt.clouddn.com/running/2017/qyueye1.jpg" alt=""><br><img src="http://oyep1jupk.bkt.clouddn.com/running/2017/qyueye2.jpg" alt=""></p>
<p>真的非常感谢京东跑团的兄弟们，一路上有这么多志同道合的朋友们一起坚持一起跑下来！</p>
<p>结缘后的日子，很快便和凯哥组成越野小分队初试半程越野赛<br><img src="http://oyep1jupk.bkt.clouddn.com/running/2017/jingxigudao.jpg" alt=""></p>
<p>青涩的少年<br><img src="http://oyep1jupk.bkt.clouddn.com/running/2017/jingxigudao2.jpg" alt=""></p>
<h4 id="展望未来"><a href="#展望未来" class="headerlink" title="展望未来"></a>展望未来</h4><p>从接触越野到目前为止一年多，去年是在接触并熟悉感受越野，今年则是在越野赛中不断认识自己，而今年也是我的越野元年，明年我可能回去挑战一些越野赛事并且去尝试感受不同地方的风景和山脉，希望自己能够在越野赛事中不断的认识自己，历练自己。</p>
<p>大连100的🏆很帅气，我想明年肯定会去体验一下的。<br><img src="http://oyep1jupk.bkt.clouddn.com/running/2017/dalian100.jpg" alt=""></p>
<p>越野、马拉松，2018 我们再见！</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;时间过的很快，不知不觉中已经到了一年的最后两个月了，而同样也到了需要供暖和剁手的季节(插播个小广告:挑好物，上京东哦！)。北京的秋天和冬天其实并不明显，因为天气逐渐变冷，我也深知，今年的户外长跑可能就要止步于昨天的”奥森100+超级马拉松”的陪跑活动了，该赛事由”汇跑赛事”主办，参赛选手需要有资深的跑步经历，并且需要再12小时内完成100+公里的马拉松。很幸运，公司的同事”藤神”也是其中50多位选手中的一员，而我为了感受”疯(封)神之旅”，也依然加入了”藤神”陪跑团中，助力京东跑团的兄弟安全完赛。&lt;/p&gt;
    
    </summary>
    
      <category term="生活思考" scheme="http://yoursite.com/categories/%E7%94%9F%E6%B4%BB%E6%80%9D%E8%80%83/"/>
    
    
      <category term="工作" scheme="http://yoursite.com/tags/%E5%B7%A5%E4%BD%9C/"/>
    
      <category term="生活" scheme="http://yoursite.com/tags/%E7%94%9F%E6%B4%BB/"/>
    
      <category term="感悟" scheme="http://yoursite.com/tags/%E6%84%9F%E6%82%9F/"/>
    
  </entry>
  
  <entry>
    <title>使用Docker镜像快速启动Etcd集群</title>
    <link href="http://yoursite.com/2017/11/03/%E4%BD%BF%E7%94%A8Docker%E9%95%9C%E5%83%8F%E5%BF%AB%E9%80%9F%E5%90%AF%E5%8A%A8Etcd%E9%9B%86%E7%BE%A4/"/>
    <id>http://yoursite.com/2017/11/03/使用Docker镜像快速启动Etcd集群/</id>
    <published>2017-11-03T01:11:57.000Z</published>
    <updated>2017-11-05T02:00:27.000Z</updated>
    
    <content type="html"><![CDATA[<p>本篇文章上接<a href="https://xxbandy.github.io/2017/08/26/Dockerfile-etcd/" target="_blank" rel="external">自构建etcd镜像</a>来使用systemd工具利用自构建的etcd镜像快速的搭建一套高可用的etcd集群。</p>
<a id="more"></a>
<h3 id="核心配置文件"><a href="#核心配置文件" class="headerlink" title="核心配置文件"></a>核心配置文件</h3><p>测试集群使用3节点的etcd集群进行搭建测试，以下为node1节点配置示例，其他两个节点类似，仅需要修改<code>NAME</code><br><a href="http://blog.csdn.net/peterxiaoq/article/details/72831866" target="_blank" rel="external">systemd添加自定义服务</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"># cat /etc/etcd/etcd.conf</div><div class="line">NAME=&quot;etcd-1&quot;</div><div class="line">DATADIR=&quot;/export/etcd_data&quot;</div><div class="line">MYHOST=&quot;http://10.0.0.1&quot;</div><div class="line">PORT=&quot;2379&quot;</div><div class="line">CLUSTER_PORT=&quot;2380&quot;</div><div class="line">CLUSTER=&quot;etcd-1=http://10.0.0.1:2380,etcd-2=http://10.0.0.2:2380,etcd-3=http://10.0.0.3:2380&quot;</div><div class="line">CLUSTER_TOKEN=&quot;my-etcd-token&quot;</div><div class="line">CLUSTER_STATE=&quot;new&quot;</div><div class="line"></div><div class="line"># cat /etc/systemd/system/etcd-node.service</div><div class="line">[Unit]</div><div class="line">Description=etcd node</div><div class="line">After=docker.service</div><div class="line">Requires=docker.service</div><div class="line"></div><div class="line">[Service]</div><div class="line">User=root</div><div class="line">EnvironmentFile=-/etc/etcd/etcd.conf</div><div class="line">PermissionsStartOnly=true</div><div class="line">ExecStart=/usr/bin/docker run -itd --net=host   --name=etcd-node -e NAME=$&#123;NAME&#125; -e DATADIR=$&#123;DATADIR&#125; -e MYHOST=$&#123;MYHOST&#125; -e PORT=$&#123;PORT&#125; -e CLUSTER_PORT$=$&#123;CLUSTER_PORT&#125; -e CLUSTER=$&#123;CLUSTER&#125; -e CLUSTER_TOKEN=$&#123;CLUSTER_TOKEN&#125; -e CLUSTER_STATE=$&#123;CLUSTER_STATE&#125; xxbandy123/etcd:3.0.10</div><div class="line"></div><div class="line">#ExecStop=/usr/bin/docker rm -f etcd-node</div><div class="line">#Restart=always</div><div class="line">#RestartSec=10</div><div class="line"></div><div class="line">[Install]</div><div class="line">WantedBy=multi-user.target</div></pre></td></tr></table></figure></p>
<p><code>注意1</code>:需要分别修改每个节点上/etc/etcd/etcd.conf配置文件中的NAME和MYHOST、CLUSTER三个变量<br><code>注意2</code>:在编写systemctl服务管理配置的时候，一定不要设置重启策略并且设置<code>ExecStop</code>,因为初始化集群时需要多个节点同时进行启动并互相发现，当重启某个实例的时候，重新选举注册时，就会发现该节点已经存在与集群中，因此无法正常加入集群，而导致实例启动失败。正常的做法应该是某个实例异常后，先在集群内部摘除该节点，其后将该节点按照当前状态加入到集群后根据相关信息再次启动实例<br><a href="https://segmentfault.com/a/1190000003976539" target="_blank" rel="external">etcd运维</a></p>
<h3 id="启动验证"><a href="#启动验证" class="headerlink" title="启动验证"></a>启动验证</h3><p>分别启动三个docker实例</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">systemctl daemon-reload</div><div class="line">systemctl start etcd-node</div><div class="line"></div><div class="line"># etcdctl cluster-health</div><div class="line">2017-11-03 09:15:49.006358 I | warning: ignoring ServerName for user-provided CA for backwards compatibility is deprecated</div><div class="line">2017-11-03 09:15:49.007093 I | warning: ignoring ServerName for user-provided CA for backwards compatibility is deprecated</div><div class="line">member 911c5e15a35cdb8f is healthy: got healthy result from http://10.0.0.1:2379</div><div class="line">member b01d138087dbe547 is healthy: got healthy result from http://10.0.0.3:2379</div><div class="line">member c22c1c7b5a4c9f9b is healthy: got healthy result from http://10.0.0.2:2379</div><div class="line">cluster is healthy</div></pre></td></tr></table></figure>
<h3 id="集群维护"><a href="#集群维护" class="headerlink" title="集群维护"></a>集群维护</h3><p>模拟集群某个节点宕机，并恢复集群</p>
<h4 id="查看当前集群状态信息以及可用性"><a href="#查看当前集群状态信息以及可用性" class="headerlink" title="查看当前集群状态信息以及可用性"></a>查看当前集群状态信息以及可用性</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">etcdctl member list</div><div class="line">2017-11-04 09:04:14.150103 I | warning: ignoring ServerName for user-provided CA for backwards compatibility is deprecated</div><div class="line">9923f8b86d3ce7a6: name=etcd-1 peerURLs=http://10.0.0.1:2380 clientURLs=http://172.25.44.6:2379 isLeader=false</div><div class="line">b01d138087dbe547: name=etcd-3 peerURLs=http://10.0.0.3:2380 clientURLs=http://172.25.47.78:2379 isLeader=false</div><div class="line">c22c1c7b5a4c9f9b: name=etcd-2 peerURLs=http://10.0.0.2:2380 clientURLs=http://172.25.47.77:2379 isLeader=true</div><div class="line">[root@hc-25-44-6 pe]# etcdctl set bgops biaoge</div><div class="line">2017-11-04 09:04:40.234434 I | warning: ignoring ServerName for user-provided CA for backwards compatibility is deprecated</div><div class="line">biaoge</div><div class="line"></div><div class="line"># etcdctl get bgops</div><div class="line">2017-11-04 09:05:22.059435 I | warning: ignoring ServerName for user-provided CA for backwards compatibility is deprecated</div><div class="line">biaoge</div></pre></td></tr></table></figure>
<h4 id="删除node2节点上的容器实例"><a href="#删除node2节点上的容器实例" class="headerlink" title="删除node2节点上的容器实例"></a>删除node2节点上的容器实例</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"># docker rm -f -v etcd-node</div><div class="line"># etcdctl cluster-health</div><div class="line">member 9923f8b86d3ce7a6 is healthy: got healthy result from http://10.0.0.1:2379</div><div class="line">member b01d138087dbe547 is healthy: got healthy result from http://10.0.0.3:2379</div><div class="line">failed to check the health of member c22c1c7b5a4c9f9b on http://10.0.0.2:2379: Get http://172.25.47.77:2379/health: dial tcp 172.25.47.77:2379: getsockopt: connection refused</div><div class="line">member c22c1c7b5a4c9f9b is unreachable: [http://10.0.0.2:2379] are all unreachable</div><div class="line">cluster is healthy</div><div class="line"></div><div class="line"># etcdctl get bgops</div><div class="line">2017-11-04 09:10:40.658013 I | warning: ignoring ServerName for user-provided CA for backwards compatibility is deprecated</div><div class="line">biaoge</div></pre></td></tr></table></figure>
<p>如上显示，其中node2节点的已经失联，而由于当前etcd集群是3实例集群，因此集群整体仍然是健康状态，并且能够正常使用</p>
<h4 id="恢复node2节点实例到集群中"><a href="#恢复node2节点实例到集群中" class="headerlink" title="恢复node2节点实例到集群中"></a>恢复node2节点实例到集群中</h4><p>注意：如果单纯的去按照原始配置启动node2上的实例的话，会提示无法加入集群(因为实例id已经注册上去了c22c1c7b5a4c9f9b)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"># docker logs etcd-node</div><div class="line"> ....</div><div class="line">2017-11-04 01:12:25.307452 C | etcdmain: member c22c1c7b5a4c9f9b has already been bootstrapped</div></pre></td></tr></table></figure></p>
<p>正确的恢复姿势<br>1.在集群中移除异常节点<br>2.在集群中增加集群节点(异常节点也作为新节点加入集群)<br>3.根据集群反馈信息进行异常节点重启<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"># etcdctl member remove c22c1c7b5a4c9f9b</div><div class="line">2017-11-04 09:15:48.488427 I | warning: ignoring ServerName for user-provided CA for backwards compatibility is deprecated</div><div class="line">Removed member c22c1c7b5a4c9f9b from cluster</div><div class="line"></div><div class="line"># etcdctl member add etcd-2 http://10.0.0.2:2380</div><div class="line">2017-11-04 09:16:50.704247 I | warning: ignoring ServerName for user-provided CA for backwards compatibility is deprecated</div><div class="line">Added member named etcd-2 with ID 51e807366fadaded to cluster</div><div class="line"></div><div class="line">ETCD_NAME=&quot;etcd-2&quot;</div><div class="line">ETCD_INITIAL_CLUSTER=&quot;etcd-2=http://10.0.0.2:2380,etcd-1=http://10.0.0.1:2380,etcd-3=http://10.0.0.3:2380&quot;</div><div class="line">ETCD_INITIAL_CLUSTER_STATE=&quot;existing&quot;</div></pre></td></tr></table></figure></p>
<p>根据反馈信息进行异常节点恢复(给出了name,cluster,state三个参数)<br>由于我们是根据原有集群进行恢复节点，所以需要修改node2节点的状态,并启动实例<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"># grep STATE  /etc/etcd/etcd.conf</div><div class="line">CLUSTER_STATE=&quot;existing&quot;</div><div class="line"># systemctl restart  etcd-node</div><div class="line"># docker ps</div><div class="line">CONTAINER ID        IMAGE                               COMMAND                  CREATED             STATUS              PORTS               NAMES</div><div class="line">9fb8b1544642        xxbandy123/etcd:3.0.10   &quot;/docker-entrypoint.s&quot;   33 seconds ago      Up 32 seconds                           etcd-node</div><div class="line"></div><div class="line"># etcdctl cluster-health</div><div class="line">2017-11-04 09:23:44.053605 I | warning: ignoring ServerName for user-provided CA for backwards compatibility is deprecated</div><div class="line">2017-11-04 09:23:44.054497 I | warning: ignoring ServerName for user-provided CA for backwards compatibility is deprecated</div><div class="line">member 51e807366fadaded is healthy: got healthy result from http://10.0.0.2:2379</div><div class="line">member 9923f8b86d3ce7a6 is healthy: got healthy result from http://10.0.0.1:2379</div><div class="line">member b01d138087dbe547 is healthy: got healthy result from http://10.0.0.3:2379</div><div class="line">cluster is healthy</div><div class="line"># etcdctl get bgops</div><div class="line">2017-11-04 09:23:38.541355 I | warning: ignoring ServerName for user-provided CA for backwards compatibility is deprecated</div><div class="line">biaoge</div></pre></td></tr></table></figure></p>
<p>至此，node2节点成功恢复到etcd集群中，并可以提供正常服务</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本篇文章上接&lt;a href=&quot;https://xxbandy.github.io/2017/08/26/Dockerfile-etcd/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;自构建etcd镜像&lt;/a&gt;来使用systemd工具利用自构建的etcd镜像快速的搭建一套高可用的etcd集群。&lt;/p&gt;
    
    </summary>
    
      <category term="Docker" scheme="http://yoursite.com/categories/Docker/"/>
    
    
      <category term="Etcd-Cluster" scheme="http://yoursite.com/tags/Etcd-Cluster/"/>
    
      <category term="Docker" scheme="http://yoursite.com/tags/Docker/"/>
    
      <category term="systemd" scheme="http://yoursite.com/tags/systemd/"/>
    
  </entry>
  
  <entry>
    <title>玩转Docker运维管理</title>
    <link href="http://yoursite.com/2017/10/30/%E7%8E%A9%E8%BD%ACDocker%E8%BF%90%E7%BB%B4%E7%AE%A1%E7%90%86/"/>
    <id>http://yoursite.com/2017/10/30/玩转Docker运维管理/</id>
    <published>2017-10-30T14:41:34.000Z</published>
    <updated>2017-10-30T14:47:32.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>在使用docker过程中，我们经常发现管理维护是一个很复杂过程，因为我们在使用docker commands的过程中，我们只会去使用我们认为简单并且熟悉的命令，然而docker本身其实是提供给我们很多便捷且人性化的工具的，如果掌握这些使用技巧，也许你的维护管理工作将会事半功倍，并且给人看起来会很牛逼的样子。</p>
</blockquote>
<a id="more"></a>
<h4 id="创建容器时传入环境变量"><a href="#创建容器时传入环境变量" class="headerlink" title="创建容器时传入环境变量"></a>创建容器时传入环境变量</h4><p>在实际应用场景中，不论是从安全还是可配置方面去考虑，很多参数是比较适合用环境变量加载进去的，比如数据库的连接信息，时区，还有字体支持等等，在创建容器的时候其实都可以使用-e 指定key/value进行传递环境变量进去。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">sh-4.2# docker run -itd --name test-env -e TZ=&apos;Asia/Shanghai&apos; biaoge/centos6.8-jdjr-test-app </div><div class="line">ee20b44301e27c16eae63dab243d293054178dd5f819c23d44bd9e534208bb42</div><div class="line">sh-4.2# docker exec -it test-env date</div><div class="line">2017年 01月 17日 星期二 10:35:17 CST</div><div class="line">sh-4.2# date</div><div class="line">Tue Jan 17 10:35:21 CST 2017</div><div class="line">可以看到加了时区环境变量的容器已经和宿主机在同一个时区(CST)，并且时间和宿主机基本同步</div><div class="line"></div><div class="line">sh-4.2# docker run -itd --name test  biaoge/centos6.8-jdjr-test-app</div><div class="line">d6a02874b999ff4eea79e3b302148b42043af01c89a5d31e5d858e0806f9077a</div><div class="line">sh-4.2# docker exec -it test date</div><div class="line">2017年 01月 20日 星期五 01:43:48 Asia</div><div class="line">默认没有加时区环境变量的容器还是Asia</div></pre></td></tr></table></figure>
<h4 id="调整宿主机和容器的时间差异"><a href="#调整宿主机和容器的时间差异" class="headerlink" title="调整宿主机和容器的时间差异"></a>调整宿主机和容器的时间差异</h4><p>首先我们需要弄清几个概念：在类unix系统中有硬件时钟与系统时钟，硬件时钟是指主机板上的时钟设备，也就是通常可在BIOS画面设定的时钟，系统时钟则是指kernel中的时钟。unix以及linux系统时间是从格林威治时间到当前的秒数，即1970年1月1日凌晨零点零分零秒到当前的时间，全球都一样，这是绝对值；而时区则是由于地理位置差异、行政区划导致各地显示时间的差异，为了克服时间上的混乱，规定将全球划分为24个时区，我们国家属于东八区标识为CST。</p>
<p>因此，对于 Docker 容器而言，根本不存在宿主和容器的时间差异问题，因为他们使用的是同一个内核、同一个时钟，二者完全一样，所以根本不存在同步问题。一般来说这个问题是由时区导致的，可以使用date命令查看下容器当前的时间时区是啥。UTC(通用协调时)表示使用的是国际标准0时区，UTC与格林尼治平均时(GMT, Greenwich Mean Time)一样，都与英国伦敦的本地时相同。CST表示中国标准时间时区一般是中国上海”Aisa/Shanghai”，也就是说UTC和CST相差了8个小时。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">解决办法：</div><div class="line">创建容器的时候，使用-e 将时区信息传入到容器内部。</div><div class="line">sh-4.2# docker run -itd --name test-env -e TZ=&apos;Asia/Shanghai&apos; images</div></pre></td></tr></table></figure>
<p><code>注意：其实使用单纯的环境变量来改变容器内部的TIME ZONE，只会影响当前容器用户的时区，一旦切换到真正的root用户就会发现时区依然是不正确的，比如以下栗子：</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">$ docker run -itd --name test-env -e TZ=&apos;Asia/Shanghai&apos; images</div><div class="line">$ docker exec -it test-env bash</div><div class="line">bash-4.1# date</div><div class="line">2017年 09月 20日 星期三 20:45:54 CST</div><div class="line">bash-4.1# sudo su -c date</div><div class="line">2017年 09月 20日 星期三 08:46:02 EDT</div><div class="line">bash-4.1#</div></pre></td></tr></table></figure>
<p>那么如何真正解决时区这个问题呢？其实是<code>/etc/localtime</code>在作怪，用户只需要将容器内部的localtime改成你想要的时区就行了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">bash-4.1# ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime </div><div class="line">bash-4.1# date</div><div class="line">2017年 09月 20日 星期三 20:54:35 CST</div><div class="line">bash-4.1# sudo su -c date</div><div class="line">2017年 09月 20日 星期三 20:54:39 CST</div><div class="line">bash-4.1#</div></pre></td></tr></table></figure>
<p>So,在使用Dockerfile构建镜像的时候将<code>/usr/share/zoneinfo/Asia/Shanghai</code>强制软连接到<code>/etc/localtime</code>就可以永久修复时区的问题了。</p>
<p>####指定容器的rootfs的大小<br>在使用docker的过程中，会发现cpu和memory可以很随意的动态调整，但是默认的rootfs却是不能随意调整的，默认是10g大小，当然如果对于数据有需求，可以通过挂载voulme进行扩展存储。如果用户执意想要调整rootfs的大小，在docker1.12版本默认提供了两种方式：在启动docker 的时候加载参数<code>--storage-opt dm.basesize=40G</code>用来调整默认容器的rootfs大小；在创建容器的时候使用参数<code>--storage-opt size=70G</code>来设置改容器的rootfs大小。</p>
<p><code>喜讯：在docker最近发布的1.13版本中，支持了磁盘的配额，不过还未测试</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">sh-4.2# docker run -itd --name volume-test --storage-opt size=70G biaoge/centos6.8-jdjr-test-app</div><div class="line">18d47e69802aa84df00182885b256c50ebc56e15d8e6990fc1e187ffe254171e</div><div class="line"></div><div class="line">sh-4.2# docker exec -it volume-test df -H | grep rootfs</div><div class="line">rootfs                 76G  1.5G   74G   2% /</div><div class="line">sh-4.2# docker exec -it test-env df -H | grep rootfs</div><div class="line">rootfs                 11G  1.5G  9.3G  14% /</div></pre></td></tr></table></figure>
<h4 id="快速管理容器和镜像"><a href="#快速管理容器和镜像" class="headerlink" title="快速管理容器和镜像"></a>快速管理容器和镜像</h4><p>在docker中删除容器需要指定容器名或者容器id，但是在容器比较多，并且状态不一的情况下删除容器还是需要走下心的。不过好处是docker ps默认提供了很多好用的功能，可以很方便地管理容器(创建容器的时候如果加上label后更方便哦)。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line">原理：先用docker ps -a -q 输出所有容器的container id(-f 表示过滤参数或者输出格式)，然后作为docker rm 的参数进行批量删除</div><div class="line">输出所有容器的name(利用了Golang语言中的模板语法)：</div><div class="line">sh-4.2# docker ps --format=&apos;&#123;&#123;.Names&#125;&#125;&apos;</div><div class="line">test-env</div><div class="line">test-args</div><div class="line">test-run</div><div class="line">输出所有容器名包含test的容器，并打印容器名</div><div class="line">sh-4.2# docker ps -f name=test --format=&apos;&#123;&#123;.Names&#125;&#125;&apos;</div><div class="line">test-env</div><div class="line">test-args</div><div class="line">test-run</div><div class="line">查看退出状态的容器，并打印容器名</div><div class="line">sh-4.2# docker ps -f status=exited --format=&quot;&#123;&#123;.Names&#125;&#125;&quot;</div><div class="line">thirsty_brahmagupta</div><div class="line">clever_mestorf</div><div class="line">hopeful_morse</div><div class="line">stoic_morse</div><div class="line">elated_williams</div><div class="line">tender_jepsen</div><div class="line">reverent_mirzakhani</div><div class="line"></div><div class="line">删除所有容器：</div><div class="line">sh-4.2# docker rm -f -v $(docker ps -a -q)</div><div class="line">删除/启动所有退出的容器：</div><div class="line">sh-4.2# docker rm/start $(docker ps -qf status=exited)</div><div class="line">删除所有镜像：</div><div class="line">sh-4.2# docker rmi $(docker images -q)</div><div class="line"></div><div class="line">查看悬挂镜像:</div><div class="line">sh-4.1# docker  images -qf dangling=true</div><div class="line"></div><div class="line">只查看镜像或者容器指定的信息(在docker1.10之后才支持的)</div><div class="line"></div><div class="line">只列出镜像的id以及仓库名称：</div><div class="line">sh-4.2# docker images --format &quot;&#123;&#123;.ID&#125;&#125;: &#123;&#123;.Repository&#125;&#125;&quot;</div><div class="line">67591570dd29: centos</div><div class="line">0a18f1c0ead2: rancher/server</div><div class="line"></div><div class="line">只列出容器的相关id,image,status和name</div><div class="line">sh-4.2# docker ps --format &quot;&#123;&#123;.ID&#125;&#125;: &#123;&#123;.Image&#125;&#125; : &#123;&#123;.Status&#125;&#125; : &#123;&#123;.Names&#125;&#125;&quot;</div><div class="line">66b60b72f00e: centos : Up 7 days : pensive_poincare</div><div class="line">或者自己重新定义列,就和原生差不多:</div><div class="line">sh-4.2# docker ps --format &quot;table &#123;&#123;.ID&#125;&#125;\t&#123;&#123;.Image&#125;&#125;\t&#123;&#123;.Status&#125;&#125;\t&#123;&#123;.Names&#125;&#125;&quot;</div><div class="line">CONTAINER ID        IMAGE                                         STATUS              NAMES</div><div class="line">66b60b72f00e        centos                                        Up 7 days           pensive_poincare</div></pre></td></tr></table></figure>
<p><code>注意:</code>其实上面的–format利用的就是go语言中的模版语法，所有容器的组织信息都在结构体中：</p>
<p><code>*formatter.containerContext</code></p>
<h4 id="容器label的使用"><a href="#容器label的使用" class="headerlink" title="容器label的使用"></a>容器label的使用</h4><p>在实际运维过程中，大量的容器可能会一些运维上的挑战，通过使用label，可以很好的将容器分类。label贯穿于docker的整个过程。<br>这个label可以作为你区分业务，区分模板各种区分容器的标识，通过标识，可以将容器更好的进行分组</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">sh-4.2# docker run -itd --name volume-test --storage-opt size=70G --label zone=test biaoge/centos6.8-jdjr-test-app</div><div class="line">c3772397e58e663095c2c0fd8d688b3d41b494097999ec2b6d6b7c509d23a138</div><div class="line">创建容器的时候定义一个label，表示该容器在test这个区域</div><div class="line">使用定义的label进行快速检索容器，并进行下一步操作(比如删除啦，更新啦)</div><div class="line">sh-4.2# docker ps -qf label=zone=test</div><div class="line">c3772397e58e</div><div class="line">sh-4.2# docker ps -f label=zone=test --format=&apos;&#123;&#123;.Names&#125;&#125;&apos;</div><div class="line">volume-test</div></pre></td></tr></table></figure>
<h4 id="快速查看容器的相关配置信息"><a href="#快速查看容器的相关配置信息" class="headerlink" title="快速查看容器的相关配置信息"></a>快速查看容器的相关配置信息</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">查看容器的devicemapper设备：</div><div class="line">sh-4.2# docker inspect -f &apos;&#123;&#123;.GraphDriver.Data.DeviceName&#125;&#125;&apos; nginx </div><div class="line">docker-8:1-67411759-7c9d6d3327b02659c81bcb70bf6a4c7a45df6a589af2a2d42a387dc0e90d4913</div><div class="line">查看容器的PID：</div><div class="line">sh-4.2# docker inspect -f &apos;&#123;&#123;.State.Pid&#125;&#125;&apos; nginx </div><div class="line">27521</div><div class="line">查看容器name：</div><div class="line">sh-4.2# docker inspect -f &apos;&#123;&#123;.Name&#125;&#125;&apos; nginx </div><div class="line">/nginx</div><div class="line">获取容器的ID：</div><div class="line">sh-4.2# docker inspect --format &#123;&#123;.Id&#125;&#125; nginx</div><div class="line">53214bc9cd001f2c548edcce0c42fe51f1a118c08941406d43122a8348055843</div></pre></td></tr></table></figure>
<h4 id="使用alias来预定义常用的命令"><a href="#使用alias来预定义常用的命令" class="headerlink" title="使用alias来预定义常用的命令"></a>使用alias来预定义常用的命令</h4><p>docker管理命令经常需要指定各种参数，通过linux的alias命令将默认的参数预定义起来，可以很方便的进行管理容器。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">sh-4.2# alias dockerrm=&apos;docker rm -f -v&apos;</div><div class="line">sh-4.2# alias dockerexec=&apos;docker exec -it&apos;</div><div class="line">sh-4.2# alias dockerrmimage=&apos;docker rmi&apos;</div><div class="line"></div><div class="line">sh-4.2# dockerrm volume-test</div><div class="line">volume-test</div><div class="line"></div><div class="line">sh-4.2# dockerexec volume-test ls</div><div class="line">bin   dev  export  lib	  media  opt   root  selinux  sys  usr</div><div class="line">boot  etc  home    lib64  mnt	 proc  sbin  srv      tmp  var</div><div class="line">sh-4.2# dockerexec volume-test bash</div><div class="line">bash-4.1#</div></pre></td></tr></table></figure>
<h4 id="使容器随着docker-daemon的启动一同启动"><a href="#使容器随着docker-daemon的启动一同启动" class="headerlink" title="使容器随着docker daemon的启动一同启动"></a>使容器随着docker daemon的启动一同启动</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker run 的时候加参数--restart=always</div></pre></td></tr></table></figure>
<h4 id="如何动态修改容器的内存和cpu限制docker1-10之后才支持的动态调整"><a href="#如何动态修改容器的内存和cpu限制docker1-10之后才支持的动态调整" class="headerlink" title="如何动态修改容器的内存和cpu限制docker1.10之后才支持的动态调整"></a>如何动态修改容器的内存和cpu限制<code>docker1.10之后才支持的动态调整</code></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">sh-4.2# dockerexec test-env cat /sys/fs/cgroup/memory/memory.limit_in_bytes</div><div class="line">9223372036854775807</div><div class="line">sh-4.2# cat /sys/fs/cgroup/memory/memory.limit_in_bytes </div><div class="line">9223372036854775807</div><div class="line">可以看到，默认没有给容器限制内存，它会共享宿主机的所有内存</div><div class="line">动态调整内存为2014M：</div><div class="line">sh-4.2# docker update -m 2014M test-env</div><div class="line">test-env</div><div class="line">sh-4.2# dockerexec test-env cat /sys/fs/cgroup/memory/memory.limit_in_bytes</div><div class="line">2111832064</div></pre></td></tr></table></figure>
<h4 id="docker容器中真实用户的隔离"><a href="#docker容器中真实用户的隔离" class="headerlink" title="docker容器中真实用户的隔离"></a>docker容器中真实用户的隔离</h4><p>注意：默认docker容器内部的用户会继承宿主机的用户id，也就是说容器外部有一个uid为500的用户test，容器内部有一个uid为500的用户admin，容器内部运行的程序如果在宿主机上查看的时候会发现程序的启动用户会是外部宿主机的test用户。<br>这是因为默认情况下容器的 user namespace 并未开启，所以容器内的用户和宿主用户共享 uid 空间。容器内的 uid 为 0 的 root，就被系统视为 uid=0 的宿主 root，因此磁盘读写时，具有宿主 root 同等读写权限。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">开启user namespace：</div><div class="line">启动docker的时候加参数--userns-remap=default</div><div class="line">https://docs.docker.com/engine/reference/commandline/dockerd/#/daemon-user-namespace-options</div></pre></td></tr></table></figure></p>
<h4 id="在docker-container和物理机中双向拷贝文件"><a href="#在docker-container和物理机中双向拷贝文件" class="headerlink" title="在docker container和物理机中双向拷贝文件"></a>在docker container和物理机中双向拷贝文件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">容器内部文件拷贝到宿主机：</div><div class="line">sh-4.2# docker cp jupyter-70002111:/home/70002111/教程-研究功能介绍.ipynb .</div><div class="line">sh-4.2# ls</div><div class="line">Dockerfile  教程-研究功能介绍.ipynb</div><div class="line">宿主机文件拷贝到容器：</div><div class="line">sh-4.2# docker cp Dockerfile jupyter-70002111:/home/70002111/</div><div class="line">sh-4.2# docker exec -it jupyter-70002188 ls </div><div class="line">Dockerfile</div></pre></td></tr></table></figure>
<h4 id="向容器内部程序发送signal"><a href="#向容器内部程序发送signal" class="headerlink" title="向容器内部程序发送signal"></a>向容器内部程序发送signal</h4><p>注意：在给容器进程发送SIGTERM信号时只会发给主进程，也就是容器内 PID 为 1 的进程。至于说主进程启动的那些子进程，完全看主进程是否愿意转发SIGTERM 给子进程了。所以那些把 Docker当做虚拟机用的，主进程跑了个bash，然后exec 进去启动程序的，或者来个&amp;让程序跑后台的情况，应用进程必然无法收到SIGTERM。<br><br>还有一种可能是在Dockerfile中的CMD那行用的是 shell 格式写的命令，而不是 exec 格式。在镜像中使用CMD启动的容器会加一个 sh -c 来去执行，因此使用 shell 格式写 CMD 的时候，PID 为 1 的进程是 sh，而它不转发信号，所以主程序收不到。</p>
<p>所以在写CMD哪行命令的时候，最好按照exec格式去写。</p>
<p><code>划重点: 由于在容器内部是没有init进程的，所以容器的整个生命周期会和容器内部PID为1的进程紧密相连，用户在使用过程中经常会发现容器更新版本之后，业务调用方经常会有一些请求异常，这其实也是因为容器内部的1号进程的设置有关，导致容器在停止时可能直接发送SIGKILL信号，导致容器当前正在处理中的业务也会立即断开连接，这样可能会导致一些业务异常</code></p>
<p>总而言之，向容器内部程序发送合适的信号是非常有必要的，这样可以使你的容器很优雅的退出。<code>docker stop操作会让容器在10s后进行优雅的退出</code></p>
<p><a href="https://segmentfault.com/a/1190000008233992" target="_blank" rel="external">如何优雅的关闭容器</a></p>
<h4 id="容器的cache不释放"><a href="#容器的cache不释放" class="headerlink" title="容器的cache不释放"></a>容器的cache不释放</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ echo 1 &gt; /proc/sys/vm/drop_caches</div></pre></td></tr></table></figure>
<h4 id="桥接网络连入下层网络并使用IPAM-没有NAT-端口映射"><a href="#桥接网络连入下层网络并使用IPAM-没有NAT-端口映射" class="headerlink" title="桥接网络连入下层网络并使用IPAM (没有NAT/端口映射)"></a>桥接网络连入下层网络并使用IPAM (没有NAT/端口映射)</h4><p><code>注意:docker network是1.12版本加进来的，支持了多种网络插件</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">$ docker network create \</div><div class="line">	-d bridge \</div><div class="line">	--subnet=192.168.57.0/24 \</div><div class="line">	--ip-range=192.168.57.32/28 \</div><div class="line">	--gateway=192.168.57.11 \</div><div class="line">	--aux-address DefaultGatewayIPv4=192.168.57.1 \</div><div class="line">	-o com.docker.network.bridge.name=brnet \</div><div class="line">	brnet</div><div class="line">$ brctl addif brnet eth2</div><div class="line">$ docker run --net=brnet -it busybox ifconfig</div><div class="line"></div><div class="line">注意其它主机的 --ip-range 和 --gateway 需要做对应调整。</div><div class="line"></div><div class="line">这种拓扑是，容器内 eth0 连接 brnet 接口，该接口直接通过 eth2 访问交换。</div></pre></td></tr></table></figure>
<h4 id="Docker查看某个容器绑定的cpu内核"><a href="#Docker查看某个容器绑定的cpu内核" class="headerlink" title="Docker查看某个容器绑定的cpu内核"></a>Docker查看某个容器绑定的cpu内核</h4><p><code>容器内部第一个进程编号一般为1</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ docker exec -it container-name taskset -c -p 1 </div><div class="line">pid 1&apos;s current affinity list:0-3</div></pre></td></tr></table></figure>
<h4 id="给docker配置hosts"><a href="#给docker配置hosts" class="headerlink" title="给docker配置hosts"></a>给docker配置hosts</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">$ docker run --add-host biaoge-ops:192.168.0.1 centos cat /etc/hosts</div><div class="line">127.0.0.1	localhost</div><div class="line">::1	localhost ip6-localhost ip6-loopback</div><div class="line">fe00::0	ip6-localnet</div><div class="line">ff00::0	ip6-mcastprefix</div><div class="line">ff02::1	ip6-allnodes</div><div class="line">ff02::2	ip6-allrouters</div><div class="line">192.168.0.1	biaoge-ops</div><div class="line">10.0.0.3	6ff3ea7114b4</div></pre></td></tr></table></figure>
<p><a href="http://www.jianshu.com/p/0231568ab33(" target="_blank" rel="external">原文地址</a><br><a href="https://my.oschina.net/xxbAndy/blog" target="_blank" rel="external">个人博客</a><br>微信公众号：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/2577135-5d2191eacf61c6dc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="wechat.png"></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;在使用docker过程中，我们经常发现管理维护是一个很复杂过程，因为我们在使用docker commands的过程中，我们只会去使用我们认为简单并且熟悉的命令，然而docker本身其实是提供给我们很多便捷且人性化的工具的，如果掌握这些使用技巧，也许你的维护管理工作将会事半功倍，并且给人看起来会很牛逼的样子。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Docker" scheme="http://yoursite.com/categories/Docker/"/>
    
    
      <category term="Docker" scheme="http://yoursite.com/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Docker API for Python</title>
    <link href="http://yoursite.com/2017/10/30/Docker-API-for-Python/"/>
    <id>http://yoursite.com/2017/10/30/Docker-API-for-Python/</id>
    <published>2017-10-30T14:37:34.000Z</published>
    <updated>2017-10-30T14:40:18.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>使用Docker API for Python来更好的管理容器！</p>
</blockquote>
<a id="more"></a>
<p><code>客户端初始化的三种方法</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">import docker</div><div class="line">docker.api()</div><div class="line">docker.APIClient()</div><div class="line">docker.client()</div><div class="line">docker.DockerClient() 其实就是docker.client()的一个子集</div><div class="line">docker.from_env() 其实也是docker.client()的一个子集</div></pre></td></tr></table></figure></p>
<h3 id="一、初始化客户端"><a href="#一、初始化客户端" class="headerlink" title="一、初始化客户端"></a>一、初始化客户端</h3><h4 id="1-Docker客户端的初始化工作"><a href="#1-Docker客户端的初始化工作" class="headerlink" title="1.Docker客户端的初始化工作"></a>1.Docker客户端的初始化工作</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; import docker</div><div class="line">&gt;&gt;&gt; client = docker.APIClient(base_url=&apos;unix://var/run/docker.sock’,version=&apos;1.21&apos;,timeout=5)</div><div class="line">&gt;&gt;&gt; client.version()</div><div class="line">&#123;u&apos;ApiVersion&apos;: u&apos;1.21’,</div><div class="line"> u&apos;Arch&apos;: u&apos;amd64&apos;,</div><div class="line"> u&apos;BuildTime&apos;: u&apos;2016-09-27T23:38:15.810178467+00:00&apos;,</div><div class="line"> u&apos;Experimental&apos;: True,</div><div class="line"> u&apos;GitCommit&apos;: u&apos;45bed2c&apos;,</div><div class="line"> u&apos;GoVersion&apos;: u&apos;go1.6.3&apos;,</div><div class="line"> u&apos;KernelVersion&apos;: u&apos;4.4.22-moby&apos;,</div><div class="line"> u&apos;Os&apos;: u&apos;linux&apos;,</div><div class="line"> u&apos;Version&apos;: u&apos;1.12.2-rc1&apos;&#125;</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">Args:</div><div class="line">   base_url (str): 指定链接路径，可以通过socket或者tcp方式链接</div><div class="line">       ``unix:///var/run/docker.sock`` or ``tcp://127.0.0.1:1234``.</div><div class="line">   version (str): 指定API使用的版本(docker=2.0.0默认的api版本是1.24,最低支持1.21,docker1.9+的api是1.21),因此在使用python的docker模块时一定要注意docker的api以及docker模块的api是否兼容。当然如果设置为 ``auto`` 降回去自动检测server的版本</div><div class="line">   timeout (int): 使用API调用的默认超时时间，默认单位为秒</div><div class="line">   tls (bool or :py:class:`~docker.tls.TLSConfig`): Enable TLS. Pass</div><div class="line">       ``True`` to enable it with default options, or pass a</div><div class="line">       :py:class:`~docker.tls.TLSConfig` object to use custom</div><div class="line">       configuration.</div></pre></td></tr></table></figure>
<p><strong>查看docker引擎当前版本:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">$ sudo docker version</div><div class="line">Client:</div><div class="line"> Version:      1.9.1</div><div class="line"> API version:  1.21</div><div class="line"> Go version:   go1.4.3</div><div class="line"> Git commit:   a34a1d5-dirty</div><div class="line"> Built:        Tue Mar 28 15:39:19 UTC 2017</div><div class="line"> OS/Arch:      linux/amd64</div><div class="line"></div><div class="line">Server:</div><div class="line"> Version:      1.9.1</div><div class="line"> API version:  1.21</div><div class="line"> Go version:   go1.4.3</div><div class="line"> Git commit:   a34a1d5-dirty</div><div class="line"> Built:        Tue Mar 28 15:39:19 UTC 2017</div><div class="line"> OS/Arch:      linux/amd64</div></pre></td></tr></table></figure>
<p><strong>The sdk of docker for python–docker==2.0.0:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">1.丢弃了python2.6的支持</div><div class="line">2.最低支持API版本为1.12(Engine version 1.9.0+)</div><div class="line">3.`docker.Client`被替换成`docker.APIClient`</div><div class="line">4.`docker.from_env`初始化一个docker客户端实例代替了`APIClient `实例 </div><div class="line">5.从`APIClient.start`中移除了HostConfig参数</div><div class="line">6.开始由之前的docker-py模块变为docker</div><div class="line">7.`docker.ssladapter`替换为`docker.transport.ssladapter`</div></pre></td></tr></table></figure>
<p>####2.Docker客户端的具体方法</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">import docker</div><div class="line">C  = docker.DockerClient(base_url=&apos;unix://var/run/docker.sock&apos;,version=&apos;auto&apos;,timeout=10)</div><div class="line"></div><div class="line">##docker相关的方法使用</div><div class="line">使用DockerClient对象，会有以下方法：</div><div class="line">C.api,</div><div class="line">C.containers,</div><div class="line">C.events,</div><div class="line">C.from_env,</div><div class="line">C.images,</div><div class="line">C.info,</div><div class="line">C.login,</div><div class="line">C.networks,</div><div class="line">C.nodes,</div><div class="line">C.ping,</div><div class="line">C.services,</div><div class="line">C.swarm,</div><div class="line">C.version,</div><div class="line">C.volumes,</div><div class="line"></div><div class="line"></div><div class="line">#输出docker的相关信息，相当于docker info</div><div class="line">C.info()</div></pre></td></tr></table></figure>
<h3 id="二、api方法使用示例"><a href="#二、api方法使用示例" class="headerlink" title="二、api方法使用示例"></a>二、api方法使用示例</h3><h4 id="1-login方法定义"><a href="#1-login方法定义" class="headerlink" title="1. login方法定义"></a>1. login方法定义</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">C.login()</div><div class="line">login(*args, **kwargs) method of docker.client.DockerClient instance</div><div class="line">    Authenticate with a registry. Similar to the ``docker login`` command.</div><div class="line">    </div><div class="line">    Args:</div><div class="line">        username (str): The registry username</div><div class="line">        password (str): The plaintext password</div><div class="line">        email (str): The email for the registry account</div><div class="line">        registry (str): URL to the registry.  E.g.</div><div class="line">            ``https://index.docker.io/v1/``</div><div class="line">        reauth (bool): Whether refresh existing authentication on the</div><div class="line">            Docker server.</div><div class="line">        dockercfg_path (str): Use a custom path for the ``.dockercfg`` file</div><div class="line">    (default ``$HOME/.dockercfg``)</div><div class="line">    </div><div class="line">    Returns:返回的错误日志信息</div><div class="line">        (dict): The response from the login request</div><div class="line"></div><div class="line">          Raises:</div><div class="line">        :py:class:`docker.errors.APIError`</div><div class="line">            If the server returns an error.</div><div class="line"></div><div class="line">##使用login方法登录</div><div class="line">C.login(&apos;xxbandy123&apos;,&apos;nslalla&apos;)</div></pre></td></tr></table></figure>
<h4 id="2-images-类定义："><a href="#2-images-类定义：" class="headerlink" title="2.images 类定义："></a>2.images 类定义：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">build方法</div><div class="line">get方法：</div><div class="line">get(self, name)</div><div class="line">    Gets an image.</div><div class="line">    </div><div class="line">    Args:</div><div class="line">        name (str): The name of the image.</div><div class="line">    </div><div class="line">    Returns:</div><div class="line">        (:py:class:`Image`): The image.</div><div class="line">    </div><div class="line">    Raises:</div><div class="line">        :py:class:`docker.errors.ImageNotFound` If the image does not</div><div class="line">        exist.</div><div class="line">        :py:class:`docker.errors.APIError`</div><div class="line">            If the server returns an error.</div><div class="line">list方法：</div><div class="line">   list(self, name=None, all=False, filters=None)</div><div class="line">    List images on the server.</div><div class="line">    </div><div class="line">    Args:</div><div class="line">        name (str): Only show images belonging to the repository ``name``</div><div class="line">        all (bool): Show intermediate image layers. By default, these are</div><div class="line">            filtered out.</div><div class="line">        filters (dict): Filters to be processed on the image list.</div><div class="line">            Available filters:</div><div class="line">            - ``dangling`` (bool)</div><div class="line">            - ``label`` (str): format either ``key`` or ``key=value``</div><div class="line">    </div><div class="line">    Returns:</div><div class="line">        (list of :py:class:`Image`): The images.</div><div class="line">    </div><div class="line">    Raises:</div><div class="line">        :py:class:`docker.errors.APIError`</div><div class="line">            If the server returns an error.</div></pre></td></tr></table></figure>
<p>示例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">查看默认所有的镜像文件，以image-id进行区分</div><div class="line">In [34]: C.images.list()</div><div class="line">Out[34]: </div><div class="line">[&lt;Image: &apos;busybox:latest&apos;&gt;,</div><div class="line"> &lt;Image: &apos;rancher-server:latest&apos;, &apos;rancher/server:latest&apos;&gt;,</div><div class="line"> &lt;Image: &apos;singleuser:latest&apos;&gt;,</div><div class="line"> &lt;Image: &apos;registry:2&apos;&gt;,</div><div class="line"> &lt;Image: &apos;rancher-agent:latest&apos;, &apos;rancher/agent:v1.0.2&apos;&gt;]</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div></pre></td><td class="code"><pre><div class="line">load方法：相当于docker load</div><div class="line"></div><div class="line">pull方法：下载镜像文件</div><div class="line"> pull(self, name, **kwargs)</div><div class="line">    Pull an image of the given name and return it. Similar to the</div><div class="line">    ``docker pull`` command.</div><div class="line">    </div><div class="line">    If you want to get the raw pull output, use the</div><div class="line">    :py:meth:`~docker.api.image.ImageApiMixin.pull` method in the</div><div class="line">    low-level API.</div><div class="line">    </div><div class="line">    Args:</div><div class="line">        repository (str): The repository to pull</div><div class="line">        tag (str): The tag to pull</div><div class="line">        insecure_registry (bool): Use an insecure registry</div><div class="line">        auth_config (dict): Override the credentials that</div><div class="line">            :py:meth:`~docker.client.DockerClient.login` has set for</div><div class="line">            this request. ``auth_config`` should contain the ``username``</div><div class="line">            and ``password`` keys to be valid.</div><div class="line">    </div><div class="line">    Returns:</div><div class="line">        (:py:class:`Image`): The image that has been pulled.</div><div class="line"></div><div class="line">需要注意的是：使用pull的时候，会弱匹配所有的tag标签</div><div class="line"></div><div class="line">push方法：上传镜像文件</div><div class="line"></div><div class="line">push(self, repository, tag=None, **kwargs)</div><div class="line">    Push an image or a repository to the registry. Similar to the ``docker</div><div class="line">    push`` command.</div><div class="line">    </div><div class="line">    Args:</div><div class="line">        repository (str): The repository to push to</div><div class="line">        tag (str): An optional tag to push</div><div class="line">        stream (bool): Stream the output as a blocking generator</div><div class="line">        insecure_registry (bool): Use ``http://`` to connect to the</div><div class="line">            registry</div><div class="line">        auth_config (dict): Override the credentials that</div><div class="line">            :py:meth:`~docker.api.daemon.DaemonApiMixin.login` has set for</div><div class="line">            this request. ``auth_config`` should contain the ``username``</div><div class="line">            and ``password`` keys to be valid.</div><div class="line">    </div><div class="line">    Returns:</div><div class="line">        (generator or str): The output from the server.</div><div class="line">    </div><div class="line">    Raises:</div><div class="line">        :py:class:`docker.errors.APIError`</div><div class="line"></div><div class="line">remove方法：docker rmi </div><div class="line"> remove(self, *args, **kwargs)</div><div class="line">    Remove an image. Similar to the ``docker rmi`` command.</div><div class="line">    </div><div class="line">    Args:</div><div class="line">        image (str): The image to remove</div><div class="line">        force (bool): Force removal of the image</div><div class="line">        noprune (bool): Do not delete untagged parents</div><div class="line"></div><div class="line">search方法：</div><div class="line">search(self, *args, **kwargs)</div><div class="line">    Search for images on Docker Hub. Similar to the ``docker search``</div><div class="line">    command.</div><div class="line">    </div><div class="line">    Args:</div><div class="line">        term (str): A term to search for.</div><div class="line">    </div><div class="line">    Returns:</div><div class="line">        (list of dicts): The response of the search.</div></pre></td></tr></table></figure>
<h4 id="3-docker管理容器相关"><a href="#3-docker管理容器相关" class="headerlink" title="3.docker管理容器相关"></a>3.docker管理容器相关</h4><p>C.containers类，下面有相关的方法：</p>
<ul>
<li>client</li>
<li>create</li>
<li>get</li>
<li>list</li>
<li>model</li>
<li>run …</li>
</ul>
<p>列出当前存活的容器：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">C.containers.list()</div></pre></td></tr></table></figure></p>
<p>列出指定容器：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">C.containers.get(&apos;&apos;)</div></pre></td></tr></table></figure></p>
<p>创建容器：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div></pre></td><td class="code"><pre><div class="line">C.containers.create</div><div class="line">create(image, command=None, **kwargs) method of docker.models.containers.ContainerCollection instance</div><div class="line">    Create a container without starting it. Similar to ``docker create``.</div><div class="line">    </div><div class="line">    Takes the same arguments as :py:meth:`run`, except for ``stdout``,</div><div class="line">    ``stderr``, and ``remove``.</div><div class="line">    </div><div class="line">    Returns:</div><div class="line">        A :py:class:`Container` object.</div><div class="line">    </div><div class="line">    Raises:</div><div class="line">        :py:class:`docker.errors.ImageNotFound`</div><div class="line">            If the specified image does not exist.</div><div class="line">        :py:class:`docker.errors.APIError`</div><div class="line">            If the server returns an error.</div><div class="line"></div><div class="line"></div><div class="line">run一个容器：类似于命令行的docker run方法</div><div class="line">run(image, command=None, stdout=True, stderr=False, remove=False, **kwargs) method of docker.models.containers.ContainerCollection instance</div><div class="line">    Run a container. By default, it will wait for the container to finish</div><div class="line">    and return its logs, similar to ``docker run``.</div><div class="line">    </div><div class="line">    如果&apos;detach&apos;参数设置为&apos;True&apos;,他将立即返回一个Container对象，类似于&apos;docker run -d&apos;    </div><div class="line">    实例:</div><div class="line">        运行一个容器并获取输出。</div><div class="line">    </div><div class="line">        &gt;&gt;&gt; import docker</div><div class="line">        &gt;&gt;&gt; client = docker.from_env()</div><div class="line">        &gt;&gt;&gt; client.containers.run(&apos;alpine&apos;, &apos;echo hello world&apos;)</div><div class="line">        b&apos;hello world\n&apos;</div><div class="line">    </div><div class="line">        后台运行一个容器:</div><div class="line">        &gt;&gt;&gt; container = client.containers.run(&apos;bfirsh/reticulate-splines&apos;,</div><div class="line">                                              detach=True)</div><div class="line">        获取该容器的日志信息</div><div class="line">        &gt;&gt;&gt; container.logs()</div><div class="line">        &apos;Reticulating spline 1...\nReticulating spline 2...\n&apos;</div><div class="line"></div><div class="line">   参数介绍:</div><div class="line">        image (str): run一个容器所需要的镜像(str类型)</div><div class="line">        command (str or list): 容器启动默认运行的命令(字符串或者列表类型).</div><div class="line"></div><div class="line">        blkio_weight_device: 设置设备Block IO 权重：``[&#123;&quot;Path&quot;: &quot;device_path&quot;, &quot;Weight&quot;: weight&#125;]``.</div><div class="line">        blkio_weight: 设置block IO 的权重 范围10-1000.</div><div class="line">        cap_add (list of str): 增加内核特性 比如：``[&quot;SYS_ADMIN&quot;, &quot;MKNOD&quot;]``.</div><div class="line">        cap_drop (list of str): 删除内核特性</div><div class="line">        cpu_group (int): 每颗cpu的长度</div><div class="line">        cpu_period (int): 容器在每一个cpu的时间周期内可以得到多少的的cpu时间(ms)</div><div class="line">        cpu_shares (int): 共享cpu权重CPU 相对权重</div><div class="line">        cpuset_cpus (str): 绑定cpu的执行 (``0-3``,``0,1``).</div><div class="line"></div><div class="line">        detach (bool): 后台运行一个容器，布尔类型值.相当于docker run -d选项</div><div class="line"></div><div class="line">        device_read_bps: 从一个设备上限制读速率(bytes/s) `[&#123;&quot;Path&quot;: &quot;device_path&quot;, &quot;Rate&quot;: rate&#125;]`</div><div class="line">        device_read_iops: 从一个设备中限制读取速率(IO/s)</div><div class="line">        device_write_bps: 从一个设备上限制写速率(bytes/s)</div><div class="line">        device_write_iops: 从一个设备中限制读取速率(IO/s)</div><div class="line">        devices (list): 映射主机的设备到容器中``&lt;path_on_host&gt;:&lt;path_in_container&gt;:&lt;cgroup_permissions&gt;``.</div><div class="line">        dns (list): 配置当前的dns-server</div><div class="line">        dns_opt (list): 添加额外的dns参数选项到容器内部，比如resolv.conf文件</div><div class="line">        dns_search (list): 设置dns搜索域</div><div class="line">        domainname (str or list): 设置当前dns搜索域名</div><div class="line"></div><div class="line">        entrypoint (str or list): 为容器设置入口,覆盖镜像中的entrypoint</div><div class="line"></div><div class="line">        environment (dict or list): 内部环境变量[&quot;SOMEVARIABLE=xxx&quot;]``</div><div class="line">        extra_hosts (dict): 在容器内部添加额外的主机名解析(本地hosts文件)</div><div class="line">        group_add (list): 设置容器内部进程运行时额外的组名（gid）</div><div class="line"></div><div class="line">        hostname (str): 容器设置额外的主机名.相当于docker run -h/--hostname 选项</div><div class="line"></div><div class="line">        ipc_mode (str): 为容器设置ipc模式</div><div class="line">        isolation (str): 隔离技术的使用Default: `None`.</div><div class="line">        labels (dict or list): 一个k/v类型的标签存储``&#123;&quot;label1&quot;: &quot;value1&quot;, &quot;label2&quot;: &quot;value2&quot;&#125;``)或一个列表类型的k/v存储``[&quot;label1&quot;, &quot;label2&quot;]``</div><div class="line">        links (dict or list of tuples): 为容器映射一个别名``(name, alias)`` </div><div class="line">        log_config (dict): 容器的日志配置。</div><div class="line">            keys:</div><div class="line">            - ``type`` The logging driver name.</div><div class="line">            - ``config`` A dictionary of configuration for the logging</div><div class="line">              driver.</div><div class="line">        mac_address (str): 绑定mac地址.</div><div class="line"></div><div class="line">        mem_limit (float or str): 内存限制，允许浮点型数据或单位区分的字符串(``100000b``, ``1000k``, ``128m``, ``1g``). 如果一个字符串没有指定单位，默认会使用字节(bytes)</div><div class="line">        mem_limit (str or int): 容器可以使用的最大内存数量(e.g. ``1G``).</div><div class="line"></div><div class="line">        mem_swappiness (int): 调整容器内存的swappiness行为状态，允许的数值为0-100 </div><div class="line">        memswap_limit (str or int): 最大内存限制，容器可用的内存为(memory+swap)</div><div class="line">        networks (list): 设置连接到该容器网络的名称</div><div class="line">        name (str): 为容器设置名字</div><div class="line">        network_disabled (bool): 禁用容器网络</div><div class="line">        network_mode (str): 网络模式 相当于docker run --net=&apos;none&apos;</div><div class="line">    </div><div class="line">            - ``bridge`` 默认使用桥接模式</div><div class="line">            - ``none`` 无网络模式</div><div class="line">            - ``container:&lt;name|id&gt;`` 重用另外一个容器的网络</div><div class="line">            - ``host`` 使用本机的网络栈</div><div class="line"></div><div class="line"></div><div class="line">        oom_kill_disable (bool): 是否启用OOM</div><div class="line">        oom_score_adj (int): 一个整数，以调整OOM的整体性能.</div><div class="line">        pid_mode (str): pid模式，如果设置为&apos;host&apos;,在容器内部将会使用宿主机的host pid</div><div class="line">        pids_limit (int): 调整容器的pid的限制。&apos;-1&apos;表示不限制</div><div class="line"></div><div class="line">        ports (dict): 为容器内部绑定端口 相当于docker run -p </div><div class="line">    		实例：</div><div class="line">              ``&#123;&apos;2222/tcp&apos;: 3333&#125;`` 暴露容器内部的2222端口到本机的3333端</div><div class="line">              ``&#123;&apos;2222/tcp&apos;: None&#125;`` 将容器内部的2222随机映射到本机</div><div class="line">              ``&#123;&apos;1111/tcp&apos;: (&apos;127.0.0.1&apos;, 1111)&#125;``.</div><div class="line">              ``&#123;&apos;1111/tcp&apos;: [1234, 4567]&#125;`` 绑定多个端口</div><div class="line"></div><div class="line"></div><div class="line">		privileged (bool): 给容器额外的特权</div><div class="line"></div><div class="line">        publish_all_ports (bool): 开放所有的端口到本机上 相当于docker run -P </div><div class="line"></div><div class="line">        read_only (bool): 以只读方式挂载容器的根文件系统</div><div class="line">        remove (bool): 当容器退出的时候删除，默认是&apos;False&apos;</div><div class="line">        restart_policy (dict): 当容器退出时重启容器</div><div class="line">            配置参数如下：</div><div class="line">            - ``Name`` One of ``on-failure``, or ``always``.</div><div class="line">            - ``MaximumRetryCount`` 容器失败多少次后进行重启</div><div class="line">            实例:</div><div class="line">            ``&#123;&quot;Name&quot;: &quot;on-failure&quot;, &quot;MaximumRetryCount&quot;: 5&#125;``</div><div class="line">    </div><div class="line">        security_opt (list): 设置安全标签，类似于selinux</div><div class="line">        shm_size (str or int): /dev/shm 的大小(e.g. ``1G``).</div><div class="line"></div><div class="line">        stdin_open (bool): 保持 ``STDIN`` 打开即使没有attach到容器内部相当于docker run -i</div><div class="line"></div><div class="line">        stdout (bool): 当detach=False的时候，从&apos;STDOUT&apos;返回日志。默认为True</div><div class="line">        stdout (bool): 当detach=False的时候，从&apos;STDERR&apos;返回日志，默认为False</div><div class="line">        stop_signal (str): 设置用于停止容器的信号。(e.g. ``SIGINT``).</div><div class="line">        sysctls (dict): 容器内部设置内核参数</div><div class="line">        tmpfs (dict): 挂载临时文件系统 </div><div class="line">                        .. code-block:: python</div><div class="line">    </div><div class="line">                &#123;</div><div class="line">                    &apos;/mnt/vol2&apos;: &apos;&apos;,</div><div class="line">                    &apos;/mnt/vol1&apos;: &apos;size=3G,uid=1000&apos;</div><div class="line">                &#125;</div><div class="line">    </div><div class="line">        tty (bool): 分配一个tty 相当于docker run -t</div><div class="line"></div><div class="line">        ulimits (list): 在容器内部设置ulimits值，一个字典类型的列表</div><div class="line">        user (str or int): 设置容器启动的用户名以及id</div><div class="line"></div><div class="line">        userns_mode (str): 为容器设置用户的命名空间模式，当用户的namespace的remapping参数被启用的时候，支持参数有&apos;host&apos;</div><div class="line">            values are: ``host``</div><div class="line">        volume_driver (str): 数据卷挂载驱动名</div><div class="line">        volumes (dict or list): 一个字典配置，将外部数据卷挂载到容器内部，key是主机或者数据卷的名字，value是带有key的字典：</div><div class="line">        		实例：</div><div class="line">                &#123;&apos;/home/user1/&apos;: &#123;&apos;bind&apos;: &apos;/mnt/vol2&apos;, &apos;mode&apos;: &apos;rw&apos;&#125;,</div><div class="line">                 &apos;/var/www&apos;: &#123;&apos;bind&apos;: &apos;/mnt/vol1&apos;, &apos;mode&apos;: &apos;ro&apos;&#125;&#125;</div><div class="line">    </div><div class="line">        volumes_from (list): 获取容器名或者id标识。</div><div class="line">        working_dir (str): 容器默认的工作目录</div><div class="line">    </div><div class="line">    返回参数:</div><div class="line">        容器的日志，包含 ``STDOUT``, ``STDERR``</div><div class="line">        If ``detach`` is ``True``, a :py:class:`Container` object is</div><div class="line">        returned instead.</div><div class="line">    </div><div class="line">    异常信息:</div><div class="line">    	如果容器以非0状态退出，或者`detach`参数为`False`</div><div class="line">        :py:class:`docker.errors.ContainerError`</div><div class="line">        如果指定的镜像不存在</div><div class="line">        :py:class:`docker.errors.ImageNotFound`</div><div class="line">        如果是服务返回一个错误</div><div class="line">        :py:class:`docker.errors.APIError`</div><div class="line">            If the server returns an error.</div></pre></td></tr></table></figure>
<p>示例：<br>一个完整的创建容器的例子：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">Command line:</div><div class="line">$ docker run -itd -P --cpuset_cpus=&apos;0,1&apos; --cpu_shares=2 --cpu_period=10000 --hostname=xxbandy --mem_limit=512m --net=none --oom_kill_disable=True -P -u admin busybox /bin/sh</div><div class="line"></div><div class="line">Python API:</div><div class="line">c1 = C.containers.run(&apos;busybox&apos;,command=&apos;/bin/sh&apos;,name=&apos;xxb-test&apos;,detach=True,tty=True,stdin_open=True,cpuset_cpus=&apos;0,1&apos;,cpu_shares=2,cpu_period=10000,hostname=&apos;xxbandy&apos;,mem_limit=&apos;512m&apos;,network_mode=&apos;none&apos;,oom_kill_disable=True,publish_all_ports=True,user=&apos;root&apos;)</div><div class="line"></div><div class="line">查看容器相关信息：</div><div class="line">容器id，64位的字符</div><div class="line">In [20]: c1.id</div><div class="line">Out[20]: &apos;499db0824206d61d09db2f36c70aa84bdb1a4b6d508b001a618d2010a23fea7e&apos;</div><div class="line"></div><div class="line"></div><div class="line">c1.logs </div><div class="line">c1.name      获取容器名信息</div><div class="line">c1.reload</div><div class="line">c1.remove    删除容器信息，相当于docker rm 参数：c1.remove(v=True,link=True,force=True)</div><div class="line">c2.rename	 重命名容器名，相当于docker renmame oldname newname</div><div class="line">c1.resize	 设置tty session信息</div><div class="line">c1.restart   重启容器信息</div><div class="line">c1.start     启动容器信息</div><div class="line">c1.stats     容器状态</div><div class="line"></div><div class="line">c1.update    动态调整容器内部信息（blkio_weight，cpu_period，cpu_quota，cpu_shares，cpuset_cpus，cpuset_mems，mem_limit，mem_reservation）</div><div class="line">    Args:</div><div class="line">        blkio_weight (int): 块IO权重比例（10-100）</div><div class="line">        cpu_period (int): 限制cpu公平调度周期</div><div class="line">        cpu_quota (int): 限制cpu公平调度配额</div><div class="line">        cpu_shares (int): 设置cpu共享权重</div><div class="line">        cpuset_cpus (str): 指定cpu执行(0-3, 0,1)</div><div class="line">        cpuset_mems (str): 指定cpu内存的执行(0-3, 0,1)</div><div class="line">        mem_limit (int or str): 内存限制</div><div class="line">        mem_reservation (int or str): 内存软限制</div><div class="line">        memswap_limit (int or str): swap限制总的可使用内存限制(memory + swap)，-1表示关闭swap</div><div class="line">        kernel_memory (int or str): 内核内存限制</div><div class="line">        restart_policy (dict): 重启策略</div></pre></td></tr></table></figure>
<p><code>注意:</code>update方法在docker1.10之后才增加了改功能</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">查看容器相关信息：</div><div class="line">容器id，64位的字符</div><div class="line">In [20]: c1.id</div><div class="line">Out[20]: &apos;499db0824206d61d09db2f36c70aa84bdb1a4b6d508b001a618d2010a23fea7e&apos;</div><div class="line"></div><div class="line">可以在/sys/fs/cgroup/memory/docker目录下面查看到每个容器的相关cgroup配置信息。</div><div class="line">查看内存信息：</div><div class="line"># grep hierarchical memory.stat     分别显示容器的内存限制和swap限制</div><div class="line">hierarchical_memory_limit 536870912</div><div class="line">hierarchical_memsw_limit 1073741824</div><div class="line"></div><div class="line">#cat memory.limit_in_bytes</div><div class="line">536870912</div><div class="line"></div><div class="line">可以在/sys/fs/cgroup/cpuset/docker目录下面查看到容器cpu的相关配置</div><div class="line"># cat cpuset.cpus       显示当前绑定的cpu信息</div><div class="line">0-1</div><div class="line">使用docker update动态调整内存信息:</div><div class="line">docker update -m 1024M xuxuebiao-test</div><div class="line"></div><div class="line"># cat memory.limit_in_bytes </div><div class="line">1073741824</div><div class="line"># grep hierarchical_memory_limit memory.stat </div><div class="line">hierarchical_memory_limit 1073741824</div></pre></td></tr></table></figure>
<p>个人博客：<a href="https://my.oschina.net/xxbAndy/blog" target="_blank" rel="external">https://my.oschina.net/xxbAndy/blog</a><br>微信公众号：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/2577135-5d2191eacf61c6dc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="wechat.png"></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;使用Docker API for Python来更好的管理容器！&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="http://yoursite.com/tags/Docker/"/>
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>GPU环境下玩转Docker(三)</title>
    <link href="http://yoursite.com/2017/10/30/GPU%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%8E%A9%E8%BD%ACDocker-%E4%B8%89/"/>
    <id>http://yoursite.com/2017/10/30/GPU环境下玩转Docker-三/</id>
    <published>2017-10-30T14:08:39.000Z</published>
    <updated>2017-10-30T14:32:06.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>前言: 在前面两个章节中已经介绍了如何构建GPU的基础环境以及使用Docker方式来优雅的运行GPU应用，单纯的使用Docker这种方式是无法满足大规模的应用调度和管理的，对于集群调度以及容器化管理方面，我们也采用了业界比较知名的容器编排调度管理工具Kubernetes，本篇文章简单介绍GPU业务容器在Kubernetes上的运行。</p>
</blockquote>
<a id="more"></a>
<p><a href="https://xxbandy.github.io/2017/10/26/GPU%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%8E%A9%E8%BD%ACDocker-%E4%B8%80/" target="_blank" rel="external">GPU环境下玩转Docker(一)</a></p>
<p><a href="https://xxbandy.github.io/2017/10/26/GPU%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%8E%A9%E8%BD%ACDocker-%E4%BA%8C/" target="_blank" rel="external">GPU环境下玩转Docker(二)</a></p>
<h3 id="使用Kubernetes调度GPU容器"><a href="#使用Kubernetes调度GPU容器" class="headerlink" title="使用Kubernetes调度GPU容器"></a>使用Kubernetes调度GPU容器</h3><h4 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a>1. 准备工作</h4><p>k8s当前已经支持GPU的资源调度了，详情可查看中文文档：<a href="https://k8smeetup.github.io/docs/tasks/manage-gpus/scheduling-gpus/" target="_blank" rel="external">k8s调度GPU</a>。<br>这里介绍一个简单的实例。</p>
<p><code>注意：官方网站中也提到，当前k8s调度GPU也还是处于实验性阶段，在测试K8S调度GPU之前需要做以下相关工作。</code></p>
<ul>
<li>Kubernetes 节点必须预先安装好 NVIDIA 驱动，否则，Kubelet 将检测不到可用的GPU信息；如果节点的 Capacity 属性中没有出现 NIVIDA GPU 的数量，有可能是驱动没有安装或者安装失败，请尝试重新安装</li>
<li><p>在整个 Kubernetes 系统中，feature-gates 里面特定的 alpha 特性参数 Accelerators 必须设置为 true：–feature-gates=”Accelerators=true”</p>
</li>
<li><p>Kuberntes 节点必须使用 docker 引擎作为容器的运行引擎</p>
</li>
</ul>
<p>以上工作完成后，节点会自动发现主机上的NVIDIA GPU机器，并将其作为可调度资源暴露。</p>
<p><code>注意1：为了防止错误调度，需要给GPU机器去做额外的标签</code><br><code>注意2：kubelet程序在启动时必须加载--allow-privileged=true参数，以对所有的GPU容器设置特权模式来识别宿主机资源</code></p>
<p><strong>kubelet启动参数</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line"># cat  /usr/lib/systemd/system/kubelet.service | grep -v ^#</div><div class="line">[Unit]</div><div class="line">Description=Kubernetes Kubelet Server</div><div class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</div><div class="line">After=docker.service</div><div class="line">Requires=docker.service</div><div class="line"></div><div class="line">[Service]</div><div class="line">WorkingDirectory=/export/lib/kubelet</div><div class="line">EnvironmentFile=-/export/kubernetes/config</div><div class="line">EnvironmentFile=-/export/kubernetes/kubelet</div><div class="line">ExecStart=/usr/bin/kubelet \</div><div class="line">            $KUBE_LOGTOSTDERR \</div><div class="line">            $KUBE_LOG_LEVEL \</div><div class="line">            $KUBELET_API_SERVER \</div><div class="line">            $KUBELET_ADDRESS \</div><div class="line">            $KUBELET_PORT \</div><div class="line">            $KUBELET_HOSTNAME \</div><div class="line">            $KUBE_ALLOW_PRIV \</div><div class="line">            $KUBELET_POD_INFRA_CONTAINER \</div><div class="line">            $KUBELET_ARGS \</div><div class="line">Restart=on-failure</div><div class="line"></div><div class="line"></div><div class="line"># cat  /export/kubernetes/kubelet | grep -v ^#</div><div class="line">KUBELET_ADDRESS=&quot;--address=10.0.0.1&quot;</div><div class="line">KUBELET_HOSTNAME=&quot;--hostname-override=10.0.0.1&quot;</div><div class="line">KUBELET_POD_INFRA_CONTAINER=&quot;--pod-infra-container-image=idockerhub.xxb.com/k8s/pause&quot;</div><div class="line">KUBELET_ARGS=&quot;--cgroup-driver=cgroupfs \</div><div class="line">                --cluster-dns=10.254.0.2 \</div><div class="line">                --experimental-bootstrap-kubeconfig=/export/kubernetes/bootstrap.kubeconfig \</div><div class="line">                --kubeconfig=/export/kubernetes/kubelet.kubeconfig \</div><div class="line">                --require-kubeconfig \</div><div class="line">                --cert-dir=/export/kubernetes/ssl \</div><div class="line">                --cluster-domain=cluster.local. \</div><div class="line">                --hairpin-mode promiscuous-bridge \</div><div class="line">                --serialize-image-pulls=false \</div><div class="line">                --feature-gates=&apos;Accelerators=true&apos;&quot;</div><div class="line"></div><div class="line"># cat  /export/kubernetes/config | grep -v ^#</div><div class="line">KUBE_LOGTOSTDERR=&quot;--logtostderr=true&quot;</div><div class="line"></div><div class="line">KUBE_LOG_LEVEL=&quot;--v=0&quot;</div><div class="line"></div><div class="line">KUBE_ALLOW_PRIV=&quot;--allow-privileged=true&quot;</div><div class="line"></div><div class="line">KUBE_MASTER=&quot;--master=http://10.0.0.2:8080&quot;</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">#/usr/bin/kubelet --logtostderr=true --v=0 --address=10.0.0.1 --hostname-override=10.0.0.1 --allow-privileged=true --pod-infra-container-image=idockerhub.xxb.com/k8s/pause --cgroup-driver=cgroupfs --cluster-dns=10.254.0.2 --experimental-bootstrap-kubeconfig=/export/kubernetes/bootstrap.kubeconfig --kubeconfig=/export/kubernetes/kubelet.kubeconfig --require-kubeconfig --cert-dir=/export/kubernetes/ssl --cluster-domain=cluster.local. --hairpin-mode promiscuous-bridge --serialize-image-pulls=false --feature-gates=Accelerators=true Restart=on-failure</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"># /usr/local/bin/kubectl -s http://10.0.0.2:8080 label nodes 10.0.0.1 type=gpu</div><div class="line"></div><div class="line"># /usr/local/bin/kubectl -s http://10.0.0.2:8080 get nodes  --show-labels</div><div class="line">NAME             STATUS    AGE       VERSION   LABELS</div><div class="line">10.0.0.2     Ready     2d        v1.6.2    beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=10.0.0.2</div><div class="line">10.0.0.1   Ready     4h        v1.6.2    beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=10.0.0.1,type=gpu</div><div class="line"></div><div class="line"></div><div class="line"># /usr/local/bin/kubectl -s http://10.0.0.2:8080 get node -l type=gpu</div><div class="line">NAME             STATUS    AGE       VERSION</div><div class="line">10.0.0.1   Ready     4h        v1.6.2</div></pre></td></tr></table></figure>
<h4 id="2-测试用例"><a href="#2-测试用例" class="headerlink" title="2. 测试用例"></a>2. 测试用例</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line">apiVersion: extensions/v1beta1</div><div class="line">kind: Deployment</div><div class="line">metadata:</div><div class="line">  name: test-gpu</div><div class="line">spec:</div><div class="line">  replicas: 1</div><div class="line">  template:</div><div class="line">    metadata:</div><div class="line">      labels:</div><div class="line">        name: test-gpu</div><div class="line">    spec:</div><div class="line">      containers:</div><div class="line">      - name: test-gpu</div><div class="line">        image: idockerhub.xxb.com/k8s/tensorflow/tensorflow:latest-gpu</div><div class="line">        ports:</div><div class="line">        - containerPort: 8888</div><div class="line">        resources:</div><div class="line">          limits:</div><div class="line">            alpha.kubernetes.io/nvidia-gpu: 2</div><div class="line">        volumeMounts:</div><div class="line">            - mountPath: /usr/local/nvidia</div><div class="line">              name: nvidia-driver</div><div class="line">            - mountPath: /dev/nvidia0</div><div class="line">              name: nvidia0</div><div class="line">            - mountPath: /dev/nvidia-uvm</div><div class="line">              name: nvidia-uvm</div><div class="line">            - mountPath: /dev/nvidia-uvm-tools</div><div class="line">              name: nvidia-uvm-tools</div><div class="line">            - mountPath: /dev/nvidiactl</div><div class="line">              name: nvidiactl</div><div class="line">      volumes:</div><div class="line">        - name: nvidia-driver</div><div class="line">          hostPath:</div><div class="line">            path: /var/lib/nvidia-docker/volumes/nvidia_driver/375.39</div><div class="line">        - name: nvidia0</div><div class="line">          hostPath:</div><div class="line">            path: /dev/nvidia0</div><div class="line">        - name: nvidia-uvm</div><div class="line">          hostPath:</div><div class="line">            path: /dev/nvidia-uvm</div><div class="line">        - name: nvidia-uvm-tools</div><div class="line">          hostPath:</div><div class="line">            path: /dev/nvidia-uvm-tools</div><div class="line">        - name: nvidiactl</div><div class="line">          hostPath:</div><div class="line">            path: /dev/nvidiactl</div></pre></td></tr></table></figure>
<p><code>注意1：k8s调度gpudocker容器需要和业务方进行强关联，所以对于cuda,cudnn,nvidia-docker的版本要求是非常高的。</code><br><code>注意2：k8s调度的gpu其实是独享的，也就是上面分配了2个gpu设备，那么该宿主机上将最多只能创建2个卡的gpu容器，否则会因为资源不够而调度失败。</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"># ll /var/lib/nvidia-docker/volumes/nvidia_driver/</div><div class="line">total 0</div><div class="line">drwxr-xr-x 5 nvidia-docker nvidia-docker 38 Oct 18 21:38 375.39</div><div class="line"></div><div class="line"></div><div class="line"># docker ps</div><div class="line">CONTAINER ID        IMAGE                                                                                                                    COMMAND                  CREATED             STATUS              PORTS                                              NAMES</div><div class="line">f3a3f8dd30ca        idockerhub.xxb.com/jdjr/tensorflow-gpu@sha256:7844f390a9d5ff369c7756a52ca65dae095087c736935e9310e12c7caa7c73dd            &quot;/run_jupyter.sh --al&quot;   2 days ago          Up 2 days                                                              k8s_test-gpu_test-gpu-1430106381-9n8hb_default_97177dcf-b7da-11e7-b982-ecf4bbc19ea8_0</div><div class="line">7650dce5a686        idockerhub.xxb.com/k8s/pause                                                                                              &quot;/pod&quot;                   2 days ago          Up 2 days                                                              k8s_POD_test-gpu-1430106381-9n8hb_default_97177dcf-b7da-11e7-b982-ecf4bbc19ea8_0</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"># 尝试创建一个4卡的gpu设备的容器</div><div class="line"># docker exec -it 0cce1f2a59dd ls -la /dev/nvidia*</div><div class="line">crw-rw-rw- 1 root root 244,   0 Jul 19 05:14 /dev/nvidia-uvm</div><div class="line">crw-rw-rw- 1 root root 244,   1 Jul 19 05:14 /dev/nvidia-uvm-tools</div><div class="line">crw-rw-rw- 1 root root 195,   0 Jun 20 02:54 /dev/nvidia0</div><div class="line">crw-rw-rw- 1 root root 195,   1 Oct 23 10:06 /dev/nvidia1</div><div class="line">crw-rw-rw- 1 root root 195,   2 Oct 23 10:06 /dev/nvidia2</div><div class="line">crw-rw-rw- 1 root root 195,   3 Oct 23 10:06 /dev/nvidia3</div><div class="line">crw-rw-rw- 1 root root 195, 255 Jun 20 02:54 /dev/nvidiactl</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">尝试运算服务后的结果：</div><div class="line">2017-10-23 10:14:25.172617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: Tesla M40 24GB, pci bus id: 0000:06:00.0)</div></pre></td></tr></table></figure>
<p>通过上述测试用例，就可以跑通官方tensorflow gpu镜像。</p>
<p><code>NOTES:</code></p>
<blockquote>
<p>GPUs 只能通过limits选项指定<br>GPUs 是严格隔离的，不同容器之间不能共享<br>每个容器可以请求一个或者多个GPUS<br>GPUs 只能正整数级请求<br>使用K8S调度GPU容器必须开启privileged模式(识别宿主机设备)</p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;前言: 在前面两个章节中已经介绍了如何构建GPU的基础环境以及使用Docker方式来优雅的运行GPU应用，单纯的使用Docker这种方式是无法满足大规模的应用调度和管理的，对于集群调度以及容器化管理方面，我们也采用了业界比较知名的容器编排调度管理工具Kubernetes，本篇文章简单介绍GPU业务容器在Kubernetes上的运行。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Docker" scheme="http://yoursite.com/categories/Docker/"/>
    
    
      <category term="Docker" scheme="http://yoursite.com/tags/Docker/"/>
    
      <category term="GPU" scheme="http://yoursite.com/tags/GPU/"/>
    
      <category term="NVIDIA" scheme="http://yoursite.com/tags/NVIDIA/"/>
    
  </entry>
  
  <entry>
    <title>Manager-your-GPUs.md</title>
    <link href="http://yoursite.com/2017/10/30/Manager-your-GPUs/"/>
    <id>http://yoursite.com/2017/10/30/Manager-your-GPUs/</id>
    <published>2017-10-30T14:03:27.000Z</published>
    <updated>2017-10-30T14:07:30.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="使用nvidia-smi管理你的GPU卡"><a href="#使用nvidia-smi管理你的GPU卡" class="headerlink" title="使用nvidia-smi管理你的GPU卡"></a>使用nvidia-smi管理你的GPU卡</h2><p><code>nvidia-smi</code>命令是NVIDIA系统管理接口，之前提到使用<code>nvidia-docker</code>实际上底层也是调用的该接口。该接口可以查看到当前主机上的相关GPU设备，任务以及当前状态等信息，熟练使用该接口能够更好的管理好GPU系统资源。</p>
<a id="more"></a>
<h3 id="开启持久模式"><a href="#开启持久模式" class="headerlink" title="开启持久模式"></a>开启持久模式</h3><p>在Linux上，你需要将GPUs设置为持久模式<code>persistence mode</code>来保证你的<code>NVIDIA</code>驱动即使没有应用正在运行也是出于加载状态的。这个在你有一些短生命周期的job类型应用运行时是非常有用的。持久模式比较耗电，但是它会防止每次启动GPU应用程序时发生的相当长的延迟。当然如果你使用设定了时钟频率或功率限制的GPUs的话(当驱动不加载的话，这些设置会丢失)，持久模式将是非常有必要的。通过如下命令设置持久模式：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">nvidia-smi -pm 1</div></pre></td></tr></table></figure></p>
<p>在Windows上，改接口不支持设置持久模式，但是可以设置为<code>TCC</code>模式。</p>
<h3 id="查看GPU状态"><a href="#查看GPU状态" class="headerlink" title="查看GPU状态"></a>查看GPU状态</h3><p>1.GPU设备概要信息<br>由以下输出可以看到驱动版本为：<code>375.39</code>,以及GPU基本信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">sh-4.2# nvidia-smi</div><div class="line">Wed Oct 18 11:58:03 2017</div><div class="line">+-----------------------------------------------------------------------------+</div><div class="line">| NVIDIA-SMI 375.39                 Driver Version: 375.39                    |</div><div class="line">|-------------------------------+----------------------+----------------------+</div><div class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</div><div class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</div><div class="line">|===============================+======================+======================|</div><div class="line">|   0  Tesla M40 24GB      On   | 0000:04:00.0     Off |                    0 |</div><div class="line">| N/A   23C    P8    17W / 250W |      0MiB / 22939MiB |      0%      Default |</div><div class="line">+-------------------------------+----------------------+----------------------+</div><div class="line">|   1  Tesla M40           On   | 0000:05:00.0     Off |                    0 |</div><div class="line">| N/A   26C    P8    17W / 250W |      0MiB / 11443MiB |      0%      Default |</div><div class="line">+-------------------------------+----------------------+----------------------+</div><div class="line">|   2  Tesla M40 24GB      On   | 0000:06:00.0     Off |                    0 |</div><div class="line">| N/A   22C    P8    17W / 250W |      0MiB / 22939MiB |      0%      Default |</div><div class="line">+-------------------------------+----------------------+----------------------+</div><div class="line">|   3  Tesla M40           On   | 0000:07:00.0     Off |                    0 |</div><div class="line">| N/A   23C    P8    16W / 250W |      0MiB / 11443MiB |      0%      Default |</div><div class="line">+-------------------------------+----------------------+----------------------+</div><div class="line"></div><div class="line">+-----------------------------------------------------------------------------+</div><div class="line">| Processes:                                                       GPU Memory |</div><div class="line">|  GPU       PID  Type  Process name                               Usage      |</div><div class="line">|=============================================================================|</div><div class="line">|  No running processes found                                                 |</div><div class="line">+-----------------------------------------------------------------------------+</div><div class="line"></div><div class="line"># Temp 标识GPU设备的温度</div><div class="line"># Memory-Usage 表示内存使用率</div><div class="line"># GPU-Util 表示GPU使用率</div></pre></td></tr></table></figure></p>
<p>2.查看当前系统可用的GPU设备列表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ nvidia-smi -L</div><div class="line">GPU 0: Tesla M40 24GB (UUID: GPU-eb4e4871-504d-feb7-ba59-xxxxxxxxxx)</div><div class="line">GPU 1: Tesla M40 (UUID: GPU-6c2cb0c9-acba-1dab-6525-xxxxxxxxxx)</div><div class="line">GPU 2: Tesla M40 24GB (UUID: GPU-85551fe5-68ea-15b3-76c1-6fe1sas2w    1)</div><div class="line">GPU 3: Tesla M40 (UUID: GPU-8fe0a30b-7faa-0537-e3a5-53ba5c8a61wesd)</div></pre></td></tr></table></figure>
<p>3.查看GPU以及单元信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ nvidia-smi -q</div></pre></td></tr></table></figure></p>
<p>4.查看每一个GPU指定详细信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># nvidia-smi --query-gpu=index,name,uuid,serial --format=csv</div><div class="line">index, name, uuid, serial</div><div class="line">0, Tesla M40 24GB, GPU-eb4e4871-504d-feb7-ba59-xxxxxxxx, xxxxxxxxxx</div><div class="line">1, Tesla M40, GPU-6c2cb0c9-acba-1dab-6525-xxxxxxxx, xxxxxxxxxx</div><div class="line">2, Tesla M40 24GB, GPU-85551fe5-68ea-15b3-76c1-xxxxxxxx, xxxxxxxxxx</div><div class="line">3, Tesla M40, GPU-8fe0a30b-7faa-0537-e3a5-xxxxxxxx, xxxxxxxxxx</div></pre></td></tr></table></figure></p>
<p>5.指定GPU查看相关信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"># nvidia-smi --query-gpu=index,name,uuid,serial --format=csv --id=0</div><div class="line">index, name, uuid, serial</div><div class="line">0, Tesla M40 24GB, GPU-eb4e4871-504d-feb7-ba59-d15a66d6faa7, 0322816142509</div></pre></td></tr></table></figure></p>
<h3 id="监控和管理GPU-Boost"><a href="#监控和管理GPU-Boost" class="headerlink" title="监控和管理GPU Boost"></a>监控和管理GPU Boost</h3><p>管理员和用户可以使用这种方式来观察GPUs的状态。<br>以下显示了每个GPU的可用时钟频率(Tesla M40)。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">$ nvidia-smi -q -d SUPPORTED_CLOCKS</div><div class="line">GPU 0000:07:00.0</div><div class="line">    Supported Clocks</div><div class="line">        Memory                      : 3004 MHz</div><div class="line">            Graphics                : 1114 MHz</div><div class="line">            Graphics                : 1088 MHz</div><div class="line">            Graphics                : 1063 MHz</div><div class="line">            Graphics                : 1038 MHz</div><div class="line">            Graphics                : 1013 MHz</div><div class="line">            Graphics                : 987 MHz</div><div class="line">            Graphics                : 962 MHz</div><div class="line">            Graphics                : 949 MHz</div><div class="line">            Graphics                : 924 MHz</div><div class="line">            Graphics                : 899 MHz</div><div class="line">            Graphics                : 873 MHz</div><div class="line">            Graphics                : 848 MHz</div><div class="line">            Graphics                : 823 MHz</div><div class="line">            Graphics                : 797 MHz</div><div class="line">            Graphics                : 772 MHz</div><div class="line">            Graphics                : 747 MHz</div><div class="line">            Graphics                : 721 MHz</div><div class="line">            Graphics                : 696 MHz</div><div class="line">            Graphics                : 671 MHz</div><div class="line">            Graphics                : 645 MHz</div><div class="line">            Graphics                : 620 MHz</div><div class="line">            Graphics                : 595 MHz</div><div class="line">            Graphics                : 557 MHz</div><div class="line">            Graphics                : 532 MHz</div><div class="line">        Memory                      : 405 MHz</div><div class="line">            Graphics                : 324 MHz</div></pre></td></tr></table></figure>
<p>以上显示中只有两个内存时钟(memory clock)被支持：3004 MHz和405 MHz.运行在前者的内存，有24个支持GPU时钟频率。后者只有一个GPU频率，且是空闲状态的。在Tesla K80上，GPU Boost会自动管理这些频率，来让他们运行的尽可能快。而在其他一些模块中，比如Tesla K40，必须由管理员来指定GPU时钟频率。</p>
<p>查看当前GPU的时钟频率，默认的时钟加速和最小的时钟频率<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line">$ nvidia-smi -q -d CLOCK</div><div class="line"></div><div class="line">GPU 0000:07:00.0</div><div class="line">    Clocks</div><div class="line">        Graphics                    : 949 MHz</div><div class="line">        SM                          : 949 MHz</div><div class="line">        Memory                      : 3004 MHz</div><div class="line">        Video                       : 873 MHz</div><div class="line">    Applications Clocks</div><div class="line">        Graphics                    : 947 MHz</div><div class="line">        Memory                      : 3004 MHz</div><div class="line">    Default Applications Clocks</div><div class="line">        Graphics                    : 947 MHz</div><div class="line">        Memory                      : 3004 MHz</div><div class="line">    Max Clocks</div><div class="line">        Graphics                    : 1114 MHz</div><div class="line">        SM                          : 1114 MHz</div><div class="line">        Memory                      : 3004 MHz</div><div class="line">        Video                       : 1024 MHz</div><div class="line">    SM Clock Samples</div><div class="line">        Duration                    : 10989718.85 sec</div><div class="line">        Number of Samples           : 46</div><div class="line">        Max                         : 1063 MHz</div><div class="line">        Min                         : 324 MHz</div><div class="line">        Avg                         : 948 MHz</div><div class="line">    Memory Clock Samples</div><div class="line">        Duration                    : 10989718.85 sec</div><div class="line">        Number of Samples           : 46</div><div class="line">        Max                         : 3004 MHz</div><div class="line">        Min                         : 405 MHz</div><div class="line">        Avg                         : 3003 MHz</div><div class="line">    Clock Policy</div><div class="line">        Auto Boost                  : On</div><div class="line">        Auto Boost Default          : On</div></pre></td></tr></table></figure></p>
<p>理想状态中，你想让所有的时钟都一直运行在比较高的速度，但是对于所有的应用来说是不可能的。可以使用PERFORMANCE参数来查看每个GPU卡当前的状态以及时钟慢下来的原因。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">$ nvidia-smi -q -d PERFORMANCE/performance</div><div class="line">GPU 0000:07:00.0</div><div class="line">    Performance State               : P0</div><div class="line">    Clocks Throttle Reasons</div><div class="line">        Idle                        : Not Active</div><div class="line">        Applications Clocks Setting : Active</div><div class="line">        SW Power Cap                : Not Active</div><div class="line">        HW Slowdown                 : Not Active</div><div class="line">        Sync Boost                  : Not Active</div><div class="line">        Unknown                     : Not Active</div></pre></td></tr></table></figure>
<p>如果任何一个GPU时钟都以比较慢速度运行的话，那么上面的<code>Clocks Throttle Reasons</code>中的一个或多个将会被标记为active状态。最需要关注的是<code>HW Slowdown</code>和<code>Unknown</code>是否是active状态，如果那样的话很可能是电源或者冷却系统的问题。其余的需要关注设备卡是否是空闲的或者是由管理员手动设置为<code>slower</code>模式。</p>
<p>使用<code>nvidia-smi</code>还可以去监控其他相关指标，-d参数支持<code>MEMORY UTILIZATION ECC TEMPERATURE POWER CLOCK COMPUTE PIDS PERFORMANCE SUPPORTED_CLOCKS PAGE_RETIREMENT ACCOUNTING</code></p>
<p>查看每块GPU卡的内存使用：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">$ nvidia-smi -q -d memory</div><div class="line"></div><div class="line">GPU 0000:06:00.0</div><div class="line">    FB Memory Usage</div><div class="line">        Total                       : 22939 MiB</div><div class="line">        Used                        : 21800 MiB</div><div class="line">        Free                        : 1139 MiB</div><div class="line">    BAR1 Memory Usage</div><div class="line">        Total                       : 32768 MiB</div><div class="line">        Used                        : 2 MiB</div><div class="line">        Free                        : 32766 MiB</div><div class="line"></div><div class="line">GPU 0000:07:00.0</div><div class="line">    FB Memory Usage</div><div class="line">        Total                       : 11443 MiB</div><div class="line">        Used                        : 10876 MiB</div><div class="line">        Free                        : 567 MiB</div><div class="line">    BAR1 Memory Usage</div><div class="line">        Total                       : 16384 MiB</div><div class="line">        Used                        : 2 MiB</div><div class="line">        Free                        : 16382 MiB</div></pre></td></tr></table></figure>
<p>指定GPU卡查看相关指标：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ nvidia-smi -i 0 -q -d MEMORY,UTILIZATION,POWER,CLOCK,COMPUTE</div></pre></td></tr></table></figure></p>
<h3 id="查看系统的拓扑结构"><a href="#查看系统的拓扑结构" class="headerlink" title="查看系统的拓扑结构"></a>查看系统的拓扑结构</h3><p>要适当的利用更先进的NVIDIA GPU优势(例如GPU Direct)，因此系统的拓扑结构的正确配置是非常重要的。拓扑结构涉及到<code>PCI-Express</code>(GPUs, InfiniBand HCAs, storage controllers, etc)设备如何连接到其他设备，以及如何连接到系统CPU的。如果配置不正确，可能某些特定的功能性能会比较低甚至不能正常工作。为了解决如上问题，<code>nvidia-smi</code>最近的版本包含了一个可用查看系统拓扑的命令。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"># 显示GPU拓扑(-m参数可以看到GPU交流矩阵以及CPU亲和性绑定)</div><div class="line">$  nvidia-smi topo -m</div><div class="line">	GPU0	GPU1	GPU2	GPU3	CPU Affinity</div><div class="line">GPU0	 X 	PIX	PIX	PIX	0-0,2-2,4-4,6-6,8-8,10-10,12-12,14-14,16-16,18-18,20-20,22-22</div><div class="line">GPU1	PIX	 X 	PIX	PIX	0-0,2-2,4-4,6-6,8-8,10-10,12-12,14-14,16-16,18-18,20-20,22-22</div><div class="line">GPU2	PIX	PIX	 X 	PIX	0-0,2-2,4-4,6-6,8-8,10-10,12-12,14-14,16-16,18-18,20-20,22-22</div><div class="line">GPU3	PIX	PIX	PIX	 X 	0-0,2-2,4-4,6-6,8-8,10-10,12-12,14-14,16-16,18-18,20-20,22-22</div><div class="line"></div><div class="line">Legend:</div><div class="line"></div><div class="line">  X   = Self</div><div class="line">  SOC  = Connection traversing PCIe as well as the SMP link between CPU sockets(e.g. QPI)</div><div class="line">  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)</div><div class="line">  PXB  = Connection traversing multiple PCIe switches (without traversing the PCIe Host Bridge)</div><div class="line">  PIX  = Connection traversing a single PCIe switch</div><div class="line">  NV#  = Connection traversing a bonded set of # NVLinks</div></pre></td></tr></table></figure>
<p>以上配置显示我们有四块GOU卡，并且都链接在服务器的第一颗CPU上(物理机2颗6核cpu并开启超线程)。该工具建议推荐我们将job运行在偶数标记的cpu上。并且以上四块GPU卡都是互相通过PCIe switch直连的。</p>
<p>一个可用的GPU矩阵表示如下：</p>
<ul>
<li>X = 表示GPU本身</li>
<li>SOC = 表示贯穿PCIe总线和CPU sockets之间的SMP链接。</li>
<li>PHB = 贯穿PCIe总线和PCIe Host Bridge</li>
<li>PXB = 贯穿多个PCIe switch(不通过PCIe Host Bridge)</li>
<li>PIX = 链接单个PCIe switch</li>
<li>NV# = 贯穿一组NVLinks设备</li>
</ul>
<p><code>划重点啦：其实由上面的GPU拓扑可以看出来，我们系统上的4块设备是两两互相直连的架构！</code></p>
<p><a href="https://www.microway.com/hpc-tech-tips/nvidia-smi_control-your-gpus/" target="_blank" rel="external">nvidia-smi命令使用帮助</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;使用nvidia-smi管理你的GPU卡&quot;&gt;&lt;a href=&quot;#使用nvidia-smi管理你的GPU卡&quot; class=&quot;headerlink&quot; title=&quot;使用nvidia-smi管理你的GPU卡&quot;&gt;&lt;/a&gt;使用nvidia-smi管理你的GPU卡&lt;/h2&gt;&lt;p&gt;&lt;code&gt;nvidia-smi&lt;/code&gt;命令是NVIDIA系统管理接口，之前提到使用&lt;code&gt;nvidia-docker&lt;/code&gt;实际上底层也是调用的该接口。该接口可以查看到当前主机上的相关GPU设备，任务以及当前状态等信息，熟练使用该接口能够更好的管理好GPU系统资源。&lt;/p&gt;
    
    </summary>
    
      <category term="Docker" scheme="http://yoursite.com/categories/Docker/"/>
    
    
      <category term="GPU" scheme="http://yoursite.com/tags/GPU/"/>
    
      <category term="NVIDIA" scheme="http://yoursite.com/tags/NVIDIA/"/>
    
  </entry>
  
  <entry>
    <title>GPU环境下玩转Docker(二)</title>
    <link href="http://yoursite.com/2017/10/26/GPU%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%8E%A9%E8%BD%ACDocker-%E4%BA%8C/"/>
    <id>http://yoursite.com/2017/10/26/GPU环境下玩转Docker-二/</id>
    <published>2017-10-26T02:07:46.000Z</published>
    <updated>2017-10-30T14:28:38.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>前言:<br>在一节中<a href="https://xxbandy.github.io/2017/10/26/GPU%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%8E%A9%E8%BD%ACDocker-%E4%B8%80/" target="_blank" rel="external"></a>,我们已经在GPU物理机上准备好了GPU环境，本篇文章介绍如何使用Docker来管理GPU容器。</p>
</blockquote>
<a id="more"></a>
<h3 id="使用NVIDIA驱动Docker容器来识别gpu环境"><a href="#使用NVIDIA驱动Docker容器来识别gpu环境" class="headerlink" title="使用NVIDIA驱动Docker容器来识别gpu环境"></a>使用NVIDIA驱动Docker容器来识别gpu环境</h3><p>使用Docker方式来运行GPU任务计算。英伟达(nvidia)官方提供了一个插件<a href="https://github.com/NVIDIA/nvidia-docker" target="_blank" rel="external">NVIDIA-Docker</a>，封装docker的相关参数来绑定GPU相关信息，以给容器提供gpu环境。下面主要介绍使用<code>nvidia-docker</code>插件运行容器以共享宿主机的GPU资源，后面会捎带的讲解如何使用docker原生的方式来运行GPU容器环境。</p>
<p><a href="https://devblogs.nvidia.com/parallelforall/nvidia-docker-gpu-server-application-deployment-made-easy/" target="_blank" rel="external">nvidia-docker部署gpu应用</a><br><a href="https://github.com/NVIDIA/nvidia-docker/wiki/Motivation" target="_blank" rel="external">nvidia-docker的动机</a></p>
<p><a href="https://github.com/NVIDIA/nvidia-docker/wiki/Installation" target="_blank" rel="external">nvidia插件安装指导</a><br><a href="https://github.com/NVIDIA/nvidia-docker/wiki/nvidia-docker" target="_blank" rel="external">nvidia-docker使用指南</a><br><a href="https://github.com/NVIDIA/nvidia-docker/wiki/nvidia-docker-plugin" target="_blank" rel="external">nvidia-docker插件</a></p>
<p><a href="https://github.com/NVIDIA/nvidia-docker/wiki/NVIDIA-driver" target="_blank" rel="external">nvidia驱动</a><br><a href="https://github.com/NVIDIA/nvidia-docker/wiki/GPU-isolation" target="_blank" rel="external">GPU隔离技术</a><br><a href="https://github.com/NVIDIA/nvidia-docker/wiki/Image-inspection" target="_blank" rel="external">镜像检测</a></p>
<h4 id="快速部署安装"><a href="#快速部署安装" class="headerlink" title="快速部署安装"></a>快速部署安装</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div></pre></td><td class="code"><pre><div class="line"># 安装 nvidia-docker and nvidia-docker-plugin</div><div class="line">$ wget -P /tmp https://github.com/NVIDIA/nvidia-docker/releases/download/v1.0.1/nvidia-docker-1.0.1-1.x86_64.rpm</div><div class="line">$ rpm -i /tmp/nvidia-docker*.rpm &amp;&amp; rm /tmp/nvidia-docker*.rpm</div><div class="line">$ systemctl start nvidia-docker</div><div class="line"></div><div class="line"># 测试docker容器内部可以识别宿主机的GPU环境</div><div class="line"># nvidia-docker run --rm idockerhub.xxb.com/nvidia-docker/cuda8.0-runtime:centos6-17-10-19 nvidia-smi</div><div class="line">Thu Oct 19 08:07:09 2017</div><div class="line">+-----------------------------------------------------------------------------+</div><div class="line">| NVIDIA-SMI 375.39                 Driver Version: 375.39                    |</div><div class="line">|-------------------------------+----------------------+----------------------+</div><div class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</div><div class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</div><div class="line">|===============================+======================+======================|</div><div class="line">|   0  Tesla M40 24GB      On   | 0000:04:00.0     Off |                    0 |</div><div class="line">| N/A   28C    P8    18W / 250W |      0MiB / 22939MiB |      0%      Default |</div><div class="line">+-------------------------------+----------------------+----------------------+</div><div class="line">|   1  Tesla M40           On   | 0000:05:00.0     Off |                    0 |</div><div class="line">| N/A   31C    P8    17W / 250W |      0MiB / 11443MiB |      0%      Default |</div><div class="line">+-------------------------------+----------------------+----------------------+</div><div class="line">|   2  Tesla M40 24GB      On   | 0000:06:00.0     Off |                    0 |</div><div class="line">| N/A   26C    P8    18W / 250W |      0MiB / 22939MiB |      0%      Default |</div><div class="line">+-------------------------------+----------------------+----------------------+</div><div class="line">|   3  Tesla M40           On   | 0000:07:00.0     Off |                    0 |</div><div class="line">| N/A   27C    P8    16W / 250W |      0MiB / 11443MiB |      0%      Default |</div><div class="line">+-------------------------------+----------------------+----------------------+</div><div class="line"></div><div class="line">+-----------------------------------------------------------------------------+</div><div class="line">| Processes:                                                       GPU Memory |</div><div class="line">|  GPU       PID  Type  Process name                               Usage      |</div><div class="line">|=============================================================================|</div><div class="line">|  No running processes found                                                 |</div><div class="line">+-----------------------------------------------------------------------------+</div><div class="line"></div><div class="line"># 绑定GPU核心到docker容器内部(可以看到该容器内部其实只绑定了一块宿主机上的第一块GPU卡)实现GPU隔离</div><div class="line"># NV_GPU=0 nvidia-docker run --rm idockerhub.xxb.com/nvidia-docker/cuda8.0-runtime:centos6-17-10-19 nvidia-smi</div><div class="line">Wed Oct 25 07:17:03 2017</div><div class="line">+-----------------------------------------------------------------------------+</div><div class="line">| NVIDIA-SMI 375.39                 Driver Version: 375.39                    |</div><div class="line">|-------------------------------+----------------------+----------------------+</div><div class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</div><div class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</div><div class="line">|===============================+======================+======================|</div><div class="line">|   0  Tesla M40 24GB      On   | 0000:04:00.0     Off |                    0 |</div><div class="line">| N/A   23C    P8    17W / 250W |      0MiB / 22939MiB |      0%      Default |</div><div class="line">+-------------------------------+----------------------+----------------------+</div><div class="line"></div><div class="line">+-----------------------------------------------------------------------------+</div><div class="line">| Processes:                                                       GPU Memory |</div><div class="line">|  GPU       PID  Type  Process name                               Usage      |</div><div class="line">|=============================================================================|</div><div class="line">|  No running processes found                                                 |</div><div class="line">+-----------------------------------------------------------------------------+</div><div class="line"></div><div class="line"># NV_GPU=&quot;0,2&quot; nvidia-docker run --rm -ti idockerhub.xxb.com/nvidia-docker/cuda8.0-runtime:centos6-17-10-19 nvidia-smi</div><div class="line">Wed Oct 25 08:37:25 2017</div><div class="line">+-----------------------------------------------------------------------------+</div><div class="line">| NVIDIA-SMI 375.39                 Driver Version: 375.39                    |</div><div class="line">|-------------------------------+----------------------+----------------------+</div><div class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</div><div class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</div><div class="line">|===============================+======================+======================|</div><div class="line">|   0  Tesla M40 24GB      On   | 0000:04:00.0     Off |                    0 |</div><div class="line">| N/A   34C    P0    59W / 250W |  21802MiB / 22939MiB |      0%      Default |</div><div class="line">+-------------------------------+----------------------+----------------------+</div><div class="line">|   1  Tesla M40 24GB      On   | 0000:06:00.0     Off |                    0 |</div><div class="line">| N/A   34C    P0    57W / 250W |  21800MiB / 22939MiB |      0%      Default |</div><div class="line">+-------------------------------+----------------------+----------------------+</div><div class="line"></div><div class="line">+-----------------------------------------------------------------------------+</div><div class="line">| Processes:                                                       GPU Memory |</div><div class="line">|  GPU       PID  Type  Process name                               Usage      |</div><div class="line">|=============================================================================|</div><div class="line">+-----------------------------------------------------------------------------+</div></pre></td></tr></table></figure>
<p><code>注意1：上述输出的表格中可用看到，使用nvidia-docker工具创建的容器内部其实是可以识别到宿主机的GPU设备的</code></p>
<p><code>注意2：CPU和GPU其实很类似，无法智能识别需要几块卡设备，只能通过NV_GPU方式来给容器绑定GPU卡(类似于cpu set的方式)；需要管理员动态的调整需要分配的具体GPU卡设备</code></p>
<h4 id="容器内部GPU环境验证"><a href="#容器内部GPU环境验证" class="headerlink" title="容器内部GPU环境验证"></a>容器内部GPU环境验证</h4><p>2.1 <strong>使用官方的gpu版本的tensorflow镜像测试GPU设备</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div></pre></td><td class="code"><pre><div class="line"># nvidia-docker run -it --rm -v /usr/lib64/libcuda.so.1:/usr/local/nvidia/lib64/libcuda.so.1 idockerhub.xxb.com/jdjr/tensorflow-gpu:17-10-17 bash</div><div class="line"></div><div class="line">root@6b4ad215279e:/notebooks# python</div><div class="line">Python 2.7.12 (default, Nov 19 2016, 06:48:10)</div><div class="line">[GCC 5.4.0 20160609] on linux2</div><div class="line">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</div><div class="line">&gt;&gt;&gt; import tensorflow as tf</div><div class="line">&gt;&gt;&gt; a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name=&apos;a&apos;)</div><div class="line">&gt;&gt;&gt; b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name=&apos;b&apos;)</div><div class="line">&gt;&gt;&gt; c = tf.matmul(a, b)</div><div class="line">&gt;&gt;&gt; sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))</div><div class="line">2017-10-19 08:01:39.862500: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&apos;t compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.</div><div class="line">2017-10-19 08:01:39.862600: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&apos;t compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.</div><div class="line">2017-10-19 08:01:39.862646: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&apos;t compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.</div><div class="line">2017-10-19 08:01:39.862676: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&apos;t compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.</div><div class="line">2017-10-19 08:01:39.862711: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&apos;t compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.</div><div class="line">2017-10-19 08:01:40.388656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:</div><div class="line">name: Tesla M40 24GB</div><div class="line">major: 5 minor: 2 memoryClockRate (GHz) 1.112</div><div class="line">pciBusID 0000:04:00.0</div><div class="line">Total memory: 22.40GiB</div><div class="line">Free memory: 22.29GiB</div><div class="line">2017-10-19 08:01:40.682810: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x1e2dac0 exists before initializing the StreamExecutor. We haven&apos;t verified StreamExecutor works with that.</div><div class="line">2017-10-19 08:01:40.684222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties:</div><div class="line">name: Tesla M40</div><div class="line">major: 5 minor: 2 memoryClockRate (GHz) 1.112</div><div class="line">pciBusID 0000:05:00.0</div><div class="line">Total memory: 11.17GiB</div><div class="line">Free memory: 11.07GiB</div><div class="line">2017-10-19 08:01:40.995170: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x329a280 exists before initializing the StreamExecutor. We haven&apos;t verified StreamExecutor works with that.</div><div class="line">2017-10-19 08:01:40.998560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 2 with properties:</div><div class="line">name: Tesla M40 24GB</div><div class="line">major: 5 minor: 2 memoryClockRate (GHz) 1.112</div><div class="line">pciBusID 0000:06:00.0</div><div class="line">Total memory: 22.40GiB</div><div class="line">Free memory: 22.29GiB</div><div class="line">2017-10-19 08:01:41.289133: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x329dc00 exists before initializing the StreamExecutor. We haven&apos;t verified StreamExecutor works with that.</div><div class="line">2017-10-19 08:01:41.290444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 3 with properties:</div><div class="line">name: Tesla M40</div><div class="line">major: 5 minor: 2 memoryClockRate (GHz) 1.112</div><div class="line">pciBusID 0000:07:00.0</div><div class="line">Total memory: 11.17GiB</div><div class="line">Free memory: 11.07GiB</div><div class="line">2017-10-19 08:01:41.294062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 2 3</div><div class="line">2017-10-19 08:01:41.294083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y Y Y</div><div class="line">2017-10-19 08:01:41.294093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y Y Y</div><div class="line">2017-10-19 08:01:41.294156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 2:   Y Y Y Y</div><div class="line">2017-10-19 08:01:41.294178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 3:   Y Y Y Y</div><div class="line">2017-10-19 08:01:41.294215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: Tesla M40 24GB, pci bus id: 0000:04:00.0)</div><div class="line">2017-10-19 08:01:41.294229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -&gt; (device: 1, name: Tesla M40, pci bus id: 0000:05:00.0)</div><div class="line">2017-10-19 08:01:41.294239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:2) -&gt; (device: 2, name: Tesla M40 24GB, pci bus id: 0000:06:00.0)</div><div class="line">2017-10-19 08:01:41.294248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:3) -&gt; (device: 3, name: Tesla M40, pci bus id: 0000:07:00.0)</div><div class="line">Device mapping:</div><div class="line">/job:localhost/replica:0/task:0/gpu:0 -&gt; device: 0, name: Tesla M40 24GB, pci bus id: 0000:04:00.0</div><div class="line">/job:localhost/replica:0/task:0/gpu:1 -&gt; device: 1, name: Tesla M40, pci bus id: 0000:05:00.0</div><div class="line">/job:localhost/replica:0/task:0/gpu:2 -&gt; device: 2, name: Tesla M40 24GB, pci bus id: 0000:06:00.0</div><div class="line">/job:localhost/replica:0/task:0/gpu:3 -&gt; device: 3, name: Tesla M40, pci bus id: 0000:07:00.0</div><div class="line">2017-10-19 08:01:41.875931: I tensorflow/core/common_runtime/direct_session.cc:300] Device mapping:</div><div class="line">/job:localhost/replica:0/task:0/gpu:0 -&gt; device: 0, name: Tesla M40 24GB, pci bus id: 0000:04:00.0</div><div class="line">/job:localhost/replica:0/task:0/gpu:1 -&gt; device: 1, name: Tesla M40, pci bus id: 0000:05:00.0</div><div class="line">/job:localhost/replica:0/task:0/gpu:2 -&gt; device: 2, name: Tesla M40 24GB, pci bus id: 0000:06:00.0</div><div class="line">/job:localhost/replica:0/task:0/gpu:3 -&gt; device: 3, name: Tesla M40, pci bus id: 0000:07:00.0</div><div class="line"></div><div class="line">&gt;&gt;&gt; print(sess.run(c))</div><div class="line">MatMul: (MatMul): /job:localhost/replica:0/task:0/gpu:0</div><div class="line">2017-10-19 08:01:51.333248: I tensorflow/core/common_runtime/simple_placer.cc:872] MatMul: (MatMul)/job:localhost/replica:0/task:0/gpu:0</div><div class="line">b: (Const): /job:localhost/replica:0/task:0/gpu:0</div><div class="line">2017-10-19 08:01:51.333346: I tensorflow/core/common_runtime/simple_placer.cc:872] b: (Const)/job:localhost/replica:0/task:0/gpu:0</div><div class="line">a: (Const): /job:localhost/replica:0/task:0/gpu:0</div><div class="line">2017-10-19 08:01:51.333408: I tensorflow/core/common_runtime/simple_placer.cc:872] a: (Const)/job:localhost/replica:0/task:0/gpu:0</div><div class="line">[[ 22.  28.]</div><div class="line"> [ 49.  64.]]</div><div class="line">&gt;&gt;&gt;</div></pre></td></tr></table></figure>
<p><code>注意：由以上完整输出可以看到当前的容器环境内部可以正常识别到GPU设备，并可以进行GPU计算</code></p>
<p>2.1 <strong>使用TensorFlow-gpu环境</strong></p>
<p>官方<code>tensorflow/tensorflow:latest-gpu</code>镜像是使用<code>jupyter</code>环境来提供一个可编程的<code>TensorFlow</code>环境。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"># nvidia-docker run -itd -p 8888:8888 -p 6006:6006 idockerhub.xxb.com/jdjr/tensorflow-gpu:17-10-17</div><div class="line"># docker logs -f evil_ride</div><div class="line">[I 07:24:37.730 NotebookApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret</div><div class="line">[W 07:24:37.742 NotebookApp] WARNING: The notebook server is listening on all IP addresses and not using encryption. This is not recommended.</div><div class="line">[I 07:24:37.747 NotebookApp] Serving notebooks from local directory: /notebooks</div><div class="line">[I 07:24:37.747 NotebookApp] 0 active kernels</div><div class="line">[I 07:24:37.747 NotebookApp] The Jupyter Notebook is running at: http://[all ip addresses on your system]:8888/?token=b4f66281d6b1f89bd6fda85c6e88a022ef6d38308e7f284b</div><div class="line">[I 07:24:37.748 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).</div><div class="line">[C 07:24:37.748 NotebookApp]</div><div class="line"></div><div class="line">    Copy/paste this URL into your browser when you connect for the first time,</div><div class="line">    to login with a token:</div><div class="line">        http://localhost:8888/?token=b4f66281d6b1f89bd6fda85c6e88a022ef6d38308e7f284b</div></pre></td></tr></table></figure>
<p>成功运行后如上述日志显示，直接访问上述链接，或者访问本机的8888端口，并将后面的token作为密码输入后即可登录jupyter环境，使用tensorflow环境。</p>
<p><img src="http://oyep1jupk.bkt.clouddn.com/docker/nvidia-docker/tensorflow-jupyter.png" alt=""></p>
<p>点击右上角<code>New</code>下面的<code>Python2</code>可进入jupyter的交互式编程环境。并进行GPU简单程序的测试，测试结果如下：<br><img src="http://oyep1jupk.bkt.clouddn.com/docker/nvidia-docker/tensorflow-gpu.png" alt=""></p>
<p>可以看到，使用TensorFlow官方的镜像文件，可以直接使用jupyter进行运行gpu计算任务。该任务运行完毕之后，运行过程中的日志信息如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div></pre></td><td class="code"><pre><div class="line"># docker logs -f evil_ride</div><div class="line">[I 07:37:01.806 NotebookApp] Adapting to protocol v5.1 for kernel 253b4ef2-b573-4256-a14b-6a840777923d</div><div class="line">2017-10-25 07:37:41.174144: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&apos;t compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.</div><div class="line">2017-10-25 07:37:41.174295: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&apos;t compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.</div><div class="line">2017-10-25 07:37:41.174320: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&apos;t compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.</div><div class="line">2017-10-25 07:37:41.174342: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&apos;t compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.</div><div class="line">2017-10-25 07:37:41.174366: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&apos;t compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.</div><div class="line">2017-10-25 07:37:41.719139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:</div><div class="line">name: Tesla M40 24GB</div><div class="line">major: 5 minor: 2 memoryClockRate (GHz) 1.112</div><div class="line">pciBusID 0000:04:00.0</div><div class="line">Total memory: 22.40GiB</div><div class="line">Free memory: 22.29GiB</div><div class="line">2017-10-25 07:37:41.999138: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x1d90ab0 exists before initializing the StreamExecutor. We haven&apos;t verified StreamExecutor works with that.</div><div class="line">2017-10-25 07:37:42.001131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties:</div><div class="line">name: Tesla M40</div><div class="line">major: 5 minor: 2 memoryClockRate (GHz) 1.112</div><div class="line">pciBusID 0000:05:00.0</div><div class="line">Total memory: 11.17GiB</div><div class="line">Free memory: 11.07GiB</div><div class="line">2017-10-25 07:37:42.317011: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x3acbf10 exists before initializing the StreamExecutor. We haven&apos;t verified StreamExecutor works with that.</div><div class="line">2017-10-25 07:37:42.318986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 2 with properties:</div><div class="line">name: Tesla M40 24GB</div><div class="line">major: 5 minor: 2 memoryClockRate (GHz) 1.112</div><div class="line">pciBusID 0000:06:00.0</div><div class="line">Total memory: 22.40GiB</div><div class="line">Free memory: 22.29GiB</div><div class="line">2017-10-25 07:37:42.612283: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x3acf890 exists before initializing the StreamExecutor. We haven&apos;t verified StreamExecutor works with that.</div><div class="line">2017-10-25 07:37:42.614320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 3 with properties:</div><div class="line">name: Tesla M40</div><div class="line">major: 5 minor: 2 memoryClockRate (GHz) 1.112</div><div class="line">pciBusID 0000:07:00.0</div><div class="line">Total memory: 11.17GiB</div><div class="line">Free memory: 11.07GiB</div><div class="line">2017-10-25 07:37:42.619214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 2 3</div><div class="line">2017-10-25 07:37:42.619252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y Y Y</div><div class="line">2017-10-25 07:37:42.619270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y Y Y</div><div class="line">2017-10-25 07:37:42.619287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 2:   Y Y Y Y</div><div class="line">2017-10-25 07:37:42.619351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 3:   Y Y Y Y</div><div class="line">2017-10-25 07:37:42.619386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: Tesla M40 24GB, pci bus id: 0000:04:00.0)</div><div class="line">2017-10-25 07:37:42.619410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -&gt; (device: 1, name: Tesla M40, pci bus id: 0000:05:00.0)</div><div class="line">2017-10-25 07:37:42.619431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:2) -&gt; (device: 2, name: Tesla M40 24GB, pci bus id: 0000:06:00.0)</div><div class="line">2017-10-25 07:37:42.619464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:3) -&gt; (device: 3, name: Tesla M40, pci bus id: 0000:07:00.0)</div><div class="line">2017-10-25 07:37:56.406493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: Tesla M40 24GB, pci bus id: 0000:04:00.0)</div><div class="line">2017-10-25 07:37:56.406573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -&gt; (device: 1, name: Tesla M40, pci bus id: 0000:05:00.0)</div><div class="line">2017-10-25 07:37:56.406607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:2) -&gt; (device: 2, name: Tesla M40 24GB, pci bus id: 0000:06:00.0)</div><div class="line">2017-10-25 07:37:56.406627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:3) -&gt; (device: 3, name: Tesla M40, pci bus id: 0000:07:00.0)</div><div class="line">[I 07:39:01.292 NotebookApp] Saving file at /Untitled1.ipynb</div></pre></td></tr></table></figure></p>
<p>由上述日志输出可以看到该任务其实是占用宿主机的4个GPU卡进行任务计算的。</p>
<p><code>注意：因为jupyter是通过websocket和python环境进行交互的，如果需要使用反向代理之类的工具访问服务，需要反向代理工具支持websocket协议</code>。在实际部署过程中，我们使用Nginx进行反向代理，Nginx默认是在1.3版本开始支持websocket的，如果nginx版本大于1.3只需要对相应的配置文件中增加如下内容即可。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">upstream tomcat_txxb.wp.com &#123;</div><div class="line">        server 10.0.0.10:8888  weight=10 max_fails=2 fail_timeout=30s;</div><div class="line">                &#125;</div><div class="line">location / &#123;</div><div class="line">        proxy_next_upstream     http_500 http_502 http_503 http_504 error timeout invalid_header;</div><div class="line">        proxy_set_header        Host  $host;</div><div class="line">        proxy_set_header        X-Forwarded-For $proxy_add_x_forwarded_for;</div><div class="line">        proxy_pass              http://tomcat_txxb.wp.com;</div><div class="line"></div><div class="line">location ~ /api/kernels/ &#123;</div><div class="line">        proxy_pass            http://tomcat_txxb.wp.com;</div><div class="line">        proxy_set_header      Host $host;</div><div class="line">        # websocket support</div><div class="line">        proxy_http_version    1.1;</div><div class="line">        proxy_set_header      Upgrade &quot;websocket&quot;;</div><div class="line">        proxy_set_header      Connection &quot;Upgrade&quot;;</div><div class="line">        proxy_read_timeout    86400;</div><div class="line">    &#125;</div><div class="line">location ~ /terminals/ &#123;</div><div class="line">        proxy_pass            http://tomcat_txxb.wp.com;</div><div class="line">        proxy_set_header      Host $host;</div><div class="line">        # websocket support</div><div class="line">        proxy_http_version    1.1;</div><div class="line">        proxy_set_header      Upgrade &quot;websocket&quot;;</div><div class="line">        proxy_set_header      Connection &quot;Upgrade&quot;;</div><div class="line">        proxy_read_timeout    86400;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<blockquote>
<p>使用docker原生方式运行GPU容器环境(无非就是指定设备挂载或者将给容器开放特权来操作宿主机硬件)</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"># export DEVICES=$(\ls /dev/nvidia* | xargs -I&#123;&#125; echo &apos;--device &#123;&#125;:&#123;&#125;&apos;)</div><div class="line"># docker run  $DEVICES -it --rm -v /usr/lib64/libcuda.so.1:/usr/local/nvidia/lib64/libcuda.so.1 -v /usr/lib64/libnvidia-fatbinaryloader.so.375.39:/usr/local/nvidia/lib64/libnvidia-fatbinaryloader.so.375.39  -v /root/gpu-example/:/tmp idockerhub.xxb.com/jdjr/tensorflow-gpu:17-10-17 bash</div><div class="line"></div><div class="line"></div><div class="line"># docker run  --privileged -it --rm -v /usr/lib64/libcuda.so.1:/usr/local/nvidia/lib64/libcuda.so.1 -v /usr/lib64/libnvidia-fatbinaryloader.so.375.39:/usr/local/nvidia/lib64/libnvidia-fatbinaryloader.so.375.39  -v /root/gpu-example/:/tmp idockerhub.xxb.com/jdjr/tensorflow-gpu:17-10-17 bash</div></pre></td></tr></table></figure>
<p><code>注意：当然在上述tensorflow测试过程中，只需要部分的cuda依赖库，在很多其他的业务场景下可能需要其他的依赖库，建议使用如下方式挂载全部库依赖</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># export CUDA_SO=&quot;$(\ls /usr/lib64/libcuda* | xargs -I&#123;&#125; echo &apos;-v  &#123;&#125;:&#123;&#125;&apos;)  $(\ls /usr/lib64/libnvidia* | xargs -I&#123;&#125; echo &apos;-v &#123;&#125;:&#123;&#125;&apos;)&quot;</div><div class="line"># docker run $DEVICES $CUDA_SO --rm idockerhub.xxb.com/jdjr/tensorflow-gpu:17-10-17 bash</div></pre></td></tr></table></figure>
<blockquote>
<p>思考：其实从nvidia-docker的运行方式和docker原生的运行方式上来看，nvidia其实是使用自己的插件来封装了一些docker的默认参数，比如说上述的GPU设备，以及相关lib库依赖。从<code>nvidia-docker</code>的底层实现上也可以看得出来</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># curl -s http://localhost:3476/docker/cli</div><div class="line">--volume-driver=nvidia-docker --volume=nvidia_driver_375.39:/usr/local/nvidia:ro --device=/dev/nvidiactl --device=/dev/nvidia-uvm --device=/dev/nvidia-uvm-tools --device=/dev/nvidia0 --device=/dev/nvidia1 --device=/dev/nvidia2 --device=/dev/nvidia3</div></pre></td></tr></table></figure>
<p>也就是说<code>nvidia-docker</code>在创建容器的时候，默认是加入了上述的参数的。也就是docker原生调用过程中使用的<code>-v</code>和<code>--device</code>.其实可以查看<code>nvidia-docker</code>工具生成的容器的相关配置:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div></pre></td><td class="code"><pre><div class="line"># docker inspect evil_ride</div><div class="line">&quot;HostConfig&quot;: &#123;</div><div class="line">            &quot;Binds&quot;: [</div><div class="line">                &quot;nvidia_driver_375.39:/usr/local/nvidia:ro&quot;</div><div class="line">            ],</div><div class="line">            ........</div><div class="line">&#125;</div><div class="line"></div><div class="line">&quot;Devices&quot;: [</div><div class="line">                &#123;</div><div class="line">                    &quot;PathOnHost&quot;: &quot;/dev/nvidiactl&quot;,</div><div class="line">                    &quot;PathInContainer&quot;: &quot;/dev/nvidiactl&quot;,</div><div class="line">                    &quot;CgroupPermissions&quot;: &quot;rwm&quot;</div><div class="line">                &#125;,</div><div class="line">                &#123;</div><div class="line">                    &quot;PathOnHost&quot;: &quot;/dev/nvidia-uvm&quot;,</div><div class="line">                    &quot;PathInContainer&quot;: &quot;/dev/nvidia-uvm&quot;,</div><div class="line">                    &quot;CgroupPermissions&quot;: &quot;rwm&quot;</div><div class="line">                &#125;,</div><div class="line">                &#123;</div><div class="line">                    &quot;PathOnHost&quot;: &quot;/dev/nvidia-uvm-tools&quot;,</div><div class="line">                    &quot;PathInContainer&quot;: &quot;/dev/nvidia-uvm-tools&quot;,</div><div class="line">                    &quot;CgroupPermissions&quot;: &quot;rwm&quot;</div><div class="line">                &#125;,</div><div class="line">                &#123;</div><div class="line">                    &quot;PathOnHost&quot;: &quot;/dev/nvidia0&quot;,</div><div class="line">                    &quot;PathInContainer&quot;: &quot;/dev/nvidia0&quot;,</div><div class="line">                    &quot;CgroupPermissions&quot;: &quot;rwm&quot;</div><div class="line">                &#125;,</div><div class="line">                &#123;</div><div class="line">                    &quot;PathOnHost&quot;: &quot;/dev/nvidia1&quot;,</div><div class="line">                    &quot;PathInContainer&quot;: &quot;/dev/nvidia1&quot;,</div><div class="line">                    &quot;CgroupPermissions&quot;: &quot;rwm&quot;</div><div class="line">                &#125;,</div><div class="line">                &#123;</div><div class="line">                    &quot;PathOnHost&quot;: &quot;/dev/nvidia2&quot;,</div><div class="line">                    &quot;PathInContainer&quot;: &quot;/dev/nvidia2&quot;,</div><div class="line">                    &quot;CgroupPermissions&quot;: &quot;rwm&quot;</div><div class="line">                &#125;,</div><div class="line">                &#123;</div><div class="line">                    &quot;PathOnHost&quot;: &quot;/dev/nvidia3&quot;,</div><div class="line">                    &quot;PathInContainer&quot;: &quot;/dev/nvidia3&quot;,</div><div class="line">                    &quot;CgroupPermissions&quot;: &quot;rwm&quot;</div><div class="line">                &#125;</div><div class="line">            ],</div><div class="line"></div><div class="line"></div><div class="line">        &quot;Mounts&quot;: [</div><div class="line">            &#123;</div><div class="line">                &quot;Name&quot;: &quot;nvidia_driver_375.39&quot;,</div><div class="line">                &quot;Source&quot;: &quot;/var/lib/nvidia-docker/volumes/nvidia_driver/375.39&quot;,</div><div class="line">                &quot;Destination&quot;: &quot;/usr/local/nvidia&quot;,</div><div class="line">                &quot;Driver&quot;: &quot;nvidia-docker&quot;,</div><div class="line">                &quot;Mode&quot;: &quot;ro&quot;,</div><div class="line">                &quot;RW&quot;: false,</div><div class="line">                &quot;Propagation&quot;: &quot;rprivate&quot;</div><div class="line">            &#125;</div><div class="line">        ],</div><div class="line"></div><div class="line"></div><div class="line">        &quot;Env&quot;: [</div><div class="line">                &quot;PATH=/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot;,</div><div class="line">                &quot;CUDA_VERSION=8.0.61&quot;,</div><div class="line">                &quot;NVIDIA_CUDA_VERSION=8.0.61&quot;,</div><div class="line">                &quot;CUDA_PKG_VERSION=8-0=8.0.61-1&quot;,</div><div class="line">                &quot;LD_LIBRARY_PATH=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64&quot;,</div><div class="line">                &quot;NVIDIA_VISIBLE_DEVICES=all&quot;,</div><div class="line">                &quot;NVIDIA_DRIVER_CAPABILITIES=compute,utility&quot;,</div><div class="line">                &quot;LIBRARY_PATH=/usr/local/cuda/lib64/stubs:&quot;,</div><div class="line">                &quot;CUDNN_VERSION=6.0.21&quot;</div><div class="line">            ],</div><div class="line"></div><div class="line"></div><div class="line">        &quot;Labels&quot;: &#123;</div><div class="line">                &quot;com.nvidia.build.id&quot;: &quot;29071360&quot;,</div><div class="line">                &quot;com.nvidia.build.ref&quot;: &quot;836d5387f8888c3924aff7a011f9b2cd9956d3db&quot;,</div><div class="line">                &quot;com.nvidia.cuda.version&quot;: &quot;8.0.61&quot;,</div><div class="line">                &quot;com.nvidia.cudnn.version&quot;: &quot;6.0.21&quot;,</div><div class="line">                &quot;com.nvidia.volumes.needed&quot;: &quot;nvidia_driver&quot;,</div><div class="line">                &quot;maintainer&quot;: &quot;NVIDIA CORPORATION \u003ccudatools@nvidia.com\u003e&quot;</div><div class="line">            &#125;</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;前言:&lt;br&gt;在一节中&lt;a href=&quot;https://xxbandy.github.io/2017/10/26/GPU%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%8E%A9%E8%BD%ACDocker-%E4%B8%80/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;&lt;/a&gt;,我们已经在GPU物理机上准备好了GPU环境，本篇文章介绍如何使用Docker来管理GPU容器。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Docker" scheme="http://yoursite.com/categories/Docker/"/>
    
    
      <category term="Docker" scheme="http://yoursite.com/tags/Docker/"/>
    
      <category term="GPU" scheme="http://yoursite.com/tags/GPU/"/>
    
      <category term="NVIDIA" scheme="http://yoursite.com/tags/NVIDIA/"/>
    
  </entry>
  
  <entry>
    <title>GPU环境下玩转Docker(一)</title>
    <link href="http://yoursite.com/2017/10/26/GPU%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%8E%A9%E8%BD%ACDocker-%E4%B8%80/"/>
    <id>http://yoursite.com/2017/10/26/GPU环境下玩转Docker-一/</id>
    <published>2017-10-26T02:07:34.000Z</published>
    <updated>2017-10-30T14:27:56.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="背景："><a href="#背景：" class="headerlink" title="背景："></a>背景：</h3><p>随着大数据、人工智能以及机器学习等技术的发展，CPU计算资源已经不能满足很多计算场景，而随着硬件技术的发展，越来越多的人工智能以及机器学习领域开始使用GPU进行计算任务。而GPU环境以及具体的应用方式又给真正做人工智能相关的同学造成了很多困扰，本系列文章将分为三篇，将介绍如何搭建部署GPU环境，使用Docker进行管理GPU容器，使用Kubernetes来调度GPU容器。</p>
<p><a href="http://www.jianshu.com/p/e72a352a2bd7" target="_blank" rel="external">从GPU到GPGPU</a><br><a href="http://www.jianshu.com/p/609e0530a19c" target="_blank" rel="external">CPU与GPU</a></p>
<a id="more"></a>
<h3 id="GPU准备"><a href="#GPU准备" class="headerlink" title="GPU准备"></a>GPU准备</h3><p><a href="http://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#redhat-installation" target="_blank" rel="external">CUDA安装部署</a></p>
<p><a href="https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;target_arch=x86_64&amp;target_distro=CentOS&amp;target_version=7&amp;target_type=rpmlocal" target="_blank" rel="external">CUDA Toolkit下载页面</a></p>
<p><a href="http://www.nvidia.cn/page/home.html" target="_blank" rel="external">英伟达中文官网</a></p>
<h3 id="GPU驱动安装"><a href="#GPU驱动安装" class="headerlink" title="GPU驱动安装"></a>GPU驱动安装</h3><p><code>注意：由于GPU需要在宿主机上安装相关驱动才能够被用户态的程序所识别，所以需要先安装CUDA</code></p>
<p>参考上述的<code>CUDA安装部署</code></p>
<h4 id="系统需求"><a href="#系统需求" class="headerlink" title="系统需求"></a>系统需求</h4><p>想要在系统上使用<code>CUDA</code>，必须安装如下依赖：</p>
<ul>
<li>CUDA-capable CPU</li>
<li>一个特定版本的gcc编译器以及相关工具链</li>
<li><a href="http://developer.nvidia.com/cuda-downloads" target="_blank" rel="external">NVIDIA CUDA Toolkit</a></li>
</ul>
<p>在linux X86_64架构平台上建议的配置：</p>
<table>
<thead>
<tr>
<th>linux发行版</th>
<th>内核版本</th>
<th>GCC</th>
<th>GLIBC</th>
<th>ICC</th>
<th>PGI</th>
<th>XLC</th>
<th>CLANG</th>
</tr>
</thead>
<tbody>
<tr>
<td>RHEL 7.X</td>
<td>3.10</td>
<td>4.8.5</td>
<td>2.17</td>
<td>17.0</td>
<td>17.1</td>
<td>NO</td>
<td>3.9</td>
</tr>
<tr>
<td>Centos 7.X</td>
<td>3.10</td>
<td>4.8.5</td>
<td>2.17</td>
<td>17.0</td>
<td>17.1</td>
<td>NO</td>
<td>3.9</td>
</tr>
<tr>
<td>RHEL 6.X</td>
<td>2.6.32</td>
<td>4.4.7</td>
<td>2.12</td>
<td>17.0</td>
<td>17.1</td>
<td>NO</td>
<td>3.9</td>
</tr>
<tr>
<td>Centos 6.X</td>
<td>2.6.32</td>
<td>4.4.7</td>
<td>2.12</td>
<td>17.0</td>
<td>17.1</td>
<td>NO</td>
<td>3.9</td>
</tr>
<tr>
<td>Fedora 25</td>
<td>4.8.8</td>
<td>6.2.1</td>
<td>2.24-3</td>
<td>17.0</td>
<td>17.1</td>
<td>NO</td>
<td>3.9</td>
</tr>
<tr>
<td>OpenSUSE Leap 42.2</td>
<td>4.4.27</td>
<td>4.8</td>
<td>2.22</td>
<td>17.0</td>
<td>17.1</td>
<td>NO</td>
<td>3.9</td>
</tr>
<tr>
<td>SLES 12 SP2</td>
<td>4.4.21</td>
<td>4.8.5</td>
<td>2.22</td>
<td>17.0</td>
<td>17.1</td>
<td>NO</td>
<td>3.9</td>
</tr>
<tr>
<td>Ubuntu 17.04</td>
<td>4.9.0</td>
<td>6.3.0</td>
<td>2.24-3</td>
<td>17.0</td>
<td>17.1</td>
<td>NO</td>
<td>3.9</td>
</tr>
<tr>
<td>Ubuntu 16.04</td>
<td>4.4</td>
<td>5.3.1</td>
<td>2.23</td>
<td>17.0</td>
<td>17.1</td>
<td>NO</td>
<td>3.9</td>
</tr>
</tbody>
</table>
<h4 id="安装前准备"><a href="#安装前准备" class="headerlink" title="安装前准备"></a>安装前准备</h4><p>在安装CUDA Toolkit和驱动之前，需要在GPU主机上执行相关的操作：</p>
<ul>
<li>检测系统中有CUDA-capable GPU卡</li>
<li>检测系统是否是上述列表中支持的linux发行版本</li>
<li>检测系统中是否安装了依赖的gcc编译器</li>
<li>检测系统中是否安装了正确的内核头文件以及开发包</li>
<li>下载NVIDIA CUDA Toolkit</li>
<li>处理一些安装过程中的冲突问题</li>
</ul>
<p><strong>2.1 检测是否有一个CUDA-Capable GPU</strong></p>
<p>如下显示当前主机上支持并有四个GPU设备<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">sh-4.2# lspci | grep -i nvidia</div><div class="line">04:00.0 3D controller: NVIDIA Corporation Device 17fd (rev a1)</div><div class="line">05:00.0 3D controller: NVIDIA Corporation Device 17fd (rev a1)</div><div class="line">06:00.0 3D controller: NVIDIA Corporation Device 17fd (rev a1)</div><div class="line">07:00.0 3D controller: NVIDIA Corporation Device 17fd (rev a1)</div></pre></td></tr></table></figure></p>
<p><code>注意：如果使用上述命令没有任何输出，那需要更新你的PCI 硬件数据库，然后再次执行；</code></p>
<p>查看GPU相关基础信息：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">sh-4.2# nvidia-smi</div><div class="line">Wed Oct 18 11:58:03 2017</div><div class="line">+-----------------------------------------------------------------------------+</div><div class="line">| NVIDIA-SMI 375.39                 Driver Version: 375.39                    |</div><div class="line">|-------------------------------+----------------------+----------------------+</div><div class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</div><div class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</div><div class="line">|===============================+======================+======================|</div><div class="line">|   0  Tesla M40 24GB      On   | 0000:04:00.0     Off |                    0 |</div><div class="line">| N/A   23C    P8    17W / 250W |      0MiB / 22939MiB |      0%      Default |</div><div class="line">+-------------------------------+----------------------+----------------------+</div><div class="line">|   1  Tesla M40           On   | 0000:05:00.0     Off |                    0 |</div><div class="line">| N/A   26C    P8    17W / 250W |      0MiB / 11443MiB |      0%      Default |</div><div class="line">+-------------------------------+----------------------+----------------------+</div><div class="line">|   2  Tesla M40 24GB      On   | 0000:06:00.0     Off |                    0 |</div><div class="line">| N/A   22C    P8    17W / 250W |      0MiB / 22939MiB |      0%      Default |</div><div class="line">+-------------------------------+----------------------+----------------------+</div><div class="line">|   3  Tesla M40           On   | 0000:07:00.0     Off |                    0 |</div><div class="line">| N/A   23C    P8    16W / 250W |      0MiB / 11443MiB |      0%      Default |</div><div class="line">+-------------------------------+----------------------+----------------------+</div><div class="line"></div><div class="line">+-----------------------------------------------------------------------------+</div><div class="line">| Processes:                                                       GPU Memory |</div><div class="line">|  GPU       PID  Type  Process name                               Usage      |</div><div class="line">|=============================================================================|</div><div class="line">|  No running processes found                                                 |</div><div class="line">+-----------------------------------------------------------------------------+</div><div class="line"></div><div class="line"># Temp 标识GPU设备的温度</div><div class="line"># Memory-Usage 表示内存使用率</div><div class="line"># GPU-Util 表示GPU使用率</div></pre></td></tr></table></figure>
<p><code>注意：上述输出也可以看出该系统上有4块GPU设备，使用Tesla M40型号。其中分别有两块卡24G内存，两块是12G内存，分别处于两个PCIE总线上</code></p>
<p><code>注意：宿主机内存为256G，cpu为Intel(R) Xeon(R) CPU E5-2620 v3 @ 2.40GHz 开启超线程后为24颗逻辑cpu(两颗6核心的cpu开启了超线程)</code></p>
<p><code>注意：如果你的GPU卡是NVIDIA的，并且是在http://developer.nvidia.com/cuda-gpus中可用查看到的，那么你的GPU就是 CUDA-capable</code></p>
<p><img src="http://oyep1jupk.bkt.clouddn.com/docker/nvidia-docker/gpu-type.png" alt=""></p>
<p><strong>2.2 检测Linux的架构和操作系统版本</strong></p>
<p>因为CUDA开发工具只支持一些指定发行版本的linux，需要用户查看操作系统的架构以及发行版本。可以在CUDA Toolkit发布版本的中查看支持的linux版本。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"># uname -m &amp;&amp; cat /etc/redhat-release</div><div class="line">x86_64</div><div class="line">CentOS Linux release 7.2.1511 (Core)</div></pre></td></tr></table></figure>
<p><strong>2.3 检测系统是否安装了gcc</strong></p>
<p>当使用CUDA Toolkit进行开发的时候，gcc编译器是必须需要的。一般情况下linux主机都会安装了gcc编译器，但是为确保之后的操作不会出现大问题，建议检查下gcc以及版本是否为对应的版本。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># gcc --version</div><div class="line">gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-4)</div></pre></td></tr></table></figure>
<p><strong>2.4 检测系统是否有正确的内核头文件以及一些开发包是否安装</strong></p>
<p>CUDA驱动需要内核头文件和开发工具包来保证驱动程序的安装以及rebuilt，比如你的内核版本为<code>3.17.4-301</code>，那么<code>3.17.4-301</code>的内核头文件以及相关的开发包也必须安装。</p>
<p>当驱动程序的安装过程没有进行包的验证，在使用RPM或者DEB包安装驱动的时候如果系统上没有安装正确的软件包，它将会尝试去安装内核头文件以及开发工具包。但是通常情况下，这种安装会默认去寻找仓库中最新版本的软件包，可能会导致内核版本的不匹配等问题。因此，在安装CUDA驱动之前，最好手动确认内核头文件的版本以及开发工具包的安装。</p>
<p>在centos系统上可以执行如下命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"># uname -r</div><div class="line">3.10.0-327.el7.x86_64</div><div class="line"></div><div class="line"># yum install kernel-devel-$(uname -r) kernel-headers-$(uname -r) -y</div></pre></td></tr></table></figure></p>
<p><strong>2.5 选择安装方式</strong></p>
<p>官方有两种方式去安装： distribution-specific packages (RPM and Deb packages)和distribution-independent package (runfile packages)。其中前者对接了linux发行版原生的包管理系统，是强烈建议的一种安装方式。</p>
<p><strong>2.6 下载NVIDIA CUDA Toolkit</strong></p>
<p><a href="http://developer.nvidia.com/cuda-downloads" target="_blank" rel="external">下载地址</a><br>根据当前系统的基础状况来选择相对应的版本。<br><img src="http://oyep1jupk.bkt.clouddn.com/docker/nvidia-docker/nvidia-toolkit.png" alt="NVIDIA CUDA Toolkit"></p>
<p>可以看到安装类型支持两种方式<code>runfile</code>和<code>rpm</code>,其中rpm方式又分为<code>local</code>和<code>network</code>方式，由于我们的宿主机不能直接访问外网，先使用rpm（local）方式进行安装下载。</p>
<p>下载完成之后需要使用<code>md5sum</code>进行文件验证，以保证最终的包一致性。官方提供的checksums文件被损坏，暂时无法检验。</p>
<p><strong>2.7 处理安装冲突的一些方法</strong></p>
<p>在安装CUDA之前，任何可能冲突的安装包都需要被卸载。<br>以下为相关细节。</p>
<p><img src="http://oyep1jupk.bkt.clouddn.com/docker/nvidia-docker/conflict-specifics.png" alt=""></p>
<p>使用如下方式去卸载相关的冲突包。</p>
<p>卸载runfile方式的Toolkit :<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/usr/local/cuda-X.Y/bin/uninstall_cuda_X.Y.pl</div></pre></td></tr></table></figure></p>
<p>卸载runfile方式的Driver：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/usr/bin/nvidia-uninstall</div></pre></td></tr></table></figure></p>
<p>卸载RPM/Deb方式安装的包：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ yum remove &lt;package_name&gt;                      # Redhat/CentOS</div><div class="line">$ dnf remove &lt;package_name&gt;                      # Fedora</div><div class="line">$ zypper remove &lt;package_name&gt;                   # OpenSUSE/SLES</div><div class="line">$ apt-get --purge remove &lt;package_name&gt;          # Ubuntu</div></pre></td></tr></table></figure></p>
<h4 id="安装包管理程序-Package-Manager"><a href="#安装包管理程序-Package-Manager" class="headerlink" title="安装包管理程序(Package Manager)"></a>安装包管理程序(Package Manager)</h4><p><a href="http://docs.nvidia.com/cuda/cuda-quick-start-guide/index.html#redhat-x86_64" target="_blank" rel="external">快速安装指南</a></p>
<p><strong>3.1 在Redhat/CentOS上安装</strong></p>
<ul>
<li>1.执行2中的操作</li>
<li>2.确认DKMS依赖<br> NVIDIA驱动的RPM包会依赖一些额外的包，比如说<code>DKMS</code>和<code>libvdpau</code>,这些包在系统默认的仓库中是不包含的，只存在与第三方镜像仓库，比如<a href="http://fedoraproject.org/wiki/EPEL" target="_blank" rel="external">EPEL</a>,因此在安装驱动之前，必须将第三方源添加到本地的仓库中，否则缺失依赖会阻止安装继续进行。</li>
<li><p>3.如果需要，自定义xorg.conf文件<br>驱动会依赖一个自动生成的xorg.conf文件<code>/etc/X11/xorg.conf</code>，该文件可能会影响驱动的正常工作，可以删除该文件，或者添加<code>/etc/X11/xorg.conf.d/00-nvidia.conf</code>的内容到xorg.conf文件中。</p>
</li>
<li><p>4.安装meta-data仓库</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"># rpm --install cuda-repo-&lt;distro&gt;-&lt;version&gt;.&lt;architecture&gt;.rpm</div></pre></td></tr></table></figure>
<ul>
<li>5.清除仓库缓存</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"># yum clean expire-cache</div></pre></td></tr></table></figure>
<ul>
<li>6.安装CUDA</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"># yum install cuda</div></pre></td></tr></table></figure>
<p>如果i686的libvdpau包安装失败，可以尝试以下步骤来修复该问题。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># yumdownloader libvdpau.i686</div><div class="line"># sudo rpm -U --oldpackage libvdpau*.rpm</div></pre></td></tr></table></figure>
<ul>
<li>7.如果需要，添加libcuda.so的软连接</li>
</ul>
<p>libcuda.so库文件被安装在<code>/usr/lib{,64}/nvidia</code>目录，如果已运行的项目需要使用libcuda.so文件，可以添加一个软连接到<code>/usr/lib{,64}</code>目录。</p>
<ul>
<li>8.执行<a href="http://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions" target="_blank" rel="external">安装后操作</a></li>
</ul>
<p><strong>3.2 包管理器的额外功能</strong></p>
<p><img src="http://oyep1jupk.bkt.clouddn.com/docker/nvidia-docker/meta-packages.png" alt="cuda核心包"></p>
<h4 id="安装后操作"><a href="#安装后操作" class="headerlink" title="安装后操作"></a>安装后操作</h4><p><strong>4.1 必须执行的操作</strong></p>
<p>一些操作行为必须在安装后并且在使用CUDA Toolkit和Driver之前去执行。</p>
<p>4.1.1 环境设置</p>
<p><code>PATH</code>环境变量必须包含<code>/usr/local/cuda-8.0/bin</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">export PATH=/usr/local/cuda-8.0/bin$&#123;PATH:+:$&#123;PATH&#125;&#125;</div></pre></td></tr></table></figure></p>
<p><code>注意：</code>在使用runfile方式安装的时候，动态链接库<code>LD_LIBRARY_PATH</code>的环境变量需要包含<code>/usr/local/cuda-8.0/lib64</code>.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ export LD_LIBRARY_PATH=/usr/local/cuda-9.0/lib64\</div><div class="line">                         $&#123;LD_LIBRARY_PATH:+:$&#123;LD_LIBRARY_PATH&#125;&#125;</div></pre></td></tr></table></figure></p>
<p><strong>4.2 强烈推荐的操作</strong></p>
<p>4.2.1 安装可写的示例程序</p>
<p>为了修改，编译以及运行样品，样品程序必须也可写权限进行安装，安装脚本如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"># cuda-install-samples-8.0.sh &lt;dir&gt;</div></pre></td></tr></table></figure></p>
<p>该脚本会创建一个<code>/usr/local/cuda/samples</code>的只读拷贝，需要将拷贝的内容改为可写。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"># cuda-install-samples-8.0.sh /export/biaoge/cuda-samples</div><div class="line"></div><div class="line"># tree -L 2 /export/biaoge/cuda-samples/</div><div class="line">/export/biaoge/cuda-samples/</div><div class="line">└── NVIDIA_CUDA-8.0_Samples</div><div class="line">    ├── 0_Simple</div><div class="line">    ├── 1_Utilities</div><div class="line">    ├── 2_Graphics</div><div class="line">    ├── 3_Imaging</div><div class="line">    ├── 4_Finance</div><div class="line">    ├── 5_Simulations</div><div class="line">    ├── 6_Advanced</div><div class="line">    ├── 7_CUDALibraries</div><div class="line">    ├── bin</div><div class="line">    ├── common</div><div class="line">    ├── EULA.txt</div><div class="line">    ├── Makefile</div><div class="line">    └── uninstall_cuda_samples_8.0.pl</div></pre></td></tr></table></figure>
<p>4.2.2 验证所有的安装</p>
<p>在继续操作之前，验证一下<code>CUDA Toolkit</code>能够识别到正确的GPU硬件设备是非常重要的。因此这里需要编译一些样品程序来进行检验。</p>
<p>(1)验证驱动版本<br>如果安装了确定，需要验证下加载驱动的版本是否正确，如果没有安装驱动或者没有用过内核模块来加载，可以暂时跳过该步骤。</p>
<p>当驱动被加载后，可以通过如下命令查看到驱动的版本</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"># cat /proc/driver/nvidia/version</div><div class="line">NVRM version: NVIDIA UNIX x86_64 Kernel Module  375.39  Tue Jan 31 20:47:00 PST 2017</div><div class="line">GCC version:  gcc version 4.8.5 20150623 (Red Hat 4.8.5-4) (GCC)</div></pre></td></tr></table></figure>
<p>(2) 编译样品程序<br>CUDA Toolkit的版本可以使用<code>nvcc --version/-V</code>查看，该命令运行编译驱动来编译CUDA程序，底层其实调用了gcc编译器来编译c代码，使用<code>NVIDIA PTX</code>编译器来调用CUDA代码。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"># nvcc -V</div><div class="line">nvcc: NVIDIA (R) Cuda compiler driver</div><div class="line">Copyright (c) 2005-2016 NVIDIA Corporation</div><div class="line">Built on Tue_Jan_10_13:22:03_CST_2017</div><div class="line">Cuda compilation tools, release 8.0, V8.0.61</div></pre></td></tr></table></figure>
<p>NVIDIA CUDA Toolkit在源文件中包含了一些示例程序，用户可以通过修改<code>~/NVIDIA_CUDA-8.0_Samples</code>并执行<code>make</code>来编译这些示例程序。编译的二进制文件将存放在<code>~/NVIDIA_CUDA-8.0_Samples/bin</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"># cd /export/biaoge/cuda-samples/NVIDIA_CUDA-8.0_Samples/1_Utilities/deviceQuery</div><div class="line"></div><div class="line">#编译生成deviceQuery二进制文件，在(3)中需要验证环境</div><div class="line"># make</div><div class="line"></div><div class="line"># cd /export/biaoge/cuda-samples/NVIDIA_CUDA-8.0_Samples/1_Utilities/bandwidthTest</div><div class="line"></div><div class="line">#编译生成bandwidthTest二进制文件，在(3)中用来验证环境</div><div class="line"># make</div><div class="line"></div><div class="line"># ll ../bandwidthTest/bandwidthTest</div><div class="line">-rwxr-xr-x 1 root root 603420 Oct 18 16:05 ../bandwidthTest/bandwidthTest</div><div class="line"># ll ../deviceQuery/deviceQuery</div><div class="line">-rwxr-xr-x 1 root root 582882 Oct 18 16:44 ../deviceQuery/deviceQuery</div></pre></td></tr></table></figure>
<p>(3) 运行二进制文件</p>
<p>编译完成之后，在<code>~/NVIDIA_CUDA-8.0_Samples</code>下对应目录下运行<code>deviceQuery</code>.如果CUDA程序被正确安装和配置，<code>deviceQuery</code>的输出应该看起来如下所示。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div></pre></td><td class="code"><pre><div class="line"># ./deviceQuery</div><div class="line">./deviceQuery Starting...</div><div class="line"></div><div class="line"> CUDA Device Query (Runtime API) version (CUDART static linking)</div><div class="line"></div><div class="line">Detected 4 CUDA Capable device(s)</div><div class="line"></div><div class="line">Device 0: &quot;Tesla M40 24GB&quot;</div><div class="line">  CUDA Driver Version / Runtime Version          8.0 / 8.0</div><div class="line">  CUDA Capability Major/Minor version number:    5.2</div><div class="line">  Total amount of global memory:                 22940 MBytes (24054136832 bytes)</div><div class="line">  (24) Multiprocessors, (128) CUDA Cores/MP:     3072 CUDA Cores</div><div class="line">  GPU Max Clock rate:                            1112 MHz (1.11 GHz)</div><div class="line">  Memory Clock rate:                             3004 Mhz</div><div class="line">  Memory Bus Width:                              384-bit</div><div class="line">  L2 Cache Size:                                 3145728 bytes</div><div class="line">  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)</div><div class="line">  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers</div><div class="line">  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers</div><div class="line">  Total amount of constant memory:               65536 bytes</div><div class="line">  Total amount of shared memory per block:       49152 bytes</div><div class="line">  Total number of registers available per block: 65536</div><div class="line">  Warp size:                                     32</div><div class="line">  Maximum number of threads per multiprocessor:  2048</div><div class="line">  Maximum number of threads per block:           1024</div><div class="line">  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)</div><div class="line">  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)</div><div class="line">  Maximum memory pitch:                          2147483647 bytes</div><div class="line">  Texture alignment:                             512 bytes</div><div class="line">  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)</div><div class="line">  Run time limit on kernels:                     No</div><div class="line">  Integrated GPU sharing Host Memory:            No</div><div class="line">  Support host page-locked memory mapping:       Yes</div><div class="line">  Alignment requirement for Surfaces:            Yes</div><div class="line">  Device has ECC support:                        Enabled</div><div class="line">  Device supports Unified Addressing (UVA):      Yes</div><div class="line">  Device PCI Domain ID / Bus ID / location ID:   0 / 4 / 0</div><div class="line">  Compute Mode:</div><div class="line">     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;</div><div class="line"></div><div class="line">Device 1: &quot;Tesla M40&quot;</div><div class="line">  CUDA Driver Version / Runtime Version          8.0 / 8.0</div><div class="line">  CUDA Capability Major/Minor version number:    5.2</div><div class="line">  Total amount of global memory:                 11443 MBytes (11998855168 bytes)</div><div class="line">  (24) Multiprocessors, (128) CUDA Cores/MP:     3072 CUDA Cores</div><div class="line">  GPU Max Clock rate:                            1112 MHz (1.11 GHz)</div><div class="line">  Memory Clock rate:                             3004 Mhz</div><div class="line">  Memory Bus Width:                              384-bit</div><div class="line">  L2 Cache Size:                                 3145728 bytes</div><div class="line">  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)</div><div class="line">  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers</div><div class="line">  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers</div><div class="line">  Total amount of constant memory:               65536 bytes</div><div class="line">  Total amount of shared memory per block:       49152 bytes</div><div class="line">  Total number of registers available per block: 65536</div><div class="line">  Warp size:                                     32</div><div class="line">  Maximum number of threads per multiprocessor:  2048</div><div class="line">  Maximum number of threads per block:           1024</div><div class="line">  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)</div><div class="line">  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)</div><div class="line">  Maximum memory pitch:                          2147483647 bytes</div><div class="line">  Texture alignment:                             512 bytes</div><div class="line">  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)</div><div class="line">  Run time limit on kernels:                     No</div><div class="line">  Integrated GPU sharing Host Memory:            No</div><div class="line">  Support host page-locked memory mapping:       Yes</div><div class="line">  Alignment requirement for Surfaces:            Yes</div><div class="line">  Device has ECC support:                        Enabled</div><div class="line">  Device supports Unified Addressing (UVA):      Yes</div><div class="line">  Device PCI Domain ID / Bus ID / location ID:   0 / 5 / 0</div><div class="line">  Compute Mode:</div><div class="line">     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;</div><div class="line"></div><div class="line">Device 2: &quot;Tesla M40 24GB&quot;</div><div class="line">  CUDA Driver Version / Runtime Version          8.0 / 8.0</div><div class="line">  CUDA Capability Major/Minor version number:    5.2</div><div class="line">  Total amount of global memory:                 22940 MBytes (24054136832 bytes)</div><div class="line">  (24) Multiprocessors, (128) CUDA Cores/MP:     3072 CUDA Cores</div><div class="line">  GPU Max Clock rate:                            1112 MHz (1.11 GHz)</div><div class="line">  Memory Clock rate:                             3004 Mhz</div><div class="line">  Memory Bus Width:                              384-bit</div><div class="line">  L2 Cache Size:                                 3145728 bytes</div><div class="line">  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)</div><div class="line">  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers</div><div class="line">  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers</div><div class="line">  Total amount of constant memory:               65536 bytes</div><div class="line">  Total amount of shared memory per block:       49152 bytes</div><div class="line">  Total number of registers available per block: 65536</div><div class="line">  Warp size:                                     32</div><div class="line">  Maximum number of threads per multiprocessor:  2048</div><div class="line">  Maximum number of threads per block:           1024</div><div class="line">  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)</div><div class="line">  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)</div><div class="line">  Maximum memory pitch:                          2147483647 bytes</div><div class="line">  Texture alignment:                             512 bytes</div><div class="line">  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)</div><div class="line">  Run time limit on kernels:                     No</div><div class="line">  Integrated GPU sharing Host Memory:            No</div><div class="line">  Support host page-locked memory mapping:       Yes</div><div class="line">  Alignment requirement for Surfaces:            Yes</div><div class="line">  Device has ECC support:                        Enabled</div><div class="line">  Device supports Unified Addressing (UVA):      Yes</div><div class="line">  Device PCI Domain ID / Bus ID / location ID:   0 / 6 / 0</div><div class="line">  Compute Mode:</div><div class="line">     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;</div><div class="line"></div><div class="line">Device 3: &quot;Tesla M40&quot;</div><div class="line">  CUDA Driver Version / Runtime Version          8.0 / 8.0</div><div class="line">  CUDA Capability Major/Minor version number:    5.2</div><div class="line">  Total amount of global memory:                 11443 MBytes (11998855168 bytes)</div><div class="line">  (24) Multiprocessors, (128) CUDA Cores/MP:     3072 CUDA Cores</div><div class="line">  GPU Max Clock rate:                            1112 MHz (1.11 GHz)</div><div class="line">  Memory Clock rate:                             3004 Mhz</div><div class="line">  Memory Bus Width:                              384-bit</div><div class="line">  L2 Cache Size:                                 3145728 bytes</div><div class="line">  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)</div><div class="line">  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers</div><div class="line">  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers</div><div class="line">  Total amount of constant memory:               65536 bytes</div><div class="line">  Total amount of shared memory per block:       49152 bytes</div><div class="line">  Total number of registers available per block: 65536</div><div class="line">  Warp size:                                     32</div><div class="line">  Maximum number of threads per multiprocessor:  2048</div><div class="line">  Maximum number of threads per block:           1024</div><div class="line">  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)</div><div class="line">  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)</div><div class="line">  Maximum memory pitch:                          2147483647 bytes</div><div class="line">  Texture alignment:                             512 bytes</div><div class="line">  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)</div><div class="line">  Run time limit on kernels:                     No</div><div class="line">  Integrated GPU sharing Host Memory:            No</div><div class="line">  Support host page-locked memory mapping:       Yes</div><div class="line">  Alignment requirement for Surfaces:            Yes</div><div class="line">  Device has ECC support:                        Enabled</div><div class="line">  Device supports Unified Addressing (UVA):      Yes</div><div class="line">  Device PCI Domain ID / Bus ID / location ID:   0 / 7 / 0</div><div class="line">  Compute Mode:</div><div class="line">     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;</div><div class="line">&gt; Peer access from Tesla M40 24GB (GPU0) -&gt; Tesla M40 (GPU1) : Yes</div><div class="line">&gt; Peer access from Tesla M40 24GB (GPU0) -&gt; Tesla M40 24GB (GPU2) : Yes</div><div class="line">&gt; Peer access from Tesla M40 24GB (GPU0) -&gt; Tesla M40 (GPU3) : Yes</div><div class="line">&gt; Peer access from Tesla M40 (GPU1) -&gt; Tesla M40 24GB (GPU0) : Yes</div><div class="line">&gt; Peer access from Tesla M40 (GPU1) -&gt; Tesla M40 24GB (GPU2) : Yes</div><div class="line">&gt; Peer access from Tesla M40 (GPU1) -&gt; Tesla M40 (GPU3) : Yes</div><div class="line">&gt; Peer access from Tesla M40 24GB (GPU2) -&gt; Tesla M40 24GB (GPU0) : Yes</div><div class="line">&gt; Peer access from Tesla M40 24GB (GPU2) -&gt; Tesla M40 (GPU1) : Yes</div><div class="line">&gt; Peer access from Tesla M40 24GB (GPU2) -&gt; Tesla M40 (GPU3) : Yes</div><div class="line">&gt; Peer access from Tesla M40 (GPU3) -&gt; Tesla M40 24GB (GPU0) : Yes</div><div class="line">&gt; Peer access from Tesla M40 (GPU3) -&gt; Tesla M40 (GPU1) : Yes</div><div class="line">&gt; Peer access from Tesla M40 (GPU3) -&gt; Tesla M40 24GB (GPU2) : Yes</div><div class="line"></div><div class="line">deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 8.0, CUDA Runtime Version = 8.0, NumDevs = 4, Device0 = Tesla M40 24GB, Device1 = Tesla M40, Device2 = Tesla M40 24GB, Device3 = Tesla M40</div><div class="line">Result = PASS</div></pre></td></tr></table></figure>
<p><img src="http://oyep1jupk.bkt.clouddn.com/docker/nvidia-docker/cuda-sample.png" alt="官方文档中的示例程序"></p>
<p><code>注意：</code>如果CUDA-capable设备和CUDA 驱动都已经成功安装，但是<code>deviceQuery</code>程序报告没有<code>CUDA-capable</code>设备在线，这个可能是<code>/dev/nvidia*</code>相关文件丢失或者没有相应的权限。</p>
<p>可以使用<code>setenforce 0</code>关闭SELinux后再进行测试。</p>
<p>运行<code>bandwidthTest</code>程序来确认系统和CUDA-capable设备可以正常通信，输出结果如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"># ./bandwidthTest</div><div class="line">[CUDA Bandwidth Test] - Starting...</div><div class="line">Running on...</div><div class="line"></div><div class="line"> Device 0: Tesla M40 24GB</div><div class="line"> Quick Mode</div><div class="line"></div><div class="line"> Host to Device Bandwidth, 1 Device(s)</div><div class="line"> PINNED Memory Transfers</div><div class="line">   Transfer Size (Bytes)	Bandwidth(MB/s)</div><div class="line">   33554432			11710.6</div><div class="line"></div><div class="line"> Device to Host Bandwidth, 1 Device(s)</div><div class="line"> PINNED Memory Transfers</div><div class="line">   Transfer Size (Bytes)	Bandwidth(MB/s)</div><div class="line">   33554432			12464.9</div><div class="line"></div><div class="line"> Device to Device Bandwidth, 1 Device(s)</div><div class="line"> PINNED Memory Transfers</div><div class="line">   Transfer Size (Bytes)	Bandwidth(MB/s)</div><div class="line">   33554432			210964.2</div><div class="line"></div><div class="line">Result = PASS</div><div class="line"></div><div class="line">NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.</div></pre></td></tr></table></figure>
<p><img src="http://oyep1jupk.bkt.clouddn.com/docker/nvidia-docker/cuda-sample-1.png" alt="官方文档中的示例程序"></p>
<p>上图表示测试通过，如果测试没有通过，可以确认下系统上CUDA-capable NVIDIA GPU是否正确安装。</p>
<p><code>注意：如果上述两个示例程序都可以正常输出，name恭喜您，GPU环境目前已经可用了！</code></p>
<p>4.2.3  安装Nsight Eclipse plugins</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"># /usr/local/cuda-9.0/bin/nsight_ee_plugins_manage.sh install &lt;eclipse-dir&gt;</div></pre></td></tr></table></figure>
<p><strong>4.3 可选的操作</strong></p>
<p>在使用CUDA Toolkit中，有很多可选操作但是不是必须的但是可以提供额外的功能。</p>
<p>4.3.1 安装第三方库文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># yum install freeglut-devel libX11-devel libXi-devel libXmu-devel \</div><div class="line">    make mesa-libGLU-devel</div></pre></td></tr></table></figure></p>
<p>4.3.2 为cuda-gdb安装源代码<br>使用<code>runfile</code>方式安装后<code>cuda-gdb</code>源代码会自动安装。</p>
<p>使用RPM或者Deb方式安装，需要为cuda-gbd拷贝一份源代码。<code>cuda-gdb-src</code>包必须被安装。源码包会被以一个tar包的方式安装在<code>/usr/local/cuda-9.0/extras</code>目录。</p>
<p><a href="http://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html" target="_blank" rel="external">原文地址</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;背景：&quot;&gt;&lt;a href=&quot;#背景：&quot; class=&quot;headerlink&quot; title=&quot;背景：&quot;&gt;&lt;/a&gt;背景：&lt;/h3&gt;&lt;p&gt;随着大数据、人工智能以及机器学习等技术的发展，CPU计算资源已经不能满足很多计算场景，而随着硬件技术的发展，越来越多的人工智能以及机器学习领域开始使用GPU进行计算任务。而GPU环境以及具体的应用方式又给真正做人工智能相关的同学造成了很多困扰，本系列文章将分为三篇，将介绍如何搭建部署GPU环境，使用Docker进行管理GPU容器，使用Kubernetes来调度GPU容器。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.jianshu.com/p/e72a352a2bd7&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;从GPU到GPGPU&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.jianshu.com/p/609e0530a19c&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;CPU与GPU&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Docker" scheme="http://yoursite.com/categories/Docker/"/>
    
    
      <category term="Docker" scheme="http://yoursite.com/tags/Docker/"/>
    
      <category term="GPU" scheme="http://yoursite.com/tags/GPU/"/>
    
      <category term="AI" scheme="http://yoursite.com/tags/AI/"/>
    
      <category term="NVIDIA" scheme="http://yoursite.com/tags/NVIDIA/"/>
    
      <category term="NVIDIA-Docker" scheme="http://yoursite.com/tags/NVIDIA-Docker/"/>
    
  </entry>
  
  <entry>
    <title>ITers们,请注意你们的身体</title>
    <link href="http://yoursite.com/2017/09/14/ITers%E4%BB%AC-%E8%AF%B7%E6%B3%A8%E6%84%8F%E4%BD%A0%E4%BB%AC%E7%9A%84%E8%BA%AB%E4%BD%93/"/>
    <id>http://yoursite.com/2017/09/14/ITers们-请注意你们的身体/</id>
    <published>2017-09-13T19:05:39.000Z</published>
    <updated>2017-09-16T15:26:45.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近加班也不算太严重，不过因为赶上新项目的开工，需要花费一些额外的功夫去研究一些技术的使用场景，连续劳累了一个月之后，最终的结果就是不管晚上几点睡，第二天从来不会自动醒过来，并且随之而来身体上的体验就是左眼皮不停的再跳，跳到你感觉心烦仍不罢休，有天我还专门和朋友同事开玩笑说，“可能最近会有什么喜事吧，左眼睛一直在跳”。后来我还专门在知乎，以及贴吧之类的论坛上去查找一些相关的信息，得到一致的结论就是：有个毛线的喜事，是因为你缺觉！</p>
<a id="more"></a>
<p>好吧，看来在一段时间内，如果作息还有生活不规律，身体会提前给你警告。</p>
<p>其实搞it经常都会有两两种身体上的问题：一个是颈椎不好，另外一个是腰不好。这两个问题可算是在我身体上体现的淋漓尽致了，因为我在这两个问题上面可算是吃了不少苦头，导致我现在是按摩院和健身房的常客，经常回去做个肩颈按摩或者去健身房跑跑步，为的就是能够稍微减轻一些身体上的痛苦，同时也能够更加保重自己的身体。</p>
<p>上周五的时候，突然感觉腰有点不舒服，也就没有在意就去准备参加太原马拉松去了，整个马拉松跑的很爽很溜，毕竟是人生第一次跑马，最终也跑到了自己期望的成绩。</p>
<p><img src="/images/tymls-1.jpeg" alt="太马奖牌"><br><img src="/images/tymls-2.jpeg" alt="太马成绩"><br><img src="/images/tymls-3.jpeg" alt="太马路线"></p>
<p>跑完整个马拉松之后的这几天里，身体到没有其他部位的不舒服，但唯独腰却很不舒服，不能久坐，时间一长就会感觉到一种难以言表的疼痛。看过医生并且去中医按摩的结果是，坐姿不正和长时间坐着办公造成的腰肌轻微劳损。So，最近不得不站着办公，没事的时候，也会刻意的去捶捶腰。突然之间感觉搞我们这行的还蛮辛苦的，以后还是得更加注意身体。</p>
<p>本以为我挺辛苦的，昨晚八点多一业务开发来找我帮他们处理问题，我说你们为啥一到下班七八点就来找我呢？为啥不在上班时间找我处理呢？他说了句，“哥啊，我们哪有下班和上班的时间区分啊！”，真的感觉他们比我们要辛苦多了。后来想了想，的确是，他们那些业务研发，经常为了赶项目进度连续好些天工作到凌晨一二点，然后早上九点前又按时来公司上班。所以这也就不难理解，为啥搞it得经常会出现一些意外的情况，但我还是觉得，工作再怎么重要，还是得注意休息，保重身体，不然业务做的再好，钱赚的再多，又有毛用呢，已经脱离了我们来到这个世上的最初的目标。</p>
<p>所以，那些搞IT的兄弟姐们们，还是建议你们平时注意下自己的身体状况，多锻炼锻炼，加班干活适可而止就行了！<br><!--more--></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近加班也不算太严重，不过因为赶上新项目的开工，需要花费一些额外的功夫去研究一些技术的使用场景，连续劳累了一个月之后，最终的结果就是不管晚上几点睡，第二天从来不会自动醒过来，并且随之而来身体上的体验就是左眼皮不停的再跳，跳到你感觉心烦仍不罢休，有天我还专门和朋友同事开玩笑说，“可能最近会有什么喜事吧，左眼睛一直在跳”。后来我还专门在知乎，以及贴吧之类的论坛上去查找一些相关的信息，得到一致的结论就是：有个毛线的喜事，是因为你缺觉！&lt;/p&gt;
    
    </summary>
    
      <category term="生活思考" scheme="http://yoursite.com/categories/%E7%94%9F%E6%B4%BB%E6%80%9D%E8%80%83/"/>
    
    
      <category term="工作" scheme="http://yoursite.com/tags/%E5%B7%A5%E4%BD%9C/"/>
    
      <category term="生活" scheme="http://yoursite.com/tags/%E7%94%9F%E6%B4%BB/"/>
    
      <category term="感悟" scheme="http://yoursite.com/tags/%E6%84%9F%E6%82%9F/"/>
    
  </entry>
  
  <entry>
    <title>Dockerfile-etcd</title>
    <link href="http://yoursite.com/2017/08/26/Dockerfile-etcd/"/>
    <id>http://yoursite.com/2017/08/26/Dockerfile-etcd/</id>
    <published>2017-08-26T09:56:15.000Z</published>
    <updated>2017-08-29T15:43:53.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>本篇文章手把手教你如何使用Dockerfile构建自己etcd镜像，并且已经提供基于etcd3.0.10 的image供读者使用，用户可以快速使用docker image构建自己的etcd集群环境</p>
</blockquote>
<a id="more"></a>
<h3 id="一、etcd镜像的Dockerfile文件结构"><a href="#一、etcd镜像的Dockerfile文件结构" class="headerlink" title="一、etcd镜像的Dockerfile文件结构"></a>一、etcd镜像的Dockerfile文件结构</h3><p><code>注意：优秀的docker镜像源文件都是会尝试去除所有依赖的，也即是该文件无论被谁拿走使用，都可以快速构建属于自己的image</code></p>
<p>etcd镜像的Dockerfile项目文件结构：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div></pre></td><td class="code"><pre><div class="line">$ tree .</div><div class="line">.</div><div class="line">├──Dockerfile</div><div class="line">├──docker-entrypoint.sh</div><div class="line"></div><div class="line"></div><div class="line"># Dockerfile 文件</div><div class="line">$ cat Dockerfile</div><div class="line">FROM centos-biaoge</div><div class="line">MAINTAINER 371990778@qq.com</div><div class="line">ENV LANG=zh_CN.UTF-8;\</div><div class="line">    LC_ALL=zh_CN.UTF-8;\</div><div class="line">    TZ=&quot;Asia/Shanghai&quot;;\</div><div class="line">    TERM=xterm;\</div><div class="line">    DOWNLOAD=https://github.com/coreos/etcd/releases/download/v3.0.10/ \</div><div class="line">    ETCDVERSION=etcd-v3.0.10-linux-amd64 \</div><div class="line">    USER=admin </div><div class="line">RUN yum install mkdir curl wget tar chown unzip -y;\</div><div class="line">    useradd $&#123;USER&#125; ;\</div><div class="line">    mkdir -p /export/&#123;servers,Logs,packages,Apps,Shell&#125;;\</div><div class="line">    wget $&#123;DOWNLOAD&#125;$&#123;ETCDVERSION&#125;.tar.gz &amp;&amp; tar -zxf $&#123;ETCDVERSION&#125;.tar.gz -C /export/servers/ &amp;&amp; \</div><div class="line">    /bin/rm -rf $&#123;ETCDVERSION&#125;.tar.gz;\</div><div class="line">    chown -R $&#123;USER&#125;.$&#123;USER&#125; /export ;\</div><div class="line">    ln -s /export/servers/$&#123;ETCDVERSION&#125;/etcd* /usr/bin/;</div><div class="line">EXPOSE 2379 2380</div><div class="line">COPY docker-entrypoint.sh /</div><div class="line">ENTRYPOINT [&quot;/docker-entrypoint.sh&quot;]</div><div class="line"></div><div class="line"># 镜像启动脚本</div><div class="line">$ cat docker-entrypoint.sh</div><div class="line">#!/bin/bash</div><div class="line">#Filename:docker-entrypoint.sh</div><div class="line">#Author_by:Andy_xu </div><div class="line">#Contact:[mail:371990778@qq.com,QQ:371990778]</div><div class="line">#Date:2017-07-25 16:42</div><div class="line">#Description:</div><div class="line">if [ -z $NAME ];then</div><div class="line">	NAME=my-etcd-1</div><div class="line">fi</div><div class="line">if [ -z $DATADIR ];then</div><div class="line">	DATADIR=/export/etcd_data</div><div class="line">fi</div><div class="line">if [ -z $MYHOST ];then</div><div class="line">	MYHOST=http://localhost</div><div class="line">fi</div><div class="line">if [ -z $PORT ];then</div><div class="line">        PORT=2379</div><div class="line">fi</div><div class="line">if [ -z $CLUSTER_PORT ];then</div><div class="line">        CLUSTER_PORT=2380</div><div class="line">fi</div><div class="line">if [ -z $CLUSTER ];then </div><div class="line">	CLUSTER=my-etcd-1=http://localhost:2380</div><div class="line">fi</div><div class="line">if [ -z $CLUSTER_TOKEN ];then </div><div class="line">	CLUSTER_TOKEN=my-etcd-token</div><div class="line">fi</div><div class="line">if [ -z $CLUSTER_STATE ];then</div><div class="line">	CLUSTER_STATE=new</div><div class="line">fi</div><div class="line">	</div><div class="line">ETCD_CMD=&quot;etcd --name $&#123;NAME&#125; --data-dir $&#123;DATADIR&#125;  \</div><div class="line">	--listen-client-urls http://0.0.0.0:$&#123;PORT&#125;  \</div><div class="line">	--advertise-client-urls $&#123;MYHOST&#125;:$&#123;PORT&#125; \</div><div class="line">  	--listen-peer-urls $&#123;MYHOST&#125;:$&#123;CLUSTER_PORT&#125; \</div><div class="line">	--initial-advertise-peer-urls $&#123;MYHOST&#125;:$&#123;CLUSTER_PORT&#125; \</div><div class="line">	--initial-cluster $CLUSTER  \</div><div class="line">	 --initial-cluster-token $CLUSTER_TOKEN \</div><div class="line">	--initial-cluster-state $&#123;CLUSTER_STATE&#125; \</div><div class="line">	$*&quot;</div><div class="line">echo -e &quot;Running &apos;$ETCD_CMD&apos;\nBEGIN ETCD OUTPUT\n&quot;</div><div class="line">exec $ETCD_CMD</div></pre></td></tr></table></figure>
<h3 id="二、构建并使用image"><a href="#二、构建并使用image" class="headerlink" title="二、构建并使用image"></a>二、构建并使用image</h3><p><strong>1.构建etcd的image</strong></p>
<p>进入项目路径下，执行以下命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ docker build -t xxbandy123/etcd:3.0.10</div></pre></td></tr></table></figure></p>
<p><strong>2.使用默认参数创建etcd单实例</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ docker run -itd --name etcd-1 xxbandy123/etcd:3.0.10  --auto-compaction-retention 1</div></pre></td></tr></table></figure>
<p><code>注意：后面的 --auto-compaction-retention 1 为额外增加的参数表示1小时自动压缩保留
默认的容器启动后面都可以增加额外的参数</code></p>
<p><strong>3.使用自定义的参数进行创建etcd单实例</strong></p>
<p>image内部定义的默认参数如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">NAME=my-etcd-1</div><div class="line">DATADIR=/export/etcd_data</div><div class="line">MYHOST=http://localhost</div><div class="line">PORT=2379</div><div class="line">CLUSTER_PORT=2380</div><div class="line">CLUSTER=my-etcd-1=http://localhost:2380</div><div class="line">CLUSTER_TOKEN=my-etcd-token</div><div class="line">CLUSTER_STATE=new</div><div class="line"></div><div class="line"></div><div class="line">etcd --name $&#123;NAME&#125; --data-dir $&#123;DATADIR&#125;  \</div><div class="line">    --listen-client-urls http://0.0.0.0:$&#123;PORT&#125;  \</div><div class="line">    --advertise-client-urls $&#123;MYHOST&#125;:$&#123;PORT&#125; \</div><div class="line">    --listen-peer-urls $&#123;MYHOST&#125;:$&#123;CLUSTER_PORT&#125; \</div><div class="line">    --initial-advertise-peer-urls $&#123;MYHOST&#125;:$&#123;CLUSTER_PORT&#125; \</div><div class="line">    --initial-cluster $CLUSTER  \</div><div class="line">     --initial-cluster-token $CLUSTER_TOKEN \</div><div class="line">    --initial-cluster-state $&#123;CLUSTER_STATE&#125;</div></pre></td></tr></table></figure>
<p>可以通过环境变量的方式启动单实例的etcd，也可以将该image传入不通变量去构造集群</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ docker run -itd -e DATADIR=/root/etcd_data -e CLUSTER_TOKEN=biaoge xxbandy123/etcd:3.0.10 --auto-compaction-retention 1</div></pre></td></tr></table></figure>
<p><strong>4.如何使用etcd</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">docker pull xxbandy123/etcd:3.0.10</div><div class="line"></div><div class="line"># docker  ps -l</div><div class="line">CONTAINER ID        IMAGE                            COMMAND                  CREATED             STATUS              PORTS                                            NAMES</div><div class="line">e17c9479b424        xxbandy123/etcd:3.0.10   &quot;/docker-entrypoint.s&quot;   19 seconds ago      Up 17 seconds       0.0.0.0:1025-&gt;2379/tcp, 0.0.0.0:1024-&gt;2380/tcp   sharp_keller</div><div class="line"></div><div class="line"># docker  exec -it sharp_keller etcdctl set test biaoge</div><div class="line">biaoge</div><div class="line"></div><div class="line"># curl -s localhost:1025/v2/keys/test | jq .</div><div class="line">&#123;</div><div class="line">  &quot;node&quot;: &#123;</div><div class="line">    &quot;createdIndex&quot;: 4,</div><div class="line">    &quot;modifiedIndex&quot;: 4,</div><div class="line">    &quot;value&quot;: &quot;biaoge&quot;,</div><div class="line">    &quot;key&quot;: &quot;/test&quot;</div><div class="line">  &#125;,</div><div class="line">  &quot;action&quot;: &quot;get&quot;</div><div class="line">&#125;</div><div class="line"></div><div class="line">在任何一个客户端去访问：</div><div class="line"># curl -s 10.241.131.109:1025/v2/keys/test | jq .</div><div class="line">&#123;</div><div class="line">  &quot;node&quot;: &#123;</div><div class="line">    &quot;createdIndex&quot;: 4,</div><div class="line">    &quot;modifiedIndex&quot;: 4,</div><div class="line">    &quot;value&quot;: &quot;biaoge&quot;,</div><div class="line">    &quot;key&quot;: &quot;/test&quot;</div><div class="line">  &#125;,</div><div class="line">  &quot;action&quot;: &quot;get&quot;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="三、自由发挥时间"><a href="#三、自由发挥时间" class="headerlink" title="三、自由发挥时间"></a>三、自由发挥时间</h3><p>由于该etcd实例可以通过环境变量传入参数，因此虽然是一个image，但是却非常灵活，用户可以在很快的时间内创建出来一个etcd集群。So，学会如何构建一个etcd镜像后，可以尝试下使用该image来快速构建一个etcd集群。</p>
<p>为方便大家的使用，该image已经上传到docker hub中，读者可以直接在本地pull后进行使用：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker pull xxbandy123/etcd:3.0.10</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本篇文章手把手教你如何使用Dockerfile构建自己etcd镜像，并且已经提供基于etcd3.0.10 的image供读者使用，用户可以快速使用docker image构建自己的etcd集群环境&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Docker" scheme="http://yoursite.com/categories/Docker/"/>
    
    
      <category term="Dockerfile" scheme="http://yoursite.com/tags/Dockerfile/"/>
    
      <category term="Etcd" scheme="http://yoursite.com/tags/Etcd/"/>
    
  </entry>
  
  <entry>
    <title>Ansible-Etcd-cluster</title>
    <link href="http://yoursite.com/2017/08/26/Ansible-Etcd-cluster/"/>
    <id>http://yoursite.com/2017/08/26/Ansible-Etcd-cluster/</id>
    <published>2017-08-26T07:51:12.000Z</published>
    <updated>2017-08-29T15:45:55.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>本篇文章记录一下使用<code>ansible-playbooks</code>进行快速构建一个可用的etcd集群。在阅读并实践本文章之前，请确保您有一个可用的<code>ansible</code>环境。</p>
</blockquote>
<a id="more"></a>
<h3 id="一、集群规划"><a href="#一、集群规划" class="headerlink" title="一、集群规划"></a>一、集群规划</h3><p><code>注意:本文档基于centos7+的操作系统上进行构建，在rhel7+系列也可用使用，其他发行版本可酌情参考</code></p>
<table>
<thead>
<tr>
<th>etcd_name</th>
<th>节点</th>
<th>端口</th>
</tr>
</thead>
<tbody>
<tr>
<td>etcd1</td>
<td>10.0.0.77</td>
<td>2379/2380</td>
</tr>
<tr>
<td>etcd2</td>
<td>10.0.0.78</td>
<td>2379/2380</td>
</tr>
<tr>
<td>etcd3</td>
<td>10.0.0.79</td>
<td>2379/2380</td>
</tr>
</tbody>
</table>
<p>以上节点详情信息用来规划集群规模以及名称角色，配置文件中<code>ETCD_INITIAL_CLUSTER</code>选项中的<code>etcd_name</code>和地址需要和主机规划中一致</p>
<h3 id="二、etcd集群部署"><a href="#二、etcd集群部署" class="headerlink" title="二、etcd集群部署"></a>二、etcd集群部署</h3><blockquote>
<p>环境前提：已经配置过ansible相关的环境，并且可以免密登录</p>
</blockquote>
<p><strong>1.etcd集群相关的配置文件</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div></pre></td><td class="code"><pre><div class="line">$ tree . </div><div class="line">.</div><div class="line">├──etcd-install.yml   #ansible-playbook 脚本</div><div class="line">├──etcd.conf.j2       #etcd主配置文件</div><div class="line">├──etcd.service       #systemd服务启动文件</div><div class="line">├──host               #etcd集群主机列表</div><div class="line"></div><div class="line"># ansible-playbooks 脚本</div><div class="line">$ cat etcd-install.yml</div><div class="line">---</div><div class="line">- hosts: &quot;&#123;&#123; host &#125;&#125;&quot;</div><div class="line">  remote_user: root</div><div class="line">  vars:</div><div class="line">    hostip: &quot;&#123;&#123; ansible_all_ipv4_addresses[0] &#125;&#125;&quot;</div><div class="line">    ipv6: &quot;&#123;&#123; ansible_all_ipv6_addresses[0].split(&apos;:&apos;)[-1] &#125;&#125;&quot;</div><div class="line">    packagedir: /tmp/</div><div class="line">    serverdir: /export/servers/</div><div class="line">    download: https://github.com/coreos/etcd/releases/</div><div class="line">    etcd_version: etcd-v3.1.5-linux-amd64</div><div class="line">  tasks:</div><div class="line">  - name: &quot;test ping&quot;</div><div class="line">    ping:</div><div class="line">  - name: &quot;init env&quot;</div><div class="line">    shell: &quot;mkdir -p /export/servers /etc/etcd/ /export/Data/etcd/ &quot;</div><div class="line"></div><div class="line"></div><div class="line">  - name: &quot;wget &#123;&#123; etcd_version &#125;&#125;&quot;</div><div class="line">    get_url:</div><div class="line">     url: &quot;&#123;&#123; item.url &#125;&#125;&quot;</div><div class="line">     dest: &quot;&#123;&#123; item.dest &#125;&#125;&quot;</div><div class="line">     mode: 0644</div><div class="line">     owner: root</div><div class="line">     group: root</div><div class="line">    with_items:</div><div class="line">        - &#123; url: &quot;&#123;&#123; download &#125;&#125;&#123;&#123; etcd_version &#125;&#125;.tar.gz&quot; , dest: &quot;&#123;&#123; packagedir &#125;&#125;&quot; &#125;</div><div class="line"></div><div class="line">  - name: &quot;untar the &#123;&#123; etcd_version &#125;&#125;&quot;</div><div class="line">    unarchive:</div><div class="line">     src: &quot;&#123;&#123; item.src &#125;&#125;&quot;</div><div class="line">     dest: &quot;&#123;&#123; item.dest &#125;&#125;&quot;</div><div class="line">     owner: root</div><div class="line">     group: root</div><div class="line">     remote_src: yes</div><div class="line">    with_items:</div><div class="line">      - &#123; src: &quot;&#123;&#123; packagedir &#125;&#125;&#123;&#123; etcd_version &#125;&#125;.tar.gz&quot;, dest: &quot;&#123;&#123; serverdir &#125;&#125;&quot; &#125;</div><div class="line"></div><div class="line">  - name: &quot;copy the etcd execfile&quot;</div><div class="line">    shell: &quot;cp -rp &#123;&#123; serverdir &#125;&#125;&#123;&#123; etcd_version &#125;&#125;/etcd* /usr/bin/&quot;</div><div class="line"></div><div class="line">  - name: &quot;init the es configuration!&quot;</div><div class="line">    template:</div><div class="line">      src: &quot;&#123;&#123; item.src &#125;&#125;&quot;</div><div class="line">      dest: &quot;&#123;&#123; item.dest &#125;&#125;&quot;</div><div class="line">      mode: 0755</div><div class="line">      owner: root</div><div class="line">      group: root</div><div class="line">    with_items:</div><div class="line">      #dest后面的引号与大括号中间一定不能有空格,还有后面引号的空格也要取消掉,不然文件会有空格</div><div class="line">      - &#123; src: &quot;etcd.conf.j2&quot;, dest: &quot;/etc/etcd/etcd.conf&quot; &#125;</div><div class="line">      - &#123; src: &quot;etcd.service&quot;, dest: &quot;/etc/systemd/system/&quot; &#125;</div><div class="line"></div><div class="line"># etcd主配置文件模板，这里采用jinja2模板引擎</div><div class="line">$ cat etcd.conf.j2</div><div class="line"># [member]</div><div class="line">BASE_DIR=&quot;/export&quot;</div><div class="line"># 由于etcd_name变量比较特殊，需要和ETCD_INITIAL_CLUSTER中的值一一对应，暂时写为etcd1,配置下发后需要将该值替换成对应节点的名称</div><div class="line">ETCD_NAME=&quot;etcd1&quot;</div><div class="line">ETCD_DATA_DIR=&quot;/export/Data/etcd&quot;</div><div class="line">ETCD_LISTEN_PEER_URLS=&quot;http://&#123;&#123; hostip &#125;&#125;:2380&quot;</div><div class="line">ETCD_LISTEN_CLIENT_URLS=&quot;http://&#123;&#123; hostip &#125;&#125;:2379&quot;</div><div class="line"></div><div class="line">#[cluster]</div><div class="line">ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;http://&#123;&#123; hostip &#125;&#125;:2380&quot;</div><div class="line">ETCD_INITIAL_CLUSTER_TOKEN=&quot;etcd-cluster&quot;</div><div class="line">ETCD_ADVERTISE_CLIENT_URLS=&quot;http://&#123;&#123; hostip &#125;&#125;:2379&quot;</div><div class="line"></div><div class="line">#[initial-cluster]</div><div class="line"># 需要按照etcd集群规划节点来填写</div><div class="line">ETCD_INITIAL_CLUSTER=&quot;etcd1=http://10.0.0.77:2380,etcd2=http://10.0.0.78:2380,etcd3=http://10.0.0.79:2380&quot;</div><div class="line"></div><div class="line"></div><div class="line"># systemd 启动脚本</div><div class="line">$ cat etcd.service</div><div class="line">[Unit]</div><div class="line">Description=Etcd Server</div><div class="line">After=network.target</div><div class="line">After=network-online.target</div><div class="line">Wants=network-online.target</div><div class="line">Documentation=https://github.com/coreos</div><div class="line"></div><div class="line">[Service]</div><div class="line">Type=notify</div><div class="line"># 数据目录，需要提前进行创建</div><div class="line">WorkingDirectory=/export/Data/etcd/</div><div class="line">EnvironmentFile=-/etc/etcd/etcd.conf</div><div class="line">ExecStart=/usr/bin/etcd \</div><div class="line">  --name $&#123;ETCD_NAME&#125; \</div><div class="line">  --initial-advertise-peer-urls $&#123;ETCD_INITIAL_ADVERTISE_PEER_URLS&#125; \</div><div class="line">  --listen-peer-urls $&#123;ETCD_LISTEN_PEER_URLS&#125; \</div><div class="line">  --listen-client-urls $&#123;ETCD_LISTEN_CLIENT_URLS&#125;,http://127.0.0.1:2379 \</div><div class="line">  --advertise-client-urls $&#123;ETCD_ADVERTISE_CLIENT_URLS&#125; \</div><div class="line">  --initial-cluster-token $&#123;ETCD_INITIAL_CLUSTER_TOKEN&#125; \</div><div class="line">  --initial-cluster $&#123;ETCD_INITIAL_CLUSTER&#125; \</div><div class="line">  --initial-cluster-state new \</div><div class="line">  --data-dir=$&#123;ETCD_DATA_DIR&#125;</div><div class="line">Restart=on-failure</div><div class="line">RestartSec=5</div><div class="line">LimitNOFILE=65536</div><div class="line"></div><div class="line">[Install]</div><div class="line">WantedBy=multi-user.target</div><div class="line"></div><div class="line">$ cat hosts</div><div class="line">[etcd]</div><div class="line">10.0.0.77</div><div class="line">10.0.0.78</div><div class="line">10.0.0.79</div></pre></td></tr></table></figure></p>
<p><strong>2.使用ansible-playbooks进行部署etcd集群</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ ansible-playbook -i host -e host=etcd etcd-install.yml</div></pre></td></tr></table></figure>
<p>等待正确执行完成之后，三个节点的etcd就已经安装好了，由于是集群，所以各个节点上的配置还是有专属的部分，暂时没有想到如何进行一次性安装启动，将安装、修改配置、启动作为三部分操作.</p>
<p><strong>3.登录每个节点进行修改etcd_name</strong></p>
<p>修改每个节点上的<code>/etc/etcd/etcd.conf</code>文件:<br><code>注意：需要将各个节点ip和etcd_name对应起来(etcd1-&gt;77 etcd2-&gt;78 etcd-&gt;79)</code></p>
<p>77节点上的配置如下(其他两个节点修改对应的etcd_name)：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ETCD_NAME=&quot;etcd1&quot;</div><div class="line">ETCD_INITIAL_CLUSTER=&quot;etcd1=http://10.0.0.77:2380,etcd2=http://10.0.0.78:2380,etcd3=http://10.0.0.79:2380&quot;</div></pre></td></tr></table></figure>
<p><strong>4.检测配置文件并进行启动集群</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ ansible -i host all -m shell -a &apos;systemctl daemon-reload &amp;&amp; systemctl start etcd &amp;&amp; systemctl enable etcd&apos;</div></pre></td></tr></table></figure>
<p><code>注意：由于etcd采用集群模式，在启动第一个实例的时候会一直监听其他实例，这个时候需要尽快启动其他实例，以完成集群发现，否则第一个实例会在一定时间内挂掉</code></p>
<p><strong>5.集群状态监测</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">$ etcdctl cluster-health</div><div class="line">member 4d946fabd2e1eb9f is healthy: got healthy result from http://10.0.0.79:2379</div><div class="line">member 805150a1f1a44604 is healthy: got healthy result from http://10.0.0.77:2379</div><div class="line">member 81ddc2f4095fe8a1 is healthy: got healthy result from http://10.0.0.78:2379</div><div class="line">cluster is healthy</div><div class="line"></div><div class="line">$ etcdctl member list</div><div class="line">4d946fabd2e1eb9f: name=etcd3 peerURLs=http://10.0.0.79:2380 clientURLs=http://10.0.0.79:2379 isLeader=true</div><div class="line">805150a1f1a44604: name=etcd1 peerURLs=http://10.0.0.77:2380 clientURLs=http://10.0.0.77:2379 isLeader=false</div><div class="line">81ddc2f4095fe8a1: name=etcd2 peerURLs=http://10.0.0.78:2380 clientURLs=http://10.0.0.78:2379 isLeader=false</div></pre></td></tr></table></figure>
<p>如此，可以发现我们的etcd集群已经迅速运行起来了！</p>
<h3 id="三、etcd集群的基本使用"><a href="#三、etcd集群的基本使用" class="headerlink" title="三、etcd集群的基本使用"></a>三、etcd集群的基本使用</h3><p><code>注意1:</code>由于是集群模式，所以可用在任何一个节点进行写入操作，用户也可用使用etcd的http接口进行使用<br><code>注意2:</code>etcd v2和v3的API是完全不同的两个存储实现，所以用户在使用的时候需要注意<code>在etcd v2版本中是采用set存数据的，v3版本中采用put方式</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">指定API版本</div><div class="line"># export ETCDCTL_API=3</div><div class="line"># etcdctl  put foo &quot;Hello World!&quot;</div><div class="line"># etcdctl get foo</div><div class="line">以json格式输出</div><div class="line"># etcdctl --write-out=&quot;json&quot; get foo</div></pre></td></tr></table></figure>
<p><strong>通过前缀获取数据</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">etcdctl --endpoints=$ENDPOINTS put web1 value1</div><div class="line">etcdctl --endpoints=$ENDPOINTS put web2 value2</div><div class="line">etcdctl --endpoints=$ENDPOINTS put web3 value3</div><div class="line"></div><div class="line">etcdctl --endpoints=$ENDPOINTS get web --prefix</div><div class="line">web1</div><div class="line">value1</div><div class="line">web2</div><div class="line">value2</div><div class="line">web3</div><div class="line">value3</div></pre></td></tr></table></figure>
<p><strong>删除数据</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">etcdctl --endpoints=$ENDPOINTS put key myvalue</div><div class="line">etcdctl --endpoints=$ENDPOINTS del key</div><div class="line"></div><div class="line">etcdctl --endpoints=$ENDPOINTS put k1 value1</div><div class="line">etcdctl --endpoints=$ENDPOINTS put k2 value2</div><div class="line">etcdctl --endpoints=$ENDPOINTS del k --prefix</div></pre></td></tr></table></figure>
<p><strong>集群状态信息</strong></p>
<p><code>v3 的API才有这个功能</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">etcdctl --write-out=table  --endpoints=$&#123;HOST_1&#125;:2379,$&#123;HOST_2&#125;:2379,$&#123;HOST_3&#125;:2379 endpoint status</div><div class="line">+-------------------+------------------+---------+---------+-----------+-----------+------------+</div><div class="line">|     ENDPOINT      |        ID        | VERSION | DB SIZE | IS LEADER | RAFT TERM | RAFT INDEX |</div><div class="line">+-------------------+------------------+---------+---------+-----------+-----------+------------+</div><div class="line">| 10.0.0.77:2379 | 805150a1f1a44604 | 3.1.5   | 1.2 MB  | false     |       639 |     188421 |</div><div class="line">| 10.0.0.78:2379 | 81ddc2f4095fe8a1 | 3.1.5   | 1.2 MB  | false     |       639 |     188421 |</div><div class="line">| 10.0.0.79:2379 | 4d946fabd2e1eb9f | 3.1.5   | 1.2 MB  | true      |       639 |     188421 |</div><div class="line">+-------------------+------------------+---------+---------+-----------+-----------+------------+</div></pre></td></tr></table></figure></p>
<!--more-->
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本篇文章记录一下使用&lt;code&gt;ansible-playbooks&lt;/code&gt;进行快速构建一个可用的etcd集群。在阅读并实践本文章之前，请确保您有一个可用的&lt;code&gt;ansible&lt;/code&gt;环境。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Ansible" scheme="http://yoursite.com/categories/Ansible/"/>
    
    
      <category term="Ansible" scheme="http://yoursite.com/tags/Ansible/"/>
    
      <category term="Etcd-Cluster" scheme="http://yoursite.com/tags/Etcd-Cluster/"/>
    
  </entry>
  
</feed>
